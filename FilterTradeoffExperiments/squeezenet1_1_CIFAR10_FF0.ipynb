{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_1_CIFAR10_FF0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0 with filter ratio 0% experiment for 3*3 filters"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "69dfa33b-1214-41fd-cc40-ed5dd5ae5dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.54 s, sys: 461 ms, total: 2 s\n",
            "Wall time: 2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "       # self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                  # kernel_size=3, padding=1)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "              self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "f1979aa6-a4ae-4468-d6cf-1b6386ebad8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPymGSZuqg-e",
        "colab_type": "code",
        "outputId": "65396cad-4878-48f8-d848-b26bc7a8d012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 3.056791 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "756904\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 1, 1), (64,)), parameters=3728\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 1, 1), (64,)), parameters=4240\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 1, 1), (128,)), parameters=12576\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 1, 1), (128,)), parameters=16672\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 1, 1), (192,)), parameters=31152\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 1, 1), (192,)), parameters=37296\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 1, 1), (256,)), parameters=57920\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 1, 1), (256,)), parameters=66112\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 1, 1), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 1, 1), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 1, 1), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 1, 1), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 1, 1), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 1, 1), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 1, 1), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 1, 1), (256,)), parameters=243904\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "a62838c0-56e9-4822-d925-79514161a3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "0fa77aec-b4f4-4550-b814-71ba75f78ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "249034\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 1, 1), (64,)), parameters=3728\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 1, 1), (64,)), parameters=4240\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 1, 1), (128,)), parameters=12576\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 1, 1), (128,)), parameters=16672\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 1, 1), (192,)), parameters=31152\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 1, 1), (192,)), parameters=37296\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 1, 1), (256,)), parameters=57920\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 1, 1), (256,)), parameters=66112\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 1, 1), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 1, 1), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 1, 1), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 1, 1), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 1, 1), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 1, 1), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 1, 1), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 1, 1), (256,)), parameters=243904\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "dab97c76-1b6c-439c-a146-4efeb8e63994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 230.4522  Top1 Accuracy: 0.1026  Top5 Accuracy: 0.5038\n",
            "Epoch: 1 Validation Loss : 229.8549  Top 1 Validation Accuracy 0.1123 Top5 Validation Accuracy: 0.5386\n",
            "Training time for Epoch 1: 35.7563s\n",
            "Validation time for Epoch 1: 6.3999s\n",
            "2\n",
            "Epoch: 2 Train Loss : 229.4928  Top1 Accuracy: 0.1125  Top5 Accuracy: 0.5262\n",
            "Epoch: 2 Validation Loss : 228.8679  Top 1 Validation Accuracy 0.1141 Top5 Validation Accuracy: 0.5459\n",
            "Training time for Epoch 2: 35.8840s\n",
            "Validation time for Epoch 2: 6.2877s\n",
            "3\n",
            "Epoch: 3 Train Loss : 227.1664  Top1 Accuracy: 0.1437  Top5 Accuracy: 0.5491\n",
            "Epoch: 3 Validation Loss : 223.0128  Top 1 Validation Accuracy 0.2044 Top5 Validation Accuracy: 0.5697\n",
            "Training time for Epoch 3: 36.1976s\n",
            "Validation time for Epoch 3: 6.1860s\n",
            "4\n",
            "Epoch: 4 Train Loss : 217.9745  Top1 Accuracy: 0.2189  Top5 Accuracy: 0.6296\n",
            "Epoch: 4 Validation Loss : 205.5457  Top 1 Validation Accuracy 0.2616 Top5 Validation Accuracy: 0.7149\n",
            "Training time for Epoch 4: 35.6964s\n",
            "Validation time for Epoch 4: 6.3398s\n",
            "5\n",
            "Epoch: 5 Train Loss : 203.7177  Top1 Accuracy: 0.2538  Top5 Accuracy: 0.7526\n",
            "Epoch: 5 Validation Loss : 193.6415  Top 1 Validation Accuracy 0.2932 Top5 Validation Accuracy: 0.8049\n",
            "Training time for Epoch 5: 35.2732s\n",
            "Validation time for Epoch 5: 6.1002s\n",
            "6\n",
            "Epoch: 6 Train Loss : 190.2824  Top1 Accuracy: 0.2833  Top5 Accuracy: 0.8240\n",
            "Epoch: 6 Validation Loss : 182.6056  Top 1 Validation Accuracy 0.3110 Top5 Validation Accuracy: 0.8507\n",
            "Training time for Epoch 6: 35.4179s\n",
            "Validation time for Epoch 6: 6.2511s\n",
            "7\n",
            "Epoch: 7 Train Loss : 182.3510  Top1 Accuracy: 0.3045  Top5 Accuracy: 0.8491\n",
            "Epoch: 7 Validation Loss : 174.7082  Top 1 Validation Accuracy 0.3427 Top5 Validation Accuracy: 0.8704\n",
            "Training time for Epoch 7: 35.7174s\n",
            "Validation time for Epoch 7: 6.3499s\n",
            "8\n",
            "Epoch: 8 Train Loss : 176.8793  Top1 Accuracy: 0.3224  Top5 Accuracy: 0.8661\n",
            "Epoch: 8 Validation Loss : 175.3783  Top 1 Validation Accuracy 0.3284 Top5 Validation Accuracy: 0.8695\n",
            "Training time for Epoch 8: 35.2131s\n",
            "Validation time for Epoch 8: 6.2118s\n",
            "9\n",
            "Epoch: 9 Train Loss : 172.6226  Top1 Accuracy: 0.3425  Top5 Accuracy: 0.8733\n",
            "Epoch: 9 Validation Loss : 169.5287  Top 1 Validation Accuracy 0.3602 Top5 Validation Accuracy: 0.8841\n",
            "Training time for Epoch 9: 35.7249s\n",
            "Validation time for Epoch 9: 6.2719s\n",
            "10\n",
            "Epoch: 10 Train Loss : 169.3914  Top1 Accuracy: 0.3543  Top5 Accuracy: 0.8823\n",
            "Epoch: 10 Validation Loss : 163.6352  Top 1 Validation Accuracy 0.3864 Top5 Validation Accuracy: 0.8910\n",
            "Training time for Epoch 10: 35.4010s\n",
            "Validation time for Epoch 10: 6.3687s\n",
            "11\n",
            "Epoch: 11 Train Loss : 165.9267  Top1 Accuracy: 0.3697  Top5 Accuracy: 0.8860\n",
            "Epoch: 11 Validation Loss : 160.8153  Top 1 Validation Accuracy 0.3938 Top5 Validation Accuracy: 0.8956\n",
            "Training time for Epoch 11: 35.7617s\n",
            "Validation time for Epoch 11: 6.2933s\n",
            "12\n",
            "Epoch: 12 Train Loss : 163.5575  Top1 Accuracy: 0.3807  Top5 Accuracy: 0.8921\n",
            "Epoch: 12 Validation Loss : 158.7761  Top 1 Validation Accuracy 0.3985 Top5 Validation Accuracy: 0.9007\n",
            "Training time for Epoch 12: 35.9051s\n",
            "Validation time for Epoch 12: 6.1159s\n",
            "13\n",
            "Epoch: 13 Train Loss : 161.3579  Top1 Accuracy: 0.3924  Top5 Accuracy: 0.8957\n",
            "Epoch: 13 Validation Loss : 157.5295  Top 1 Validation Accuracy 0.4019 Top5 Validation Accuracy: 0.9036\n",
            "Training time for Epoch 13: 35.5762s\n",
            "Validation time for Epoch 13: 6.2789s\n",
            "14\n",
            "Epoch: 14 Train Loss : 159.0483  Top1 Accuracy: 0.4005  Top5 Accuracy: 0.8985\n",
            "Epoch: 14 Validation Loss : 156.3679  Top 1 Validation Accuracy 0.4114 Top5 Validation Accuracy: 0.9076\n",
            "Training time for Epoch 14: 35.4191s\n",
            "Validation time for Epoch 14: 6.3624s\n",
            "15\n",
            "Epoch: 15 Train Loss : 157.4009  Top1 Accuracy: 0.4079  Top5 Accuracy: 0.9033\n",
            "Epoch: 15 Validation Loss : 153.5437  Top 1 Validation Accuracy 0.4223 Top5 Validation Accuracy: 0.9107\n",
            "Training time for Epoch 15: 35.9274s\n",
            "Validation time for Epoch 15: 6.2571s\n",
            "Total time for training and validation: 628.9497s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "d247c137-0017-483a-dd9d-49ac148f575d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f783887edd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n28MMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "75110825-322c-4fb7-f0c5-a1369eb2218b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f78388fa7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "c86cca96-79e0-4cab-d696-eabde0f4ee97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  230.452180\n",
              "  1       2   train  229.492805\n",
              "  2       3   train  227.166446\n",
              "  3       4   train  217.974543\n",
              "  4       5   train  203.717736\n",
              "  5       6   train  190.282351\n",
              "  6       7   train  182.351032\n",
              "  7       8   train  176.879300\n",
              "  8       9   train  172.622559\n",
              "  9      10   train  169.391405\n",
              "  10     11   train  165.926732\n",
              "  11     12   train  163.557525\n",
              "  12     13   train  161.357875\n",
              "  13     14   train  159.048267\n",
              "  14     15   train  157.400932\n",
              "  15      1   valid  229.854908\n",
              "  16      2   valid  228.867947\n",
              "  17      3   valid  223.012812\n",
              "  18      4   valid  205.545743\n",
              "  19      5   valid  193.641526\n",
              "  20      6   valid  182.605598\n",
              "  21      7   valid  174.708198\n",
              "  22      8   valid  175.378305\n",
              "  23      9   valid  169.528694\n",
              "  24     10   valid  163.635210\n",
              "  25     11   valid  160.815305\n",
              "  26     12   valid  158.776095\n",
              "  27     13   valid  157.529532\n",
              "  28     14   valid  156.367905\n",
              "  29     15   valid  153.543682,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-5955664f9120a5a8ca708965911aa099\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-5955664f9120a5a8ca708965911aa099\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 230.45218043327333}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 229.49280548095703}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 227.1664460659027}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 217.97454297542572}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 203.71773607730864}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 190.28235132694243}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 182.35103240013123}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 176.87929985523223}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 172.62255907058716}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 169.39140477180482}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 165.92673215866088}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 163.55752475261687}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 161.35787470340728}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 159.04826743602752}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 157.40093171596527}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 229.85490798950195}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 228.8679473400116}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 223.01281213760376}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 205.54574286937714}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 193.64152646064758}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 182.605597615242}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 174.708198428154}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 175.37830483913422}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 169.52869355678558}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 163.63520979881287}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 160.81530451774597}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 158.77609527111053}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 157.52953159809113}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 156.36790454387665}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 153.54368197917938}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}