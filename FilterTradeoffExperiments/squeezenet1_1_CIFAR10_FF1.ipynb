{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_1_CIFAR10_FF1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0 with filter ratio 100% experiment for 3*3 filters"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "17909608-9746-4b55-f4b7-6d7e3218dfb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.56 s, sys: 417 ms, total: 1.98 s\n",
            "Wall time: 1.99 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        #self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   #kernel_size=1)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "       \n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "              self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "4b9e9832-c15a-4d12-8a20-7208daecff47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:95: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPymGSZuqg-e",
        "colab_type": "code",
        "outputId": "3c1f2d29-7fc2-4bb3-abff-4633d07a7c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 6.988879 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1739944\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 3, 3), (64,), (64, 16, 3, 3), (64,)), parameters=20112\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 3, 3), (64,), (64, 16, 3, 3), (64,)), parameters=20624\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 3, 3), (128,), (128, 32, 3, 3), (128,)), parameters=78112\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 3, 3), (128,), (128, 32, 3, 3), (128,)), parameters=82208\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 3, 3), (192,), (192, 48, 3, 3), (192,)), parameters=178608\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 3, 3), (192,), (192, 48, 3, 3), (192,)), parameters=184752\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 3, 3), (256,), (256, 64, 3, 3), (256,)), parameters=320064\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 3, 3), (256,), (256, 64, 3, 3), (256,)), parameters=328256\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 3, 3), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 3, 3), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 3, 3), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 3, 3), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 3, 3), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 3, 3), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 3, 3), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 3, 3), (256,), (256, 64, 3, 3), (256,)), parameters=1226944\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "1b06113c-449b-4ea2-bfc5-067fc1178368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "6c2d7831-faeb-48e8-ec20-e050db05a85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "1232074\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 3, 3), (64,), (64, 16, 3, 3), (64,)), parameters=20112\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 3, 3), (64,), (64, 16, 3, 3), (64,)), parameters=20624\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 3, 3), (128,), (128, 32, 3, 3), (128,)), parameters=78112\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 3, 3), (128,), (128, 32, 3, 3), (128,)), parameters=82208\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 3, 3), (192,), (192, 48, 3, 3), (192,)), parameters=178608\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 3, 3), (192,), (192, 48, 3, 3), (192,)), parameters=184752\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 3, 3), (256,), (256, 64, 3, 3), (256,)), parameters=320064\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 3, 3), (256,), (256, 64, 3, 3), (256,)), parameters=328256\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 3, 3), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 3, 3), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 3, 3), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 3, 3), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 3, 3), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 3, 3), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 3, 3), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 3, 3), (256,), (256, 64, 3, 3), (256,)), parameters=1226944\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "55efb0e9-679b-4f19-8db2-e0ad9c09c337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 229.8464  Top1 Accuracy: 0.1113  Top5 Accuracy: 0.5131\n",
            "Epoch: 1 Validation Loss : 228.3017  Top 1 Validation Accuracy 0.1540 Top5 Validation Accuracy: 0.5044\n",
            "Training time for Epoch 1: 41.4047s\n",
            "Validation time for Epoch 1: 6.2824s\n",
            "2\n",
            "Epoch: 2 Train Loss : 221.2557  Top1 Accuracy: 0.1623  Top5 Accuracy: 0.6193\n",
            "Epoch: 2 Validation Loss : 208.2428  Top 1 Validation Accuracy 0.2093 Top5 Validation Accuracy: 0.7496\n",
            "Training time for Epoch 2: 41.1852s\n",
            "Validation time for Epoch 2: 6.4500s\n",
            "3\n",
            "Epoch: 3 Train Loss : 198.1793  Top1 Accuracy: 0.2303  Top5 Accuracy: 0.8010\n",
            "Epoch: 3 Validation Loss : 184.4417  Top 1 Validation Accuracy 0.2918 Top5 Validation Accuracy: 0.8461\n",
            "Training time for Epoch 3: 41.5136s\n",
            "Validation time for Epoch 3: 6.5675s\n",
            "4\n",
            "Epoch: 4 Train Loss : 183.3148  Top1 Accuracy: 0.3004  Top5 Accuracy: 0.8476\n",
            "Epoch: 4 Validation Loss : 175.0393  Top 1 Validation Accuracy 0.3407 Top5 Validation Accuracy: 0.8740\n",
            "Training time for Epoch 4: 41.7730s\n",
            "Validation time for Epoch 4: 6.2772s\n",
            "5\n",
            "Epoch: 5 Train Loss : 173.8130  Top1 Accuracy: 0.3438  Top5 Accuracy: 0.8751\n",
            "Epoch: 5 Validation Loss : 164.4200  Top 1 Validation Accuracy 0.3776 Top5 Validation Accuracy: 0.8975\n",
            "Training time for Epoch 5: 41.9215s\n",
            "Validation time for Epoch 5: 6.2268s\n",
            "6\n",
            "Epoch: 6 Train Loss : 166.7289  Top1 Accuracy: 0.3796  Top5 Accuracy: 0.8909\n",
            "Epoch: 6 Validation Loss : 158.7190  Top 1 Validation Accuracy 0.4022 Top5 Validation Accuracy: 0.9048\n",
            "Training time for Epoch 6: 40.8022s\n",
            "Validation time for Epoch 6: 6.3627s\n",
            "7\n",
            "Epoch: 7 Train Loss : 160.8683  Top1 Accuracy: 0.4056  Top5 Accuracy: 0.9020\n",
            "Epoch: 7 Validation Loss : 155.0890  Top 1 Validation Accuracy 0.4269 Top5 Validation Accuracy: 0.9109\n",
            "Training time for Epoch 7: 41.5107s\n",
            "Validation time for Epoch 7: 6.3688s\n",
            "8\n",
            "Epoch: 8 Train Loss : 155.0915  Top1 Accuracy: 0.4290  Top5 Accuracy: 0.9112\n",
            "Epoch: 8 Validation Loss : 150.7905  Top 1 Validation Accuracy 0.4463 Top5 Validation Accuracy: 0.9158\n",
            "Training time for Epoch 8: 41.7317s\n",
            "Validation time for Epoch 8: 6.4140s\n",
            "9\n",
            "Epoch: 9 Train Loss : 149.9406  Top1 Accuracy: 0.4480  Top5 Accuracy: 0.9196\n",
            "Epoch: 9 Validation Loss : 148.3824  Top 1 Validation Accuracy 0.4572 Top5 Validation Accuracy: 0.9201\n",
            "Training time for Epoch 9: 41.2557s\n",
            "Validation time for Epoch 9: 6.2321s\n",
            "10\n",
            "Epoch: 10 Train Loss : 146.2523  Top1 Accuracy: 0.4663  Top5 Accuracy: 0.9238\n",
            "Epoch: 10 Validation Loss : 140.0102  Top 1 Validation Accuracy 0.4869 Top5 Validation Accuracy: 0.9299\n",
            "Training time for Epoch 10: 40.9459s\n",
            "Validation time for Epoch 10: 6.3923s\n",
            "11\n",
            "Epoch: 11 Train Loss : 141.2810  Top1 Accuracy: 0.4831  Top5 Accuracy: 0.9299\n",
            "Epoch: 11 Validation Loss : 142.3810  Top 1 Validation Accuracy 0.4783 Top5 Validation Accuracy: 0.9293\n",
            "Training time for Epoch 11: 40.9065s\n",
            "Validation time for Epoch 11: 6.4640s\n",
            "12\n",
            "Epoch: 12 Train Loss : 138.4859  Top1 Accuracy: 0.4977  Top5 Accuracy: 0.9335\n",
            "Epoch: 12 Validation Loss : 138.0769  Top 1 Validation Accuracy 0.5016 Top5 Validation Accuracy: 0.9295\n",
            "Training time for Epoch 12: 41.7151s\n",
            "Validation time for Epoch 12: 6.2515s\n",
            "13\n",
            "Epoch: 13 Train Loss : 135.7245  Top1 Accuracy: 0.5101  Top5 Accuracy: 0.9351\n",
            "Epoch: 13 Validation Loss : 134.0930  Top 1 Validation Accuracy 0.5114 Top5 Validation Accuracy: 0.9356\n",
            "Training time for Epoch 13: 41.1078s\n",
            "Validation time for Epoch 13: 6.3216s\n",
            "14\n",
            "Epoch: 14 Train Loss : 133.0014  Top1 Accuracy: 0.5193  Top5 Accuracy: 0.9397\n",
            "Epoch: 14 Validation Loss : 131.8440  Top 1 Validation Accuracy 0.5225 Top5 Validation Accuracy: 0.9381\n",
            "Training time for Epoch 14: 41.0773s\n",
            "Validation time for Epoch 14: 6.2344s\n",
            "15\n",
            "Epoch: 15 Train Loss : 129.9040  Top1 Accuracy: 0.5308  Top5 Accuracy: 0.9429\n",
            "Epoch: 15 Validation Loss : 132.7986  Top 1 Validation Accuracy 0.5200 Top5 Validation Accuracy: 0.9380\n",
            "Training time for Epoch 15: 41.1829s\n",
            "Validation time for Epoch 15: 6.3277s\n",
            "Total time for training and validation: 715.2104s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "c601c922-f5b9-4ebd-ea39-a8bd279233d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7839229ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYSDk6AXQggHJ0EvhBAO7v8DSwJkqISKLY8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "b9e685a6-f5bf-49df-feb1-4a0f19a5f3b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f78343bfcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "f6106643-a297-4af2-f585-4e438d680a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  229.846402\n",
              "  1       2   train  221.255692\n",
              "  2       3   train  198.179318\n",
              "  3       4   train  183.314779\n",
              "  4       5   train  173.813024\n",
              "  5       6   train  166.728943\n",
              "  6       7   train  160.868284\n",
              "  7       8   train  155.091484\n",
              "  8       9   train  149.940629\n",
              "  9      10   train  146.252261\n",
              "  10     11   train  141.280964\n",
              "  11     12   train  138.485864\n",
              "  12     13   train  135.724521\n",
              "  13     14   train  133.001426\n",
              "  14     15   train  129.904022\n",
              "  15      1   valid  228.301695\n",
              "  16      2   valid  208.242822\n",
              "  17      3   valid  184.441663\n",
              "  18      4   valid  175.039295\n",
              "  19      5   valid  164.419955\n",
              "  20      6   valid  158.719018\n",
              "  21      7   valid  155.088982\n",
              "  22      8   valid  150.790479\n",
              "  23      9   valid  148.382411\n",
              "  24     10   valid  140.010184\n",
              "  25     11   valid  142.381033\n",
              "  26     12   valid  138.076881\n",
              "  27     13   valid  134.093049\n",
              "  28     14   valid  131.843988\n",
              "  29     15   valid  132.798603,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector002: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-e84ad2b6864653042c2cdb35a6d5f825\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector002\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-e84ad2b6864653042c2cdb35a6d5f825\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 229.84640235900878}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 221.25569195747374}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 198.17931833267212}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 183.31477892398834}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 173.81302418708802}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 166.72894299030304}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 160.86828365325928}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 155.09148440361022}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 149.94062945842742}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 146.2522611618042}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 141.2809644460678}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 138.48586397171022}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 135.72452101707458}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 133.00142590999604}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 129.90402207374572}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 228.30169463157654}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 208.2428216934204}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 184.4416627883911}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 175.03929495811462}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 164.41995453834534}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 158.71901834011078}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 155.08898162841797}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 150.79047918319702}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 148.38241112232208}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 140.01018381118774}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 142.38103318214417}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 138.07688105106354}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 134.09304881095886}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 131.8439882993698}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 132.79860317707062}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}