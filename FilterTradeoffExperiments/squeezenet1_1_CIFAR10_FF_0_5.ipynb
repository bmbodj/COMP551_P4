{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_1_CIFAR10_FF_0.5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0 with filter ratio 50% experiment for 3*3 filters"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "8b2300ab-6e19-40b5-f87c-ed51b215cfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.53 s, sys: 439 ms, total: 1.97 s\n",
            "Wall time: 1.97 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "       \n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "              self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "0b7d7708-dccd-4da6-b52f-e98f9c5dcf54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:95: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPymGSZuqg-e",
        "colab_type": "code",
        "outputId": "39a92130-925b-455a-c08c-127fa985a67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 5.022681 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1248424\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "dcb21296-11d2-4ce8-aa50-06bb335b2367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "f5f8a65b-f1e9-4a4f-fb17-541350875dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "740554\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "4cd20e44-dd58-4d73-ec5f-6139c077dc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 227.7872  Top1 Accuracy: 0.1250  Top5 Accuracy: 0.5353\n",
            "Epoch: 1 Validation Loss : 221.2281  Top 1 Validation Accuracy 0.1828 Top5 Validation Accuracy: 0.6059\n",
            "Training time for Epoch 1: 37.4700s\n",
            "Validation time for Epoch 1: 6.2324s\n",
            "2\n",
            "Epoch: 2 Train Loss : 214.3014  Top1 Accuracy: 0.1993  Top5 Accuracy: 0.6905\n",
            "Epoch: 2 Validation Loss : 198.4798  Top 1 Validation Accuracy 0.2641 Top5 Validation Accuracy: 0.7986\n",
            "Training time for Epoch 2: 38.0491s\n",
            "Validation time for Epoch 2: 6.3717s\n",
            "3\n",
            "Epoch: 3 Train Loss : 192.6781  Top1 Accuracy: 0.2774  Top5 Accuracy: 0.8213\n",
            "Epoch: 3 Validation Loss : 179.5863  Top 1 Validation Accuracy 0.3458 Top5 Validation Accuracy: 0.8565\n",
            "Training time for Epoch 3: 38.2671s\n",
            "Validation time for Epoch 3: 6.2192s\n",
            "4\n",
            "Epoch: 4 Train Loss : 177.3741  Top1 Accuracy: 0.3364  Top5 Accuracy: 0.8669\n",
            "Epoch: 4 Validation Loss : 166.9535  Top 1 Validation Accuracy 0.3833 Top5 Validation Accuracy: 0.8877\n",
            "Training time for Epoch 4: 38.1680s\n",
            "Validation time for Epoch 4: 6.3481s\n",
            "5\n",
            "Epoch: 5 Train Loss : 168.0066  Top1 Accuracy: 0.3741  Top5 Accuracy: 0.8880\n",
            "Epoch: 5 Validation Loss : 158.8752  Top 1 Validation Accuracy 0.4074 Top5 Validation Accuracy: 0.9025\n",
            "Training time for Epoch 5: 37.6010s\n",
            "Validation time for Epoch 5: 6.3409s\n",
            "6\n",
            "Epoch: 6 Train Loss : 160.8608  Top1 Accuracy: 0.4056  Top5 Accuracy: 0.9010\n",
            "Epoch: 6 Validation Loss : 155.5565  Top 1 Validation Accuracy 0.4246 Top5 Validation Accuracy: 0.9077\n",
            "Training time for Epoch 6: 37.9733s\n",
            "Validation time for Epoch 6: 6.2017s\n",
            "7\n",
            "Epoch: 7 Train Loss : 156.1381  Top1 Accuracy: 0.4262  Top5 Accuracy: 0.9073\n",
            "Epoch: 7 Validation Loss : 152.2437  Top 1 Validation Accuracy 0.4376 Top5 Validation Accuracy: 0.9106\n",
            "Training time for Epoch 7: 38.0439s\n",
            "Validation time for Epoch 7: 6.3745s\n",
            "8\n",
            "Epoch: 8 Train Loss : 151.5280  Top1 Accuracy: 0.4426  Top5 Accuracy: 0.9156\n",
            "Epoch: 8 Validation Loss : 150.9251  Top 1 Validation Accuracy 0.4368 Top5 Validation Accuracy: 0.9172\n",
            "Training time for Epoch 8: 37.8611s\n",
            "Validation time for Epoch 8: 6.4130s\n",
            "9\n",
            "Epoch: 9 Train Loss : 147.1803  Top1 Accuracy: 0.4610  Top5 Accuracy: 0.9201\n",
            "Epoch: 9 Validation Loss : 143.4788  Top 1 Validation Accuracy 0.4758 Top5 Validation Accuracy: 0.9220\n",
            "Training time for Epoch 9: 38.9596s\n",
            "Validation time for Epoch 9: 6.4107s\n",
            "10\n",
            "Epoch: 10 Train Loss : 143.6642  Top1 Accuracy: 0.4758  Top5 Accuracy: 0.9263\n",
            "Epoch: 10 Validation Loss : 140.4685  Top 1 Validation Accuracy 0.4885 Top5 Validation Accuracy: 0.9272\n",
            "Training time for Epoch 10: 38.1562s\n",
            "Validation time for Epoch 10: 6.3786s\n",
            "11\n",
            "Epoch: 11 Train Loss : 140.1622  Top1 Accuracy: 0.4888  Top5 Accuracy: 0.9300\n",
            "Epoch: 11 Validation Loss : 138.1193  Top 1 Validation Accuracy 0.4986 Top5 Validation Accuracy: 0.9277\n",
            "Training time for Epoch 11: 38.1193s\n",
            "Validation time for Epoch 11: 6.3370s\n",
            "12\n",
            "Epoch: 12 Train Loss : 137.5764  Top1 Accuracy: 0.5025  Top5 Accuracy: 0.9312\n",
            "Epoch: 12 Validation Loss : 141.5796  Top 1 Validation Accuracy 0.4842 Top5 Validation Accuracy: 0.9240\n",
            "Training time for Epoch 12: 37.8361s\n",
            "Validation time for Epoch 12: 6.2502s\n",
            "13\n",
            "Epoch: 13 Train Loss : 134.8398  Top1 Accuracy: 0.5144  Top5 Accuracy: 0.9348\n",
            "Epoch: 13 Validation Loss : 135.7071  Top 1 Validation Accuracy 0.5124 Top5 Validation Accuracy: 0.9314\n",
            "Training time for Epoch 13: 38.1122s\n",
            "Validation time for Epoch 13: 6.4499s\n",
            "14\n",
            "Epoch: 14 Train Loss : 131.9724  Top1 Accuracy: 0.5249  Top5 Accuracy: 0.9375\n",
            "Epoch: 14 Validation Loss : 134.4443  Top 1 Validation Accuracy 0.5166 Top5 Validation Accuracy: 0.9335\n",
            "Training time for Epoch 14: 38.4340s\n",
            "Validation time for Epoch 14: 6.3452s\n",
            "15\n",
            "Epoch: 15 Train Loss : 129.7205  Top1 Accuracy: 0.5319  Top5 Accuracy: 0.9399\n",
            "Epoch: 15 Validation Loss : 128.3622  Top 1 Validation Accuracy 0.5397 Top5 Validation Accuracy: 0.9428\n",
            "Training time for Epoch 15: 38.2972s\n",
            "Validation time for Epoch 15: 6.3697s\n",
            "Total time for training and validation: 666.3948s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "a464d88b-1d1f-4627-aa36-97cb43760074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff1dc4906d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nToJeCCEauP8PjmBUi3xYM9EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "0faf8257-43bb-413e-8927-1129ec3caff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff1dc588ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "f0641980-d540-48fa-ced3-67a293dd17d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  227.787177\n",
              "  1       2   train  214.301427\n",
              "  2       3   train  192.678087\n",
              "  3       4   train  177.374147\n",
              "  4       5   train  168.006558\n",
              "  5       6   train  160.860773\n",
              "  6       7   train  156.138100\n",
              "  7       8   train  151.527991\n",
              "  8       9   train  147.180251\n",
              "  9      10   train  143.664181\n",
              "  10     11   train  140.162160\n",
              "  11     12   train  137.576361\n",
              "  12     13   train  134.839798\n",
              "  13     14   train  131.972398\n",
              "  14     15   train  129.720539\n",
              "  15      1   valid  221.228073\n",
              "  16      2   valid  198.479758\n",
              "  17      3   valid  179.586320\n",
              "  18      4   valid  166.953473\n",
              "  19      5   valid  158.875248\n",
              "  20      6   valid  155.556514\n",
              "  21      7   valid  152.243718\n",
              "  22      8   valid  150.925143\n",
              "  23      9   valid  143.478797\n",
              "  24     10   valid  140.468511\n",
              "  25     11   valid  138.119281\n",
              "  26     12   valid  141.579593\n",
              "  27     13   valid  135.707111\n",
              "  28     14   valid  134.444295\n",
              "  29     15   valid  128.362171,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-8e0ad88c284e63acf533b1850ce27096\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-8e0ad88c284e63acf533b1850ce27096\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 227.78717732429504}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 214.3014273405075}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 192.67808685302734}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 177.37414741516113}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 168.00655763149263}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 160.86077320575714}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 156.13809969425202}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 151.52799146175386}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 147.18025062084197}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 143.66418087482452}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 140.16216011047362}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 137.57636120319367}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 134.83979833126068}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 131.97239823341368}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 129.7205389738083}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 221.2280731201172}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 198.47975838184357}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 179.58631992340088}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 166.95347321033478}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 158.8752475976944}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 155.55651438236237}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 152.24371802806854}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 150.9251433610916}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 143.47879695892334}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 140.46851110458374}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 138.11928057670593}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 141.5795931816101}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 135.70711147785187}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 134.44429457187653}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 128.3621710538864}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}