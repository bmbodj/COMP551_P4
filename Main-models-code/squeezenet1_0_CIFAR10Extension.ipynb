{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_0_CIFAR10Extension.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of our squezenet extension. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "56bfccf5-951c-47e8-8972-6fbc032c0e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 170401792/170498071 [00:37<00:00, 3181683.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "CPU times: user 3.58 s, sys: 1.67 s, total: 5.25 s\n",
            "Wall time: 40.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xKCA29ViXj1p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DSD_Dropout(nn.Module):\n",
        "\n",
        "#use phase_change to change the phase in the training\n",
        "    (DENSE, SPARSE) = (0, 1)\n",
        "    phase = DENSE\n",
        "\n",
        "    def __init__(self, drop_ratio):\n",
        "        super(DSD_Dropout, self).__init__()\n",
        "        self.drop_ratio = drop_ratio\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.phase is DSD_Dropout.DENSE:\n",
        "            return x\n",
        "        else:\n",
        "#calculate the k using x's size(note that x is unidimensional)\n",
        "            k = drop_ratio * x.size()[0]\n",
        "#get the kth smallest element\n",
        "            kth_value = torch.abs(x).kthvalue(k)[0]\n",
        "            mask = nn.Threshold(kth_value, 0)\n",
        "\n",
        "#filter those smaller than kth_value\n",
        "#and larger than -kth_value\n",
        "\n",
        "            x = mask(x) + mask(-x)\n",
        "            return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "     \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "               self.features = nn.Sequential(\n",
        "               nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 32, 64, 64),\n",
        "                Fire(128, 32, 64, 64),\n",
        "                Fire(128, 64, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                #Fire(256, 64, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256)\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 8, 64, 64),\n",
        "                Fire(128, 8, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 16, 128, 128),\n",
        "                Fire(256, 16, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 24, 192, 192),\n",
        "                Fire(384, 24, 192, 192),\n",
        "                Fire(384, 32, 256, 256),\n",
        "                Fire(512, 32, 256, 256),\n",
        "            )\n",
        "        self.relu= nn.ReLU(inplace=True)\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            #nn.Dropout(p=0.5), substitute  dropout with dense spare dense ayer\n",
        "            DSD_Dropout(nn),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual=x\n",
        "        x = self.features(x)\n",
        "        x= self.relu(x+residual)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dHZMv4QISzz8",
        "colab_type": "code",
        "outputId": "485614d7-0a58-4567-9993-b84a4b819a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "2389fb0b-42e9-4cc2-b83b-24cea290bde5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1265
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (relu): ReLU(inplace)\n",
            "  (classifier): Sequential(\n",
            "    (0): DSD_Dropout()\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5X-h6oa9i19s",
        "colab_type": "code",
        "outputId": "abae1b2c-8730-4c9e-ef87-f9bd8cb601e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1285
        }
      },
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2)), weights=((64, 3, 3, 3), (64,)), parameters=1792\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 64, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,)), parameters=22688\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,)), parameters=24736\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 128, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,)), parameters=90432\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (10): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((64, 3, 3, 3), (64,), (32, 64, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,), (32, 128, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,), (64, 128, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=741728\n",
            "  (relu): ReLU(inplace), weights=(), parameters=0\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zIRJfZRkjJu0",
        "colab_type": "code",
        "outputId": "b419640c-d9dc-47a6-9d2a-1481810d470d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters before reducing class size: \n",
            "746858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "ddf0b526-c960-46c8-e9a1-a5ad62f884ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1355
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r170500096it [00:50, 3181683.32it/s]                               "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Train Loss : 221.3137  Top1 Accuracy: 0.1739  Top5 Accuracy: 0.6281\n",
            "Epoch: 1 Validation Loss : 195.5894  Top 1 Validation Accuracy 0.2932 Top5 Validation Accuracy: 0.8146\n",
            "Training time for Epoch 1: 20.6992s\n",
            "Validation time for Epoch 1: 3.6829s\n",
            "2\n",
            "Epoch: 2 Train Loss : 189.9362  Top1 Accuracy: 0.3010  Top5 Accuracy: 0.8210\n",
            "Epoch: 2 Validation Loss : 174.1116  Top 1 Validation Accuracy 0.3695 Top5 Validation Accuracy: 0.8662\n",
            "Training time for Epoch 2: 22.3020s\n",
            "Validation time for Epoch 2: 3.6568s\n",
            "3\n",
            "Epoch: 3 Train Loss : 173.2405  Top1 Accuracy: 0.3661  Top5 Accuracy: 0.8686\n",
            "Epoch: 3 Validation Loss : 162.3841  Top 1 Validation Accuracy 0.4132 Top5 Validation Accuracy: 0.8929\n",
            "Training time for Epoch 3: 20.4383s\n",
            "Validation time for Epoch 3: 3.6639s\n",
            "4\n",
            "Epoch: 4 Train Loss : 163.7365  Top1 Accuracy: 0.4046  Top5 Accuracy: 0.8908\n",
            "Epoch: 4 Validation Loss : 154.9655  Top 1 Validation Accuracy 0.4339 Top5 Validation Accuracy: 0.9067\n",
            "Training time for Epoch 4: 20.3145s\n",
            "Validation time for Epoch 4: 3.6428s\n",
            "5\n",
            "Epoch: 5 Train Loss : 154.5988  Top1 Accuracy: 0.4415  Top5 Accuracy: 0.9072\n",
            "Epoch: 5 Validation Loss : 148.8317  Top 1 Validation Accuracy 0.4668 Top5 Validation Accuracy: 0.9115\n",
            "Training time for Epoch 5: 23.0732s\n",
            "Validation time for Epoch 5: 4.3998s\n",
            "6\n",
            "Epoch: 6 Train Loss : 148.1693  Top1 Accuracy: 0.4646  Top5 Accuracy: 0.9172\n",
            "Epoch: 6 Validation Loss : 144.3062  Top 1 Validation Accuracy 0.4829 Top5 Validation Accuracy: 0.9213\n",
            "Training time for Epoch 6: 20.3711s\n",
            "Validation time for Epoch 6: 3.6416s\n",
            "7\n",
            "Epoch: 7 Train Loss : 143.6332  Top1 Accuracy: 0.4843  Top5 Accuracy: 0.9219\n",
            "Epoch: 7 Validation Loss : 139.3114  Top 1 Validation Accuracy 0.4926 Top5 Validation Accuracy: 0.9285\n",
            "Training time for Epoch 7: 20.3420s\n",
            "Validation time for Epoch 7: 3.6390s\n",
            "8\n",
            "Epoch: 8 Train Loss : 138.8943  Top1 Accuracy: 0.5004  Top5 Accuracy: 0.9290\n",
            "Epoch: 8 Validation Loss : 137.5620  Top 1 Validation Accuracy 0.5070 Top5 Validation Accuracy: 0.9276\n",
            "Training time for Epoch 8: 22.4039s\n",
            "Validation time for Epoch 8: 3.6457s\n",
            "9\n",
            "Epoch: 9 Train Loss : 135.7164  Top1 Accuracy: 0.5139  Top5 Accuracy: 0.9338\n",
            "Epoch: 9 Validation Loss : 129.6711  Top 1 Validation Accuracy 0.5329 Top5 Validation Accuracy: 0.9381\n",
            "Training time for Epoch 9: 20.3677s\n",
            "Validation time for Epoch 9: 3.6482s\n",
            "10\n",
            "Epoch: 10 Train Loss : 131.7051  Top1 Accuracy: 0.5276  Top5 Accuracy: 0.9375\n",
            "Epoch: 10 Validation Loss : 133.6358  Top 1 Validation Accuracy 0.5237 Top5 Validation Accuracy: 0.9312\n",
            "Training time for Epoch 10: 20.3831s\n",
            "Validation time for Epoch 10: 3.6534s\n",
            "11\n",
            "Epoch: 11 Train Loss : 129.2351  Top1 Accuracy: 0.5375  Top5 Accuracy: 0.9411\n",
            "Epoch: 11 Validation Loss : 131.5316  Top 1 Validation Accuracy 0.5280 Top5 Validation Accuracy: 0.9345\n",
            "Training time for Epoch 11: 20.8335s\n",
            "Validation time for Epoch 11: 4.5581s\n",
            "12\n",
            "Epoch: 12 Train Loss : 125.9184  Top1 Accuracy: 0.5501  Top5 Accuracy: 0.9434\n",
            "Epoch: 12 Validation Loss : 124.4544  Top 1 Validation Accuracy 0.5488 Top5 Validation Accuracy: 0.9469\n",
            "Training time for Epoch 12: 21.0219s\n",
            "Validation time for Epoch 12: 3.6494s\n",
            "13\n",
            "Epoch: 13 Train Loss : 124.0466  Top1 Accuracy: 0.5588  Top5 Accuracy: 0.9461\n",
            "Epoch: 13 Validation Loss : 122.5482  Top 1 Validation Accuracy 0.5561 Top5 Validation Accuracy: 0.9466\n",
            "Training time for Epoch 13: 20.4858s\n",
            "Validation time for Epoch 13: 3.6611s\n",
            "14\n",
            "Epoch: 14 Train Loss : 121.0611  Top1 Accuracy: 0.5692  Top5 Accuracy: 0.9486\n",
            "Epoch: 14 Validation Loss : 122.9892  Top 1 Validation Accuracy 0.5586 Top5 Validation Accuracy: 0.9454\n",
            "Training time for Epoch 14: 20.4012s\n",
            "Validation time for Epoch 14: 3.6519s\n",
            "15\n",
            "Epoch: 15 Train Loss : 118.4467  Top1 Accuracy: 0.5773  Top5 Accuracy: 0.9510\n",
            "Epoch: 15 Validation Loss : 119.0288  Top 1 Validation Accuracy 0.5761 Top5 Validation Accuracy: 0.9495\n",
            "Training time for Epoch 15: 22.4767s\n",
            "Validation time for Epoch 15: 3.6869s\n",
            "Total time for training and validation: 372.3998s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GthykbbSjPys",
        "colab_type": "code",
        "outputId": "6952af66-d1a0-4ae8-8b5b-698780573bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number after training : \")\n",
        "print(get_n_params(model))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number after training : \n",
            "746858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "3a33acd3-6b6a-4cc5-ecbd-3441e20706e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3a8a43aac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEm52AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "fbfde738-686b-4601-c250-d3f6fd3667ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3a9152fcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmi40aAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "70a87db5-f08d-4093-adc3-1ecc09f47ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  221.313668\n",
              "  1       2   train  189.936247\n",
              "  2       3   train  173.240536\n",
              "  3       4   train  163.736486\n",
              "  4       5   train  154.598793\n",
              "  5       6   train  148.169282\n",
              "  6       7   train  143.633250\n",
              "  7       8   train  138.894253\n",
              "  8       9   train  135.716438\n",
              "  9      10   train  131.705148\n",
              "  10     11   train  129.235068\n",
              "  11     12   train  125.918360\n",
              "  12     13   train  124.046559\n",
              "  13     14   train  121.061136\n",
              "  14     15   train  118.446742\n",
              "  15      1   valid  195.589401\n",
              "  16      2   valid  174.111635\n",
              "  17      3   valid  162.384137\n",
              "  18      4   valid  154.965492\n",
              "  19      5   valid  148.831733\n",
              "  20      6   valid  144.306221\n",
              "  21      7   valid  139.311371\n",
              "  22      8   valid  137.561968\n",
              "  23      9   valid  129.671077\n",
              "  24     10   valid  133.635802\n",
              "  25     11   valid  131.531602\n",
              "  26     12   valid  124.454404\n",
              "  27     13   valid  122.548184\n",
              "  28     14   valid  122.989229\n",
              "  29     15   valid  119.028845,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-58cc97f69582d0f177ad20e2dba839e6\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-58cc97f69582d0f177ad20e2dba839e6\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 221.31366834640502}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 189.93624739646913}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 173.24053618907928}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 163.73648624420167}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 154.5987933397293}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 148.16928219795227}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 143.63324978351594}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 138.8942533493042}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 135.71643829345703}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 131.70514824390412}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 129.23506803512572}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 125.91836006641388}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 124.04655898809433}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 121.06113563776016}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 118.44674196243287}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 195.58940136432648}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 174.11163544654846}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 162.38413727283478}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 154.96549248695374}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 148.8317333459854}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 144.30622053146362}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 139.31137073040009}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 137.56196761131287}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 129.67107665538788}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 133.63580238819122}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 131.53160214424133}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 124.45440435409546}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 122.54818350076675}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 122.9892286658287}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 119.02884477376938}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}