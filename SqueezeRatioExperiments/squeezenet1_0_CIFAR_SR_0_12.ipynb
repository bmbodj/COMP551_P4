{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_0_CIFAR_SR_0.12.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0 for the use of the squeeze ratio experiment with squeeze ratio =0.125"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "4540ad2d-54b6-4442-8005-1e6d8376aa92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.57 s, sys: 475 ms, total: 2.05 s\n",
            "Wall time: 2.05 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "## esperimenting squeezeratio 0.125\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 8, 64, 64),\n",
        "                Fire(128, 8, 64, 64),\n",
        "                Fire(128, 16, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 16, 128, 128),\n",
        "                Fire(256, 24, 192, 192),\n",
        "                Fire(384, 24, 192, 192),\n",
        "                Fire(384, 32, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 32, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "597c5d06-fdbb-415c-9be1-35bd5b126d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q03SdfC78ljx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        },
        "outputId": "834f60e1-786a-4120-841c-a157a5720889"
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 3.585569 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "889096\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((8, 96, 1, 1), (8,), (64, 8, 1, 1), (64,), (64, 8, 3, 3), (64,)), parameters=6024\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((8, 128, 1, 1), (8,), (64, 8, 1, 1), (64,), (64, 8, 3, 3), (64,)), parameters=6280\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (128, 16, 1, 1), (128,), (128, 16, 3, 3), (128,)), parameters=22800\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 256, 1, 1), (16,), (128, 16, 1, 1), (128,), (128, 16, 3, 3), (128,)), parameters=24848\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(24, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((24, 256, 1, 1), (24,), (192, 24, 1, 1), (192,), (192, 24, 3, 3), (192,)), parameters=52632\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(24, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((24, 384, 1, 1), (24,), (192, 24, 1, 1), (192,), (192, 24, 3, 3), (192,)), parameters=55704\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 384, 1, 1), (32,), (256, 32, 1, 1), (256,), (256, 32, 3, 3), (256,)), parameters=94752\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 512, 1, 1), (32,), (256, 32, 1, 1), (256,), (256, 32, 3, 3), (256,)), parameters=98848\n",
            "  ), weights=((96, 3, 7, 7), (96,), (8, 96, 1, 1), (8,), (64, 8, 1, 1), (64,), (64, 8, 3, 3), (64,), (8, 128, 1, 1), (8,), (64, 8, 1, 1), (64,), (64, 8, 3, 3), (64,), (16, 128, 1, 1), (16,), (128, 16, 1, 1), (128,), (128, 16, 3, 3), (128,), (16, 256, 1, 1), (16,), (128, 16, 1, 1), (128,), (128, 16, 3, 3), (128,), (24, 256, 1, 1), (24,), (192, 24, 1, 1), (192,), (192, 24, 3, 3), (192,), (24, 384, 1, 1), (24,), (192, 24, 1, 1), (192,), (192, 24, 3, 3), (192,), (32, 384, 1, 1), (32,), (256, 32, 1, 1), (256,), (256, 32, 3, 3), (256,), (32, 512, 1, 1), (32,), (256, 32, 1, 1), (256,), (256, 32, 3, 3), (256,)), parameters=376096\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "6e6e1d9a-dd4a-4e76-bffd-3e055d008d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(24, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(24, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E1dR2XK289js",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        },
        "outputId": "2e3e1082-9e39-4d08-e5d4-b369b6282f3b"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "381226\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((8, 96, 1, 1), (8,), (64, 8, 1, 1), (64,), (64, 8, 3, 3), (64,)), parameters=6024\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((8, 128, 1, 1), (8,), (64, 8, 1, 1), (64,), (64, 8, 3, 3), (64,)), parameters=6280\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (128, 16, 1, 1), (128,), (128, 16, 3, 3), (128,)), parameters=22800\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 256, 1, 1), (16,), (128, 16, 1, 1), (128,), (128, 16, 3, 3), (128,)), parameters=24848\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(24, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((24, 256, 1, 1), (24,), (192, 24, 1, 1), (192,), (192, 24, 3, 3), (192,)), parameters=52632\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(24, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((24, 384, 1, 1), (24,), (192, 24, 1, 1), (192,), (192, 24, 3, 3), (192,)), parameters=55704\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 384, 1, 1), (32,), (256, 32, 1, 1), (256,), (256, 32, 3, 3), (256,)), parameters=94752\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 512, 1, 1), (32,), (256, 32, 1, 1), (256,), (256, 32, 3, 3), (256,)), parameters=98848\n",
            "  ), weights=((96, 3, 7, 7), (96,), (8, 96, 1, 1), (8,), (64, 8, 1, 1), (64,), (64, 8, 3, 3), (64,), (8, 128, 1, 1), (8,), (64, 8, 1, 1), (64,), (64, 8, 3, 3), (64,), (16, 128, 1, 1), (16,), (128, 16, 1, 1), (128,), (128, 16, 3, 3), (128,), (16, 256, 1, 1), (16,), (128, 16, 1, 1), (128,), (128, 16, 3, 3), (128,), (24, 256, 1, 1), (24,), (192, 24, 1, 1), (192,), (192, 24, 3, 3), (192,), (24, 384, 1, 1), (24,), (192, 24, 1, 1), (192,), (192, 24, 3, 3), (192,), (32, 384, 1, 1), (32,), (256, 32, 1, 1), (256,), (256, 32, 3, 3), (256,), (32, 512, 1, 1), (32,), (256, 32, 1, 1), (256,), (256, 32, 3, 3), (256,)), parameters=376096\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "65181fb3-d595-410f-e00d-cc7dfc7fc8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print (model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(24, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(24, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "#define criteria and optimizer\n",
        "# Note that other losses or optimizers can also be tried\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.004, amsgrad=True)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "2a645362-4ee3-4313-9bc0-6abd07736127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 225.7510  Top1 Accuracy: 0.1463  Top5 Accuracy: 0.5739\n",
            "Epoch: 1 Validation Loss : 211.0234  Top 1 Validation Accuracy 0.2336 Top5 Validation Accuracy: 0.7366\n",
            "Training time for Epoch 1: 37.0991s\n",
            "Validation time for Epoch 1: 6.2448s\n",
            "2\n",
            "Epoch: 2 Train Loss : 200.6847  Top1 Accuracy: 0.2548  Top5 Accuracy: 0.7862\n",
            "Epoch: 2 Validation Loss : 185.2288  Top 1 Validation Accuracy 0.3040 Top5 Validation Accuracy: 0.8418\n",
            "Training time for Epoch 2: 37.0920s\n",
            "Validation time for Epoch 2: 6.2306s\n",
            "3\n",
            "Epoch: 3 Train Loss : 184.9716  Top1 Accuracy: 0.3080  Top5 Accuracy: 0.8430\n",
            "Epoch: 3 Validation Loss : 175.2285  Top 1 Validation Accuracy 0.3454 Top5 Validation Accuracy: 0.8697\n",
            "Training time for Epoch 3: 36.9042s\n",
            "Validation time for Epoch 3: 6.2480s\n",
            "4\n",
            "Epoch: 4 Train Loss : 176.1619  Top1 Accuracy: 0.3386  Top5 Accuracy: 0.8698\n",
            "Epoch: 4 Validation Loss : 169.1164  Top 1 Validation Accuracy 0.3677 Top5 Validation Accuracy: 0.8845\n",
            "Training time for Epoch 4: 37.0921s\n",
            "Validation time for Epoch 4: 6.0851s\n",
            "5\n",
            "Epoch: 5 Train Loss : 169.2656  Top1 Accuracy: 0.3658  Top5 Accuracy: 0.8847\n",
            "Epoch: 5 Validation Loss : 163.4660  Top 1 Validation Accuracy 0.3877 Top5 Validation Accuracy: 0.8934\n",
            "Training time for Epoch 5: 36.5832s\n",
            "Validation time for Epoch 5: 6.1393s\n",
            "6\n",
            "Epoch: 6 Train Loss : 163.5670  Top1 Accuracy: 0.3885  Top5 Accuracy: 0.8970\n",
            "Epoch: 6 Validation Loss : 159.8593  Top 1 Validation Accuracy 0.4035 Top5 Validation Accuracy: 0.9003\n",
            "Training time for Epoch 6: 36.0083s\n",
            "Validation time for Epoch 6: 6.0785s\n",
            "7\n",
            "Epoch: 7 Train Loss : 159.6266  Top1 Accuracy: 0.4040  Top5 Accuracy: 0.9043\n",
            "Epoch: 7 Validation Loss : 161.8115  Top 1 Validation Accuracy 0.4070 Top5 Validation Accuracy: 0.8888\n",
            "Training time for Epoch 7: 36.0153s\n",
            "Validation time for Epoch 7: 6.1259s\n",
            "8\n",
            "Epoch: 8 Train Loss : 155.8641  Top1 Accuracy: 0.4222  Top5 Accuracy: 0.9080\n",
            "Epoch: 8 Validation Loss : 155.3785  Top 1 Validation Accuracy 0.4185 Top5 Validation Accuracy: 0.9084\n",
            "Training time for Epoch 8: 36.2830s\n",
            "Validation time for Epoch 8: 6.0650s\n",
            "9\n",
            "Epoch: 9 Train Loss : 152.9868  Top1 Accuracy: 0.4340  Top5 Accuracy: 0.9134\n",
            "Epoch: 9 Validation Loss : 151.3370  Top 1 Validation Accuracy 0.4395 Top5 Validation Accuracy: 0.9126\n",
            "Training time for Epoch 9: 36.1876s\n",
            "Validation time for Epoch 9: 6.1662s\n",
            "10\n",
            "Epoch: 10 Train Loss : 149.4927  Top1 Accuracy: 0.4490  Top5 Accuracy: 0.9200\n",
            "Epoch: 10 Validation Loss : 149.5751  Top 1 Validation Accuracy 0.4467 Top5 Validation Accuracy: 0.9161\n",
            "Training time for Epoch 10: 36.3529s\n",
            "Validation time for Epoch 10: 6.0880s\n",
            "11\n",
            "Epoch: 11 Train Loss : 147.3315  Top1 Accuracy: 0.4563  Top5 Accuracy: 0.9219\n",
            "Epoch: 11 Validation Loss : 145.1374  Top 1 Validation Accuracy 0.4646 Top5 Validation Accuracy: 0.9244\n",
            "Training time for Epoch 11: 36.2737s\n",
            "Validation time for Epoch 11: 6.1905s\n",
            "12\n",
            "Epoch: 12 Train Loss : 145.4346  Top1 Accuracy: 0.4682  Top5 Accuracy: 0.9240\n",
            "Epoch: 12 Validation Loss : 143.3257  Top 1 Validation Accuracy 0.4692 Top5 Validation Accuracy: 0.9222\n",
            "Training time for Epoch 12: 36.3760s\n",
            "Validation time for Epoch 12: 6.1916s\n",
            "13\n",
            "Epoch: 13 Train Loss : 143.2442  Top1 Accuracy: 0.4769  Top5 Accuracy: 0.9249\n",
            "Epoch: 13 Validation Loss : 143.2603  Top 1 Validation Accuracy 0.4690 Top5 Validation Accuracy: 0.9224\n",
            "Training time for Epoch 13: 36.9996s\n",
            "Validation time for Epoch 13: 6.2874s\n",
            "14\n",
            "Epoch: 14 Train Loss : 141.7753  Top1 Accuracy: 0.4815  Top5 Accuracy: 0.9288\n",
            "Epoch: 14 Validation Loss : 142.9134  Top 1 Validation Accuracy 0.4771 Top5 Validation Accuracy: 0.9236\n",
            "Training time for Epoch 14: 37.2194s\n",
            "Validation time for Epoch 14: 6.2509s\n",
            "15\n",
            "Epoch: 15 Train Loss : 139.3137  Top1 Accuracy: 0.4938  Top5 Accuracy: 0.9300\n",
            "Epoch: 15 Validation Loss : 140.8048  Top 1 Validation Accuracy 0.4870 Top5 Validation Accuracy: 0.9285\n",
            "Training time for Epoch 15: 37.1689s\n",
            "Validation time for Epoch 15: 6.2628s\n",
            "Total time for training and validation: 642.3150s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "e7dca34f-4a80-4d59-9b6d-72e0f7e5134c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5698fb5240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ0EvhBAO7v8BEdnNG4TDOMwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "a606d6f7-f313-42e4-b888-ee548cdb4abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5697f5b7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "8541ea3f-3425-4533-920f-cac5d51cce53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  225.750950\n",
              "  1       2   train  200.684719\n",
              "  2       3   train  184.971612\n",
              "  3       4   train  176.161877\n",
              "  4       5   train  169.265586\n",
              "  5       6   train  163.566979\n",
              "  6       7   train  159.626604\n",
              "  7       8   train  155.864117\n",
              "  8       9   train  152.986836\n",
              "  9      10   train  149.492747\n",
              "  10     11   train  147.331480\n",
              "  11     12   train  145.434555\n",
              "  12     13   train  143.244174\n",
              "  13     14   train  141.775259\n",
              "  14     15   train  139.313715\n",
              "  15      1   valid  211.023387\n",
              "  16      2   valid  185.228826\n",
              "  17      3   valid  175.228490\n",
              "  18      4   valid  169.116374\n",
              "  19      5   valid  163.465999\n",
              "  20      6   valid  159.859309\n",
              "  21      7   valid  161.811458\n",
              "  22      8   valid  155.378484\n",
              "  23      9   valid  151.337004\n",
              "  24     10   valid  149.575054\n",
              "  25     11   valid  145.137363\n",
              "  26     12   valid  143.325713\n",
              "  27     13   valid  143.260269\n",
              "  28     14   valid  142.913405\n",
              "  29     15   valid  140.804837,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-94129289c12d548d0ea2dd4f76a78089\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-94129289c12d548d0ea2dd4f76a78089\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 225.75095028877257}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 200.6847190141678}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 184.9716121196747}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 176.16187653541564}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 169.26558599472045}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 163.566978597641}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 159.62660422325135}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 155.86411714553833}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 152.98683621883393}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 149.49274723529817}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 147.331480383873}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 145.4345551252365}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 143.24417390823365}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 141.7752590894699}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 139.31371474266052}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 211.0233871936798}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 185.22882556915283}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 175.22849023342133}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 169.11637425422668}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 163.4659994840622}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 159.85930943489075}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 161.8114583492279}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 155.37848353385925}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 151.33700442314148}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 149.575053691864}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 145.1373631954193}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 143.32571303844452}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 143.26026940345764}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 142.91340482234955}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 140.8048371076584}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}