{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_0_CIFAR_SR_0.25.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0 for the use of the squeeze ratio experiment t with squeeze ratio =0.75"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "1ee9524e-a4f7-4fcf-9eab-534116cbb823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.57 s, sys: 461 ms, total: 2.03 s\n",
            "Wall time: 2.03 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "## esperimenting squeezeratio 0.125\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                 Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "0082a130-30b4-454e-aea8-5cd535220037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sowAzFMy8q-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        },
        "outputId": "5b319eb8-73fe-4021-bfe6-f3b16250daab"
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 5.022681 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1248424\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "362b6f68-7e10-433b-e9eb-7083262a04eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efmf2BYD9DRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        },
        "outputId": "4b27dfa5-606e-4c24-ade5-889a51bb0ce8"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "740554\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "6ea72e01-8926-40ff-ac08-7b96332b4619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print (model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "#define criteria and optimizer\n",
        "# Note that other losses or optimizers can also be tried\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.004, amsgrad=True)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "43872b95-aa85-4cf5-cedd-202391adedec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 229.3357  Top1 Accuracy: 0.1219  Top5 Accuracy: 0.5319\n",
            "Epoch: 1 Validation Loss : 224.4997  Top 1 Validation Accuracy 0.2015 Top5 Validation Accuracy: 0.6138\n",
            "Training time for Epoch 1: 35.7801s\n",
            "Validation time for Epoch 1: 6.0594s\n",
            "2\n",
            "Epoch: 2 Train Loss : 213.2492  Top1 Accuracy: 0.2113  Top5 Accuracy: 0.7049\n",
            "Epoch: 2 Validation Loss : 191.6399  Top 1 Validation Accuracy 0.2927 Top5 Validation Accuracy: 0.8211\n",
            "Training time for Epoch 2: 36.1969s\n",
            "Validation time for Epoch 2: 6.0058s\n",
            "3\n",
            "Epoch: 3 Train Loss : 187.1994  Top1 Accuracy: 0.2973  Top5 Accuracy: 0.8371\n",
            "Epoch: 3 Validation Loss : 177.7845  Top 1 Validation Accuracy 0.3480 Top5 Validation Accuracy: 0.8648\n",
            "Training time for Epoch 3: 36.3165s\n",
            "Validation time for Epoch 3: 5.9966s\n",
            "4\n",
            "Epoch: 4 Train Loss : 174.9271  Top1 Accuracy: 0.3458  Top5 Accuracy: 0.8711\n",
            "Epoch: 4 Validation Loss : 165.1327  Top 1 Validation Accuracy 0.3815 Top5 Validation Accuracy: 0.8907\n",
            "Training time for Epoch 4: 36.3254s\n",
            "Validation time for Epoch 4: 6.0957s\n",
            "5\n",
            "Epoch: 5 Train Loss : 166.8889  Top1 Accuracy: 0.3798  Top5 Accuracy: 0.8888\n",
            "Epoch: 5 Validation Loss : 159.4051  Top 1 Validation Accuracy 0.4096 Top5 Validation Accuracy: 0.9027\n",
            "Training time for Epoch 5: 36.8172s\n",
            "Validation time for Epoch 5: 6.1198s\n",
            "6\n",
            "Epoch: 6 Train Loss : 161.1765  Top1 Accuracy: 0.3979  Top5 Accuracy: 0.9012\n",
            "Epoch: 6 Validation Loss : 156.2770  Top 1 Validation Accuracy 0.4188 Top5 Validation Accuracy: 0.9050\n",
            "Training time for Epoch 6: 36.2600s\n",
            "Validation time for Epoch 6: 6.0636s\n",
            "7\n",
            "Epoch: 7 Train Loss : 156.4383  Top1 Accuracy: 0.4196  Top5 Accuracy: 0.9091\n",
            "Epoch: 7 Validation Loss : 152.3004  Top 1 Validation Accuracy 0.4336 Top5 Validation Accuracy: 0.9099\n",
            "Training time for Epoch 7: 36.5330s\n",
            "Validation time for Epoch 7: 6.0325s\n",
            "8\n",
            "Epoch: 8 Train Loss : 152.4419  Top1 Accuracy: 0.4380  Top5 Accuracy: 0.9134\n",
            "Epoch: 8 Validation Loss : 149.4205  Top 1 Validation Accuracy 0.4486 Top5 Validation Accuracy: 0.9179\n",
            "Training time for Epoch 8: 36.3772s\n",
            "Validation time for Epoch 8: 6.0265s\n",
            "9\n",
            "Epoch: 9 Train Loss : 148.6448  Top1 Accuracy: 0.4511  Top5 Accuracy: 0.9186\n",
            "Epoch: 9 Validation Loss : 145.7750  Top 1 Validation Accuracy 0.4554 Top5 Validation Accuracy: 0.9199\n",
            "Training time for Epoch 9: 36.5961s\n",
            "Validation time for Epoch 9: 6.1218s\n",
            "10\n",
            "Epoch: 10 Train Loss : 146.5265  Top1 Accuracy: 0.4621  Top5 Accuracy: 0.9197\n",
            "Epoch: 10 Validation Loss : 143.5355  Top 1 Validation Accuracy 0.4637 Top5 Validation Accuracy: 0.9285\n",
            "Training time for Epoch 10: 36.5354s\n",
            "Validation time for Epoch 10: 6.0284s\n",
            "11\n",
            "Epoch: 11 Train Loss : 142.1591  Top1 Accuracy: 0.4776  Top5 Accuracy: 0.9270\n",
            "Epoch: 11 Validation Loss : 139.1108  Top 1 Validation Accuracy 0.4900 Top5 Validation Accuracy: 0.9291\n",
            "Training time for Epoch 11: 36.9763s\n",
            "Validation time for Epoch 11: 6.2816s\n",
            "12\n",
            "Epoch: 12 Train Loss : 139.6019  Top1 Accuracy: 0.4901  Top5 Accuracy: 0.9310\n",
            "Epoch: 12 Validation Loss : 137.7891  Top 1 Validation Accuracy 0.4913 Top5 Validation Accuracy: 0.9303\n",
            "Training time for Epoch 12: 37.9317s\n",
            "Validation time for Epoch 12: 6.2216s\n",
            "13\n",
            "Epoch: 13 Train Loss : 136.5441  Top1 Accuracy: 0.5019  Top5 Accuracy: 0.9332\n",
            "Epoch: 13 Validation Loss : 138.0052  Top 1 Validation Accuracy 0.4874 Top5 Validation Accuracy: 0.9276\n",
            "Training time for Epoch 13: 37.7335s\n",
            "Validation time for Epoch 13: 6.2688s\n",
            "14\n",
            "Epoch: 14 Train Loss : 134.3127  Top1 Accuracy: 0.5134  Top5 Accuracy: 0.9362\n",
            "Epoch: 14 Validation Loss : 135.5750  Top 1 Validation Accuracy 0.5030 Top5 Validation Accuracy: 0.9350\n",
            "Training time for Epoch 14: 37.9242s\n",
            "Validation time for Epoch 14: 6.1291s\n",
            "15\n",
            "Epoch: 15 Train Loss : 132.0704  Top1 Accuracy: 0.5190  Top5 Accuracy: 0.9387\n",
            "Epoch: 15 Validation Loss : 131.9609  Top 1 Validation Accuracy 0.5197 Top5 Validation Accuracy: 0.9385\n",
            "Training time for Epoch 15: 36.8567s\n",
            "Validation time for Epoch 15: 6.2676s\n",
            "Total time for training and validation: 642.8835s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "e057d348-96f3-4b9d-fee1-d62caff46085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd520215198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "6aa9a8d3-857e-4fff-f3dd-4317140a2165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd52034b6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCITvYE+/U8MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "a767095e-7768-422b-bd5a-7bf62ef61d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  229.335686\n",
              "  1       2   train  213.249158\n",
              "  2       3   train  187.199393\n",
              "  3       4   train  174.927065\n",
              "  4       5   train  166.888877\n",
              "  5       6   train  161.176520\n",
              "  6       7   train  156.438311\n",
              "  7       8   train  152.441898\n",
              "  8       9   train  148.644824\n",
              "  9      10   train  146.526544\n",
              "  10     11   train  142.159056\n",
              "  11     12   train  139.601856\n",
              "  12     13   train  136.544126\n",
              "  13     14   train  134.312688\n",
              "  14     15   train  132.070423\n",
              "  15      1   valid  224.499688\n",
              "  16      2   valid  191.639940\n",
              "  17      3   valid  177.784471\n",
              "  18      4   valid  165.132744\n",
              "  19      5   valid  159.405073\n",
              "  20      6   valid  156.276971\n",
              "  21      7   valid  152.300383\n",
              "  22      8   valid  149.420464\n",
              "  23      9   valid  145.774956\n",
              "  24     10   valid  143.535506\n",
              "  25     11   valid  139.110819\n",
              "  26     12   valid  137.789121\n",
              "  27     13   valid  138.005213\n",
              "  28     14   valid  135.574973\n",
              "  29     15   valid  131.960873,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-73e271e025f10ef2ede3120fbeb70c3d\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-73e271e025f10ef2ede3120fbeb70c3d\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 229.3356858253479}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 213.2491579055786}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 187.19939262866973}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 174.92706534862518}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 166.88887705802918}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 161.17652022838593}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 156.43831145763397}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 152.4418977022171}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 148.64482414722443}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 146.52654383182525}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 142.15905604362487}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 139.60185644626617}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 136.5441260099411}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 134.31268784999847}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 132.07042309045792}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 224.49968814849854}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 191.63994002342224}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 177.78447103500366}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 165.13274431228638}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 159.40507304668427}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 156.2769706249237}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 152.30038344860077}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 149.42046415805817}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 145.77495551109314}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 143.5355063676834}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 139.11081850528717}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 137.78912103176117}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 138.0052126646042}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 135.57497334480286}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 131.96087324619293}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}