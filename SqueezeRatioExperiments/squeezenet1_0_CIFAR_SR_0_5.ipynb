{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_0_CIFAR_SR_0.5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0 for the use of the squeeze ratio experiment  with squeeze ratio =0.5"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "53f253fb-9167-4178-e561-3a3d9885a7cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.5 s, sys: 422 ms, total: 1.92 s\n",
            "Wall time: 1.92 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "## esperimenting squeezeratio 0.125\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 32, 64, 64),\n",
        "                Fire(128, 32, 64, 64),\n",
        "                Fire(128, 64, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 64, 128, 128),\n",
        "                Fire(256, 96, 192, 192),\n",
        "                Fire(384, 96, 192, 192),\n",
        "                Fire(384, 128, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 128, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "de8429cb-e595-4c44-9ac9-b4b9569692e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tdifmiVL8oRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        },
        "outputId": "f3ea193a-0f56-44d0-9765-3326a237a6b0"
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 7.897313 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1967080\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 96, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,)), parameters=23712\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,)), parameters=24736\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 128, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,)), parameters=90432\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 256, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,)), parameters=98624\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((96, 256, 1, 1), (96,), (192, 96, 1, 1), (192,), (192, 96, 3, 3), (192,)), parameters=209376\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((96, 384, 1, 1), (96,), (192, 96, 1, 1), (192,), (192, 96, 3, 3), (192,)), parameters=221664\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((128, 384, 1, 1), (128,), (256, 128, 1, 1), (256,), (256, 128, 3, 3), (256,)), parameters=377472\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((128, 512, 1, 1), (128,), (256, 128, 1, 1), (256,), (256, 128, 3, 3), (256,)), parameters=393856\n",
            "  ), weights=((96, 3, 7, 7), (96,), (32, 96, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,), (32, 128, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,), (64, 128, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,), (64, 256, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,), (96, 256, 1, 1), (96,), (192, 96, 1, 1), (192,), (192, 96, 3, 3), (192,), (96, 384, 1, 1), (96,), (192, 96, 1, 1), (192,), (192, 96, 3, 3), (192,), (128, 384, 1, 1), (128,), (256, 128, 1, 1), (256,), (256, 128, 3, 3), (256,), (128, 512, 1, 1), (128,), (256, 128, 1, 1), (256,), (256, 128, 3, 3), (256,)), parameters=1454080\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "cde331fa-4157-442b-82c7-9f86d615a3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePklQJAd9Ao-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        },
        "outputId": "6153ff79-e8b0-41eb-8432-8786e9e3c010"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "1459210\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 96, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,)), parameters=23712\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,)), parameters=24736\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 128, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,)), parameters=90432\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 256, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,)), parameters=98624\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((96, 256, 1, 1), (96,), (192, 96, 1, 1), (192,), (192, 96, 3, 3), (192,)), parameters=209376\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((96, 384, 1, 1), (96,), (192, 96, 1, 1), (192,), (192, 96, 3, 3), (192,)), parameters=221664\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((128, 384, 1, 1), (128,), (256, 128, 1, 1), (256,), (256, 128, 3, 3), (256,)), parameters=377472\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((128, 512, 1, 1), (128,), (256, 128, 1, 1), (256,), (256, 128, 3, 3), (256,)), parameters=393856\n",
            "  ), weights=((96, 3, 7, 7), (96,), (32, 96, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,), (32, 128, 1, 1), (32,), (64, 32, 1, 1), (64,), (64, 32, 3, 3), (64,), (64, 128, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,), (64, 256, 1, 1), (64,), (128, 64, 1, 1), (128,), (128, 64, 3, 3), (128,), (96, 256, 1, 1), (96,), (192, 96, 1, 1), (192,), (192, 96, 3, 3), (192,), (96, 384, 1, 1), (96,), (192, 96, 1, 1), (192,), (192, 96, 3, 3), (192,), (128, 384, 1, 1), (128,), (256, 128, 1, 1), (256,), (256, 128, 3, 3), (256,), (128, 512, 1, 1), (128,), (256, 128, 1, 1), (256,), (256, 128, 3, 3), (256,)), parameters=1454080\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "b1f65de3-67dd-402e-8774-fcd1d5c6f86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print (model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "#define criteria and optimizer\n",
        "# Note that other losses or optimizers can also be tried\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.004, amsgrad=True)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "50e0a224-8694-4752-e270-bc1633fc519e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 227.2709  Top1 Accuracy: 0.1302  Top5 Accuracy: 0.5402\n",
            "Epoch: 1 Validation Loss : 216.2573  Top 1 Validation Accuracy 0.2102 Top5 Validation Accuracy: 0.6218\n",
            "Training time for Epoch 1: 40.0227s\n",
            "Validation time for Epoch 1: 5.9753s\n",
            "2\n",
            "Epoch: 2 Train Loss : 202.4804  Top1 Accuracy: 0.2448  Top5 Accuracy: 0.7643\n",
            "Epoch: 2 Validation Loss : 179.4096  Top 1 Validation Accuracy 0.3361 Top5 Validation Accuracy: 0.8611\n",
            "Training time for Epoch 2: 39.9783s\n",
            "Validation time for Epoch 2: 6.0428s\n",
            "3\n",
            "Epoch: 3 Train Loss : 178.0950  Top1 Accuracy: 0.3379  Top5 Accuracy: 0.8612\n",
            "Epoch: 3 Validation Loss : 164.6607  Top 1 Validation Accuracy 0.3896 Top5 Validation Accuracy: 0.8933\n",
            "Training time for Epoch 3: 40.0480s\n",
            "Validation time for Epoch 3: 6.0836s\n",
            "4\n",
            "Epoch: 4 Train Loss : 166.9121  Top1 Accuracy: 0.3821  Top5 Accuracy: 0.8897\n",
            "Epoch: 4 Validation Loss : 155.2812  Top 1 Validation Accuracy 0.4254 Top5 Validation Accuracy: 0.9112\n",
            "Training time for Epoch 4: 40.0662s\n",
            "Validation time for Epoch 4: 6.0468s\n",
            "5\n",
            "Epoch: 5 Train Loss : 159.3970  Top1 Accuracy: 0.4149  Top5 Accuracy: 0.9041\n",
            "Epoch: 5 Validation Loss : 152.3927  Top 1 Validation Accuracy 0.4450 Top5 Validation Accuracy: 0.9171\n",
            "Training time for Epoch 5: 40.1928s\n",
            "Validation time for Epoch 5: 6.0362s\n",
            "6\n",
            "Epoch: 6 Train Loss : 152.9110  Top1 Accuracy: 0.4405  Top5 Accuracy: 0.9147\n",
            "Epoch: 6 Validation Loss : 145.7269  Top 1 Validation Accuracy 0.4718 Top5 Validation Accuracy: 0.9212\n",
            "Training time for Epoch 6: 40.1923s\n",
            "Validation time for Epoch 6: 6.1038s\n",
            "7\n",
            "Epoch: 7 Train Loss : 147.6031  Top1 Accuracy: 0.4633  Top5 Accuracy: 0.9226\n",
            "Epoch: 7 Validation Loss : 143.5564  Top 1 Validation Accuracy 0.4739 Top5 Validation Accuracy: 0.9243\n",
            "Training time for Epoch 7: 40.1060s\n",
            "Validation time for Epoch 7: 6.0646s\n",
            "8\n",
            "Epoch: 8 Train Loss : 143.0663  Top1 Accuracy: 0.4799  Top5 Accuracy: 0.9284\n",
            "Epoch: 8 Validation Loss : 137.5731  Top 1 Validation Accuracy 0.4978 Top5 Validation Accuracy: 0.9360\n",
            "Training time for Epoch 8: 40.2183s\n",
            "Validation time for Epoch 8: 6.0909s\n",
            "9\n",
            "Epoch: 9 Train Loss : 139.0136  Top1 Accuracy: 0.4961  Top5 Accuracy: 0.9323\n",
            "Epoch: 9 Validation Loss : 137.9709  Top 1 Validation Accuracy 0.4998 Top5 Validation Accuracy: 0.9320\n",
            "Training time for Epoch 9: 40.1614s\n",
            "Validation time for Epoch 9: 6.0209s\n",
            "10\n",
            "Epoch: 10 Train Loss : 135.0348  Top1 Accuracy: 0.5126  Top5 Accuracy: 0.9366\n",
            "Epoch: 10 Validation Loss : 134.7695  Top 1 Validation Accuracy 0.5075 Top5 Validation Accuracy: 0.9371\n",
            "Training time for Epoch 10: 40.1565s\n",
            "Validation time for Epoch 10: 6.0446s\n",
            "11\n",
            "Epoch: 11 Train Loss : 131.6517  Top1 Accuracy: 0.5293  Top5 Accuracy: 0.9391\n",
            "Epoch: 11 Validation Loss : 128.9590  Top 1 Validation Accuracy 0.5357 Top5 Validation Accuracy: 0.9459\n",
            "Training time for Epoch 11: 40.1882s\n",
            "Validation time for Epoch 11: 6.0030s\n",
            "12\n",
            "Epoch: 12 Train Loss : 128.2715  Top1 Accuracy: 0.5380  Top5 Accuracy: 0.9443\n",
            "Epoch: 12 Validation Loss : 128.6330  Top 1 Validation Accuracy 0.5404 Top5 Validation Accuracy: 0.9440\n",
            "Training time for Epoch 12: 40.2162s\n",
            "Validation time for Epoch 12: 6.1596s\n",
            "13\n",
            "Epoch: 13 Train Loss : 125.7571  Top1 Accuracy: 0.5505  Top5 Accuracy: 0.9455\n",
            "Epoch: 13 Validation Loss : 124.7742  Top 1 Validation Accuracy 0.5482 Top5 Validation Accuracy: 0.9476\n",
            "Training time for Epoch 13: 41.0492s\n",
            "Validation time for Epoch 13: 6.2684s\n",
            "14\n",
            "Epoch: 14 Train Loss : 122.6305  Top1 Accuracy: 0.5615  Top5 Accuracy: 0.9490\n",
            "Epoch: 14 Validation Loss : 123.4174  Top 1 Validation Accuracy 0.5622 Top5 Validation Accuracy: 0.9515\n",
            "Training time for Epoch 14: 40.8209s\n",
            "Validation time for Epoch 14: 6.2271s\n",
            "15\n",
            "Epoch: 15 Train Loss : 120.0075  Top1 Accuracy: 0.5714  Top5 Accuracy: 0.9514\n",
            "Epoch: 15 Validation Loss : 124.3146  Top 1 Validation Accuracy 0.5497 Top5 Validation Accuracy: 0.9472\n",
            "Training time for Epoch 15: 40.9480s\n",
            "Validation time for Epoch 15: 6.2269s\n",
            "Total time for training and validation: 695.7653s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "138ef738-401d-47f3-fd11-335de248af9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9fa105b160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0AshhIOToBdCCAcnQS+EEA7u/wMSRPLvdtPfBQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "9c15efc1-ef8f-4dcf-9c87-a4196167073c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9fa1151b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XlclWXex/HPxSabgCwugApuKLIo\n4p77kk5qZZqZ5tJim9ksTeNMPZPVMzPtj1PTNDWmqWVW2qKZWpalZrmhgruoKKuAIqssB67njxsJ\nDWU7eBZ/79eLl5xz7nPdv4Pw5eY616K01gghhLAvDpYuQAghhPlJuAshhB2ScBdCCDsk4S6EEHZI\nwl0IIeyQhLsQQtghCXchhLBDEu5CCGGHJNyFEMIOOVnqxP7+/jokJMRSpxdCCJu0Z8+ebK11QG3H\nWSzcQ0JC2L17t6VOL4QQNkkpdboux0m3jBBC2CEJdyGEsEMS7kIIYYcs1udek7KyMlJSUiguLrZ0\nKcKKuLq6EhwcjLOzs6VLEcJmWFW4p6Sk0Lx5c0JCQlBKWbocYQW01pw7d46UlBRCQ0MtXY4QNsOq\numWKi4vx8/OTYBdVlFL4+fnJX3NC1JNVhTsgwS5+Rb4nhKg/q+qWEUIIe5VdUEJCSi7xKbmM6NaS\niCDvJj2fhHs1586dY8SIEQBkZGTg6OhIQIAxEWznzp24uLjU2sbs2bOZP38+YWFhVz3mzTffxMfH\nh2nTppmncCGEVckpLCUhNZeE1FziUy6QkJJLWq7RtagU+Hq6SLhfT35+fuzbtw+ABQsW4OnpyRNP\nPHHZMVprtNY4ONTco7VkyZJaz/Poo482vtjrzGQy4eQk3y5CXCmvuIwDKbnEp+YaV+apF0g+f7Hq\n8VB/D2JDfIkK9iYyyJvuQd54Nmv6nyWr63O3RomJiYSHhzNt2jS6d+9Oeno6c+bMITY2lu7du/Pc\nc89VHXvTTTexb98+TCYTPj4+zJ8/n+joaPr3709mZiYATz/9NAsXLqw6fv78+fTp04ewsDC2b98O\nQGFhIXfccQfh4eFMmjSJ2NjYql881T3zzDP07t2biIgIHnroIbTWABw7dozhw4cTHR1NTEwMSUlJ\nAPz9738nMjKS6OhonnrqqctqBuMvlk6dOgGwaNEibrvtNoYNG8bNN99MXl4ew4cPJyYmhqioKL78\n8suqOpYsWUJUVBTR0dHMnj2b3NxcOnTogMlkAiAnJ+ey20LYosISEztPnWfR1pM8vnIvw1/5nqgF\nX3P3oh28sP4I8akXiAryYf7Yrqy4vy/7nxnN5ieG8vrUntw/qAN9O/hdl2AHK75yf3btQQ6l5Zm1\nzfBAL54Z371Bzz1y5AjLli0jNjYWgBdeeAFfX19MJhPDhg1j0qRJhIeHX/ac3NxchgwZwgsvvMDv\nf/97Fi9ezPz583/VttaanTt3smbNGp577jk2bNjAG2+8QevWrVm9ejX79+8nJiamxroef/xxnn32\nWbTW3H333WzYsIGxY8cydepUFixYwPjx4ykuLqaiooK1a9eyfv16du7ciZubG+fPn6/1de/du5d9\n+/bRokULysrK+Pzzz/Hy8iIzM5OBAwcybtw49u/fz4svvsj27dvx9fXl/PnzeHt7M3DgQDZs2MC4\nceP48MMPmTx5slz9C9tQWkjpia0kXShnR1kH9mYY/eWJWQVUXj8R6O1KZLA3d/QKJjLIuCpv4VF7\n1+31Ij9pddSxY8eqYAf48MMPeffddzGZTKSlpXHo0KFfhbubmxtjx44FoFevXmzdurXGtidOnFh1\nzKUr7G3btvGnP/0JgOjoaLp3r/mX0rfffsvLL79McXEx2dnZ9OrVi379+pGdnc348eMBYxIQwKZN\nm7j33ntxc3MDwNfXt9bXPXr0aFq0aAEYv4Tmz5/Ptm3bcHBwIDk5mezsbL777jumTJlS1d6lf++/\n/35ef/11xo0bx5IlS1i+fHmt5xPCUjKTDpIVt5ZmSd/SLm8vLpTRBWivnenm0IUU796U9r6Jll0H\n0L2tPwHNm1m65Guy2nBv6BV2U/Hw8Kj6/Pjx4/zzn/9k586d+Pj4MH369BrHYVd/A9bR0fGqXRLN\nmjWr9ZiaFBUVMXfuXOLi4ggKCuLpp59u0HhwJycnKioqAH71/Oqve9myZeTm5hIXF4eTkxPBwcHX\nPN+QIUOYO3cumzdvxtnZma5du9a7NiGaQll5BUeSM0nb/y0upzbRKfcn2up0WgIndSBfe46jsO0w\nOvu7EnZxL7GpPxKbsRQuvAeHPaB9fwgdbHy0jgIHR0u/pF+x2nC3Znl5eTRv3hwvLy/S09PZuHEj\nY8aMMes5Bg4cyMcff8ygQYNISEjg0KFDvzrm4sWLODg44O/vT35+PqtXr2batGm0aNGCgIAA1q5d\ne1m3zKhRo3jxxRe56667qrplfH19CQkJYc+ePcTExLBq1aqr1pSbm0vLli1xcnLim2++ITU1FYDh\nw4czZcoUHn/88apumUtX79OnT2fatGk8++yzZv36CFEfOYWlxJ3J4fjRgzif3ESH3J/oxwEiVSkl\nuHDcoycpbWfSIuoWOoZF0MGx+tuRU4x/is5D0jY4tcX4+Oavxv2u3hAy6JewD+hqDImxMAn3BoiJ\niSE8PJyuXbvSvn17Bg4caPZzPPbYY8yYMYPw8PCqD2/vy4dO+fn5MXPmTMLDw2nTpg19+/ateuyD\nDz7gwQcf5KmnnsLFxYXVq1dX9Y/Hxsbi7OzM+PHjef755/njH//IlClTeOutt6q6kWpyzz33MH78\neCIjI+nTpw+dO3cGjG6jJ598ksGDB+Pk5ESvXr149913AZg2bRrPPfccU6ZMMfvXSIiaVFRoTmQV\nsOd0DvtOZVKWtJ2w/J8Z5rCPEQ7GBcn5ZoFkBE/GK/I3+EWMIMLZrfaG3X0hfILxAZCfAae2wqkf\njLA/UjnAwCPgl6APGQS+HSwS9urS6IrrLTY2Vl+5Wcfhw4fp1q2bReqxNiaTCZPJhKurK8ePH2f0\n6NEcP37c5t6QXLlyJRs3bqzTENFrke8NcTUXS8vZeyaHPadz2HMmh5TTJ+hVtodhDvsY5JiAB8WU\nK2cKWvfFrftYXLreDH6dzB+4OachaasR9Cd/gIIM436v4F/CPnQweAc16jRKqT1a69jajrOtpLiB\nFBQUMGLECEwmE1pr3n77bZsL9ocffphNmzaxYcMGS5ci7EipqYJ9yRfYfiKb7SfOcfBMJuEViQxz\n3Mf/uMTTkSRwBpNnII5hU6HzaBxDB+PdzLNpC2vR3vjoOR20hnOJv1zVH9sA+1cYx/l2hBF/he63\nNWk5tpUWNxAfHx/27Nlj6TIa5a233rJ0CcIOlFdoDqblsuvoaZKP7ack/RDtK1KIUKnc6ZxBa+cM\nHKhAOzih2vWHzvdC59E4WbLvWynw72x89L4fKiog8+Av/fWuXk1egoS7EMJ6aI0uyCT1+D6Sj+2j\nKO0w7nmJhOhU7lOV8zIcoMLRGe3XEceWvcE/DFpHojoMMd7ctEYODtA60vjof31mqEu4CyGuv4oK\nyE2G7GOQdZSC1INcTDuMe24iHhX5BAPBQBGunHMLweR/EwXtI/EM7g7+YTi0CAFHia9rka+OEML8\nSvIh/6zxpmLB2V8+z0uDrKPo7OMo0y/rrxRrL07qQFKc+qNadsEvJJLO3XsR2K4T7lYwrNAWSbgL\nIeqmogIunjeGABacrQztjMv/vRTkZYW/enq5gzN5Tv4klrcmvmQoiTqQdOf2+IZE0COsIwM6+tEn\nwFPW7zcTCfdqhg0bxvz587n55pur7lu4cCFHjx695puDnp6eFBQUkJaWxrx582qcCDR06FBeeeWV\ny5YwuNLChQuZM2cO7u7uAPzmN79hxYoV+Pj4NOJVCVFPJQUQt9ToMinIvDy4K2qYQe3SHJq3Qnu2\nosg/imx/H5LLvDhR5EFCnisJuW5kVPiQiwfuLk70DvFlYCc/pnX0p1sbLxwdJMybgoR7NVOnTmXl\nypWXhfvKlSt56aWX6vT8wMDAa87wrM3ChQuZPn16Vbh/9dVXDW7LEmpbDllYOa0h4RNj5mV+Orj7\nQ/PW4NkKWnYz/vVsBc1bUejiz4mLnhzMbcaB7HKOZORzNCmfgpJfwr+9nztdA5szJsaLrq2b07WN\nF+183SXMrxP5Kaxm0qRJrFu3jtLSUgCSkpJIS0tj0KBBVePOY2JiiIyM5IsvvvjV85OSkoiIiACM\npQHuuusuunXrxu23387Fi7/0Lz788MNVywU/88wzALz++uukpaUxbNgwhg0bBkBISAjZ2dkAvPba\na0RERBAREVG1XHBSUhLdunXjgQceoHv37owePfqy81yydu1a+vbtS8+ePRk5ciRnz54FjLH0s2fP\nJjIykqioKFavXg3Ahg0biImJITo6umrzkgULFvDKK69UtRkREUFSUhJJSUmEhYUxY8YMIiIiSE5O\nrvH1AezatYsBAwYQHR1Nnz59yM/PZ/DgwZctZXzTTTexf//+ev2/CTNIjYN3R8OnDxiBft838OQJ\nTHO2knjzUtaGPs3L5VO4/2gvBq71pvu7eUxYkcaf151i7f40HB0Ud8QE8Y+JkXz2yAAOPnszP/xx\nGG/fE8vvRnVhbGQbQv09JNivI+u9cl8/HzISzNtm60gY+8JVH/b19aVPnz6sX7+eW2+9lZUrV3Ln\nnXeilMLV1ZXPPvsMLy8vsrOz6devHxMmTLhq/+Bbb72Fu7s7hw8fJj4+/rIle//2t7/h6+tLeXk5\nI0aMID4+nnnz5vHaa6+xefNm/P39L2trz549LFmyhB07dqC1pm/fvgwZMoQWLVpw/PhxPvzwQ/77\n3/9y5513snr1aqZPn37Z82+66SZ+/vlnlFIsWrSIl156iVdffZXnn38eb29vEhKMr3NOTg5ZWVk8\n8MADbNmyhdDQ0DotC3z8+HGWLl1Kv379rvr6unbtypQpU/joo4/o3bs3eXl5uLm5cd999/Hee++x\ncOFCjh07RnFxMdHR0bWeU5hJQSZ8+yzs/QA8AjCN/xfbPEaxYWcmCZ9t5XhmAaUmY1E5JwdFhwAP\nerVvwbR+7ejW2ouubZrT2stV+smtkPWGu4Vc6pq5FO6X1kjRWvOXv/yFLVu24ODgQGpqKmfPnqV1\n69Y1trNlyxbmzZsHQFRUFFFRUVWPffzxx7zzzjuYTCbS09M5dOjQZY9fadu2bdx+++1VKzROnDiR\nrVu3MmHCBEJDQ+nRowdw+ZLB1aWkpDBlyhTS09MpLS0lNDQUMJYAXrlyZdVxLVq0YO3atQwePLjq\nmLosC9y+ffuqYL/a61NK0aZNG3r37g2Al5cxiWPy5Mk8//zzvPzyyyxevJhZs2bVej5hBqZS2PEf\n+OEltKmY9PD7+a/DJD5fl0dO0R6aN3OiRzsfZg0IMbpUWnvRsaUHzZysb/VDUTPrDfdrXGE3pVtv\nvZXf/e53xMXFUVRURK9evQBjIa6srCz27NmDs7MzISEhDVpe99SpU7zyyivs2rWLFi1aMGvWrAa1\nc8ml5YLBWDK4pm6Zxx57jN///vdMmDCB77//ngULFtT7PNWXBYbLlwauvixwfV+fu7s7o0aN4osv\nvuDjjz+2+Vm5NuHY1+iNf0adS+SY9wD+UjiV3XF+uDlfYFR4K8ZHBzK4i78EuY2TPvcreHp6MmzY\nMO69916mTp1adf+l5W6dnZ3ZvHkzp0+fvmY7gwcPZsUKYy2JAwcOEB8fDxjLBXt4eODt7c3Zs2dZ\nv3591XOaN29Ofn7+r9oaNGgQn3/+OUVFRRQWFvLZZ58xaNCgOr+m3NxcgoKMxYqWLl1adf+oUaN4\n8803q27n5OTQr18/tmzZwqlTpwCqumVCQkKIi4sDIC4ururxK13t9YWFhZGens6uXbsAyM/Pr1q7\n/v7772fevHn07t27amMQYX466xj5794OKyaTfL6IWaVPMu7cPPzah/Ovu3uy539G8vrUnowKbyXB\nbges98rdgqZOncrtt99+WZfFtGnTqpa7jY2NrXXjiYcffpjZs2fTrVs3unXrVvUXQHR0ND179qRr\n1660bdv2suWC58yZw5gxYwgMDGTz5s1V98fExDBr1iz69OkDGGHYs2fPGrtgarJgwQImT55MixYt\nGD58eFUwP/300zz66KNERETg6OjIM888w8SJE3nnnXeYOHEiFRUVtGzZkm+++YY77riDZcuW0b17\nd/r27UuXLl1qPNfVXp+LiwsfffQRjz32GBcvXsTNzY1Nmzbh6elJr1698PLyYvbs2XV6PaJ+Tian\ncX79/9IjbSVau/D38mkkhk5jXI/2vN69FV6uzpYuUTQBWfJXWFxaWhpDhw7lyJEjVx1GKd8b9ZN8\nvoi1+1Mo2bWc6YXv4Uc+33uMJqfffIb1isDXivb6FPUjS/4Km7Bs2TKeeuopXnvtNRkf30gZucWs\nS0hn7f40HFJ2ssB5KVEOpzjrE03OuJcZ3rlv7Y0IuyHhLixqxowZzJgxw9Jl2KxzBSWsP5DB2v1p\n7Ew6T0t9nn94rWJ4s+8xebSBmxfRKnKSVWz7Jq4vqwt3rbWMmRWXsVTXobXKLSpj48EM1sansf3E\nOcorNGH+zrzfZSv9U9/DobwCBj2B002/g6beoEJYLasKd1dXV86dO4efn58EvACMYD937hyurq6W\nLsWi8ovL2HT4LF/uT2fL8SzKyjVtfd2YMyiUqV7xtN31N9Tp09BtPIz+X2gRYumShYVZVbgHBweT\nkpJCVlaWpUsRVsTV1ZXg4GBLl3HdFZWa+O5IJmv3p7H5aBbKVEyf5ud4KayQ/t7naVV6GnXiEGQf\nhZbhMOML6DDU0mULK1GncFdKjQH+CTgCi7TWL1zx+CzgZSC18q5/aa0X1bcYZ2fnqpmRQtyIisvK\n+TH+GPv37STn9AHaVaRwj3MGL7hn4FOajirTcBJAGft1+odB3zkQM0s2rxCXqfW7QSnlCLwJjAJS\ngF1KqTVa60NXHPqR1npuE9QohP2pqIC8FMg6hinzKGdP7qc47TA+RUmMUHmMAHCAcudmOPh3Rvn3\ng4Aw8O9ifPh1Aucbu6tKXFtdftX3ARK11sb1glIrgVuBK8NdiBuP1mAqgbIi46O06JfPq25fNDav\nKDxndKFkHUWfS0SVFQHGD6G79uSsCiK7xWAuhEbQPqwnTi3DcPRpBw4yW1TUX13CPQhIrnY7Bahp\nwOwdSqnBwDHgd1rr5CsPUErNAeYAtGvXrv7VCtHUso9D/Edw8cIvoXxZYF+E0sLKxyrv0xW1t1up\nxCOI0w5B7DIN40BZa9Kc2tK2S0+G9ezKoC4tcXGSsf7CPMzVSbcW+FBrXaKUehBYCgy/8iCt9TvA\nO2DMUDXTuYVovMzDsOUVOLAalAO4eoGzBzi7gYs7OLuDqw80bwMuHsZtZ/fKx9yqHXvpMePzCkdX\nDmSb+OZYHp8fKST5HLg6OzCiWyvGR7VhaFhLXJ3lylyYX13CPRVoW+12ML+8cQqA1vpctZuLgLpt\nXSSEpWUcgC0vw6EvjFAe+Dj0nwueAQ1usqJCs+dMDuv2prP+QDpn80pwcXJgaJdWPBkdyIhuLXF3\nkTc/RdOqy3fYLqCzUioUI9TvAu6ufoBSqo3WOr3y5gTgsFmrFMLc0vfDDy/BkS+NPUAH/QH6PQIe\nfg1qrqJCE3cmh3UJ6axPyCAjr7gy0AO4JaoNI7q1wrOZBLq4fmr9btNam5RSc4GNGEMhF2utDyql\nngN2a63XAPOUUhMAE3AemNWENQvRcKl74IeX4dh6aOYNQ/4EfR8C99o3JbnStQL9z1FdGd61Jc1l\nxUVhIVa1KqQQTSZ5F/zwIiR+Y/Sd938U+swBN596NVNRodmbnMOX8ZcH+pAuAYyLaiOBLpqcrAop\nBMCZn+H7F+DkZnDzhRF/hd4PGG+Y1tGlQF8Xn8FXCelGoDs6MCQsgPmRXRnRTQJdWB8Jd2GfkrYZ\nV+qntoC7P4x6DmLvq/NCWtUDff2BdNJzjUAf3CWA+WMl0IX1k3AX9kNrOPWD8Ubp6R/BsxXc/Hfo\nNdsYsljr0zV7ky+wLj6drxIuD/Qnx4QxopvsWiRsh4S7sH1aw4lvjVBP3mGMRR/7EsTMMMabX/Op\nmoNpeayNT2NdfDopORcrA91fAl3YNAl3Ybu0huPfGN0vqbvBKxhueRV6TK913ZVjZ/P5cn8aa+PT\nOZVdiJOD4qbO/vx2ZBdGy76iwg5IuIvrS+tfpu6XFv6y/kppwa/vqz71v6b7CzMhJwl82sH4f0L0\n3eB09b1BT2UX8uX+NL6MT+fo2XwcFPTr4MecwR0Y0701LWRfUWFHJNxF08o4AN89b4wvvxTU1GP4\nrXIwpvZfWgLg0vR+F3fwjDAmH0VPBcear7RTcopYF5/O2vg0DqTmAdA7pAXPTujO2MjWtGwuKysK\n+yThLppGXhp89zfY9wG4ehs7BDXzMsLZxf3qge18xeNOrvXe//NsXjHr4tP5Mj6NuDMXAIgO9ubp\nW7rxm8g2BPpcux9eCHsg4S7MqyQffvwnbP8X6HJjstDgJ8CtRZOe9lxBCV8dyODLyo2itYZubbx4\nckwY4yIDaedX+2gZIeyJhLswj3ITxC2F7/8BhVkQcYcxYagJ9/KsaaPojgEePD6iM+OiAunUUjaH\nFjcuCXfROFrD0fWw6RnIPgbtBsDUjyC4V5OdMvl8Ef/depKPdiVTYqqgna87Dw3pwLioQLq2bi6b\nqwuBhLtojNQ4+Pp/4PQ28OsMd62AsN/Uu4+8ro5m5POfH06wZn8aDgpu7xnEtL7tiQr2lkAX4goS\n7qL+ck4bI2ASPjGm9v/mFeg166ojVhprz+kc3vo+kU2HM3F3cWT2gBDuGxRKG295Y1SIq5FwF3V3\nMQe2vgo73jaGKA56wtjcoh6LcNWV1pofjmXx7+9PsPPUeXzcnfntyM7M7B8i49GFqAMJd1E7Uyns\nWgRbXjL2Fu1xNwx7CryDzH6q8grNVwnpvPX9CQ6l59HG25X/GRfO1D5tZfciIepBflrE1WkNhz6H\nTQuMmaAdhsHo56F1pNlPVVxWzqdxqby95QSnzxXRIcCDlyZFcVuPINk0WogGkHAXNTvzM3z9NKTs\ngpbdYfpq6DTS7KfJLy5jxY4zLNp2iqz8EqKCvfnP9BhGh7fGwUHeJBWioSTcxeXOnTCGNR5ea6yu\nOOFfRjeMg6NZT5NdUMJ7Pyax7Kck8opN3NTJn4VTejCgo5+MfBHCDCTchdH9krwDdi+GA6uNKf/D\nnjJml7p4mPVU1ceol5ZXMKZ7ax4a0pHotvXb7k4IcW0S7jeyixcg/mMj1LMOG2u/9L7fWIzLs6VZ\nT1XTGPUHh3SkY4DMIhWiKUi432i0NiYf7VkMCavBdBECe8KEN4wlA8x8pX40I59Xvz7K14fO4u7i\nyKwBIdwvY9SFaHIS7jeKknxj0tHuxZCRYKy6GD3F2IIusIfZT3fmXBELNx3js32peLo48fiIzswa\nIGPUhbheJNztXfp+I9ATVhkbYrSKhFteg8jJTTL5KDOvmDe+S2TlrjM4KMWcQR14aEhHCXUhrjMJ\nd3tUWmi8Mbp7CaTFgZOb0eUSOxuCejXJ2i+5RWW89cMJ3tt+ClO5Zkrvtswb0ZlWXrIZhhCWIOFu\nT84eNAI9/iMoyYOArsZG0VFTwK1pRqMUlph4b3sS//nhBAUlJm6NDuS3I7sQ4m/evnshRP1IuNu6\nsotw8HPYs8QYzujYDLrfZvSlt+vXZCs0lpjK+XDHGf61OZHsglJGdmvFH0Z3oVsb83f1CCHqT8Ld\nVmUdMwJ93woovgB+nWD034wJR+6+TXba8grNp3EpLNx0nNQLF+nXwZe37+lKr/ZNu9OSEKJ+JNxt\nTXkZfPe/8ONCcHA29iaNnQ0hg5rsKh2MVRo3HMjg1W+OkZhZQGSQNy/cEclNnfxlRqkQVkjC3Zbk\nnIbV9xnrvfSaBcOeBs+AJj2l1pptidm8vPEo8Sm5dAzw4K1pMYyJaC2hLoQVk3C3FYfWwJq5xiSk\nye9B99ub/JRxZ3J4acMRfj55niAfN16eFMXtPYNwcpRVGoWwdhLu1q6sGL5+ylhPPTAGJi0G39Am\nPeWRjDxe2XiMTYfP4u/pwoLx4Uzt245mTuZdPEwI0XQk3K1Z9nH4ZDacTYABj8Hwv4JT000GSr1w\nkZc3HOGL/Wl4NnPiidFdmD0wFI9m8m0ihK2Rn1prtW8FrHsCnF3h7k+gy+gmO5XWmk92p/Dcl4cw\nVVTw4OCOPDSkAz7uMqtUCFsl4W5tSgpg3R8gfqUxAmbiO+AV2GSnO5tXzPzV8Ww+mkXfUF9emRxN\nW1/3JjufEOL6kHC3JunxsGo2nD8JQ/8Mg/9o9k0yLtFa88W+NJ5Zc5ASUznPjA9nZv8Q2f1ICDtR\np2EPSqkxSqmjSqlEpdT8axx3h1JKK6VizVfiDUBr2PlfWDTSWBdm5loYOr/Jgj27oISH3t/Dbz/a\nR4cAD76aN4jZA0Ml2IWwI7VeuSulHIE3gVFACrBLKbVGa33oiuOaA48DO5qiULt1MQe+mAtHvoTO\no+G2t8DDv8lOtz4hnac+P0BBsYn5Y7vywKAOOEqoC2F36tIt0wdI1FqfBFBKrQRuBQ5dcdzzwIvA\nH81aoT1L3gmr7oX8DGPpgH6PgEPTjCG/UFTKX784yJr9aUQEefHq5B6EtW7eJOcSQlheXcI9CEiu\ndjsF6Fv9AKVUDNBWa71OKSXhXpuKCmP5gO/+F3zawn0bjaV4m8i3h88y/9MEcgpL+d3ILjwyrCPO\nMhFJCLvW6DdUlVIOwGvArDocOweYA9CuXbvGnto2FWTCZw/Cie+g+0QYvxBcvZvkVHnFZTy/9hCf\n7EkhrFVzlszqTURQ05xLCGFd6hLuqUDbareDK++7pDkQAXxfudZIa2CNUmqC1np39Ya01u8A7wDE\nxsbqRtRtm05+D5/OgeJcGP9PiJnZZIt9bT2exZ9WxZORV8wjQzvy+MjOMsNUiBtIXcJ9F9BZKRWK\nEep3AXdfelBrnQtUvQOolPoeeOLKYL+hlZvg+3/A1lchIAzu+RxahTfJqQpLTPxj/WHe//kMHQI8\nWP3wAHq2k+V4hbjR1BruWmt6EdE9AAAVCElEQVSTUmousBFwBBZrrQ8qpZ4Ddmut1zR1kTYtNwVW\n3QfJP0PPe4ydkVyaZpLQjpPn+OOqeJJzirj/plCeuDkMV2e5WhfiRlSnPnet9VfAV1fc99erHDu0\n8WXZiezjsHgMmErgjnchclKTnKa4rJyXNx5l8Y+naNvCnY/m9KdPaNNt2CGEsH4yQ7Wp5KXD8olG\nn/oD30FAlyY5zd4zOfzhk/2czCrknn7tmT+2qyz0JYSQcG8SFy/A+3fAxfMwa12TBHuJqZyFm47z\n9g8naO3lyvv39eWmzk03+UkIYVsk3M2t7CJ8OBWyj8H0VRDYw+ynOH2ukAeX7+FIRj53xgbz9Lhw\nvFydzX4eIYTtknA3p3ITrL4fzvxkbKrRYajZT3EgNZdZS3Zhqqhg8axYhndtZfZzCCFsn4S7uWgN\n635vrBEz9iWImGj2U/x04hwPLNuNl6sTK+f0p1NLWT5ACFEzCXdz2fx3iFsKg56Avg+avfkNB9KZ\n9+E+2vm5s+zePgT6uJn9HEII+yHhbg473oEtLxnj2Ic/bfbmV+w4w9OfJxDd1ofFM3vTwkN2SBJC\nXJuEe2Md+BTWPwlht8C4hWZdTkBrzRvfJfLaN8cYGhbAv6fF4O4i/2VCiNpJUjTGpbVi2vWDSe+C\no/m+nBUVmgVrD7Lsp9NM7BnEi5OiZCVHIUSdSbg3VNo+WDkd/DvD1A/B2Xx94CWmcv7w8X6+jE/n\ngUGh/HlsN9klSQhRLxLuDXHuBHwwCdx8YPpqcDPfwlwFJSYeWr6HbYnZ/HlsVx4c0tFsbQshbhwS\n7vWVfxbenwgV5TD9U/AKNFvT5wpKmP3eLg6m5fHypCgmx7at/UlCCFEDCff6KM6DD+4wNtyYudas\nywokny9i5uKdpF64yNvTezEyXCYnCSEaTsK9rkwlsPJuyDwMUz+C4FizNX0kI4+Zi3dysbScD+7v\nS2yIrOgohGgcCfe6qCiHTx+ApK1w+zvQeaTZmt6VdJ773tuFm4sjnzw0QDatFkKYhYR7bbQ2xrEf\n+gJG/w2ip5it6U2HzvLoijiCfNxYdl8fgls0zSYeQogbj4R7bba8DLsWwYB5MGCu2Zr9eHcyf/40\ngYhALxbP6o2fZzOztS2EEBLu17J7CWz+G0RPhZHPmqVJrTVvbznJC+uPMKizP/+Z3ks21xBCmJ2k\nytUcXmus8thpFEx4AxwaPzu0okLz968Os2jbKcZHB/Lq5GhcnGTWqRDC/CTca5K0zdjUOjAG7lwK\njo3fCKOsvIInV8Xz2d5UZvZvzzPju8usUyFEk5Fwv1JGgrGTUov2MO0TcPFodJNFpSYe+SCO749m\n8YdRXZg7vBPKjAuMCSHElSTcq8tJMvY+dfE0Zp+6N368eU5hKfcu3cX+5Av8/fZI7u7brvF1CiFE\nLSTcLynMhuUTwVQM924En8ZP/S81VTD1vz9zMruQf0+LYUxEGzMUKoQQtZNwv2TNY5CXCjO+gJbd\nzNLkx7uTOZKRz3+mS7ALIa4vGaoBkJsCR9dD/7nG2uxmUFxWzhvfHSe2fQtu7t7aLG0KIURdSbgD\n7PsQ0NBzutmaXP7Tac7mlfDEzWHy5qkQ4rqTcK+ogL3LIWQQ+Iaapcn84jL+/X0igzr706+Dn1na\nFEKI+pBwP70NLpw2Nrc2k8XbksgpKuOJ0WFma1MIIepDwj1uOTTzhvAJZmkup7CURVtPcnP3VkS3\n9TFLm0IIUV83drhfvACH10DkJLPtgfqfLScoKDXxB7lqF0JY0I0d7gdWGePazfRGamZeMUu3J3Fr\ndCBdWsm67EIIy7mxwz1uObSKgMCeZmnuX5sTMZVrfjvSfNvvCSFEQ9y44Z6RAOn7jDdSzTBUMfl8\nER/uPMPk2LaE+Dd+PRohhGiMGzfc974Pji4QdadZmvvnt8dRSjFvRCeztCeEEI1xY4a7qQTiP4Ku\nt5hlcbDEzAI+jUvhnn7taeNtnjdmhRCiMW7McD/yJVzMMdvY9v/75hhuzo48MrSjWdoTQojGqlO4\nK6XGKKWOKqUSlVLza3j8IaVUglJqn1Jqm1Iq3PylmtHe98ErGDoMbXRTB1JzWZeQzr03hco+qEII\nq1FruCulHIE3gbFAODC1hvBeobWO1Fr3AF4CXjN7peZy4Qyc2Aw9p4GDY6Obe+2bY3i7OXP/oA5m\nKE4IIcyjLlfufYBErfVJrXUpsBK4tfoBWuu8ajc9AG2+Es1s3wrj3x7TGt3UntPn+e5IJg8O6YC3\nW+O34hNCCHOpy3ruQUBytdspQN8rD1JKPQr8HnABhpulOnOrqIC9H0CHIcY2eo2gtealDUfx92zG\nrAEh5qlPCCHMxGxvqGqt39RadwT+BDxd0zFKqTlKqd1Kqd1ZWVnmOnXdnfoBcs+Y5Y3UbYnZ7Dh1\nnrnDOuLuInueCCGsS13CPRWovudccOV9V7MSuK2mB7TW72itY7XWsQEBAXWv0lz2vg+uPtB1XKOa\n0VrzysajBPm4MVX2RBVCWKG6hPsuoLNSKlQp5QLcBaypfoBSqnO1m7cAx81XoplczIHDa41JS86u\njWrq60Nn2Z+Sy+MjOtPMqfFvygohhLnV2p+gtTYppeYCGwFHYLHW+qBS6jlgt9Z6DTBXKTUSKANy\ngJlNWXSDxH8C5SWNXiSsvELz2tfH6ODvwcSYIDMVJ4QQ5lWnzmKt9VfAV1fc99dqnz9u5rrMb+9y\naB0FbaIb1cza/WkcPZvPG1N74uR4Y84BE0JYvxsjndL3Q0Y8xMxoVDNl5RX836ZjdGvjxS2RbcxU\nnBBCmN+NEe5xy8GxmbEpRyN8sjuF0+eKeGJ0FxwcZNNrIYT1sv9wLyuGhI+h23hwa9HgZorLynnj\nu+PEtPNheNeWZixQCCHMz/7D/ciXUJwLMY0b2/7BjjOk5xbzxM1hKDOs/y6EEE3J/sM9bhn4tIOQ\nwQ1uorDExL83J3JTJ38GdPQ3Y3FCCNE07Dvcc04bs1J7TAeHhr/UJT+e4lxhKU/cLJteCyFsg32H\n+74PAAU97m5wE7lFZby95SQju7WiR1sf89UmhBBNyH7DvaLcWCSs4zDwaVv78Vfx9pYTFJSY+MNo\n2fRaCGE77DfcT34PeSmNWiQsM7+YJT8mMT4qkG5tvMxXmxBCNDH7Dfe9y42hj11vaXAT/958gtLy\nCn43Sq7ahRC2xT7Dveg8HFkHUVPAqWFb36VeuMiKHWeY3CuYUH8PMxcohBBNyz7DPf5jKC9tVJfM\n65uMhS3njehcy5FCCGF97C/ctTa6ZAJ7QuuIBjVxMquAVXEpTOvXjkAfNzMXKIQQTc/+wj1tL5w9\n0Kilff9v03GaOTnwyNBOZixMCCGuH/sL973vg5MrRDRskbBDaXms3Z/G7IEhBDRvWH+9EEJYmn2F\ne9lFSFgF4beCW8MmHL32zVG8XJ2YM6ijmYsTQojrx77C/dAaKMltcJdM3JkcNh3O5MEhHfF2dzZz\ncUIIcf3YV7jvXQ4tQqD9TQ16+isbj+Lv6cKsASFmLUsIIa43+wn38ychaatx1d6ARcJ+TMxm+4lz\nPDK0Ex7N6rT7oBBCWC37Cfe9H4BygOiGLRL2+rfHaePtyt1925m5MCGEuP7sI9wrymHfCug4AryD\n6v30w+l57Dh1nnsHhuLq7NgEBQohxPVlH+F+4jvIT2vwbkvLfkrC1dmBybHB5q1LCCEsxD7CPW4Z\nuPtBl7H1fmpuURmf7U3l9p5B+Li7NEFxQghx/dl+uBdmw9H1EHUXONU/nD/enUxxWQX39Asxf21C\nCGEhth/u8R9BRVmDumTKKzTLfz5NnxBfwgNlvXYhhP2w7XDXGuKWQ1AstOxW76d/fzSTM+eLmCnj\n2oUQdsa2wz01DrION3hG6tKfTtPKqxmju7cyc2FCCGFZth3ue5eBsztE3FHvp57MKmDLsSym9W2P\ns6NtfxmEEOJKtptqpYWQsBrCbwPX+veXL/vpNM6Oiql9ZNKSEML+2G64H1oDpfkN6pIpKDGxek8K\nt0S2kWV9hRB2yXbDfe9y8O0I7QfU+6mfxaWQX2KSN1KFEHbLNsP93Ak4/aNx1a5UvZ6qtWbpT6eJ\nCvamR9uGrfkuhBDWzjbDfe/7lYuETa33U386cY7EzAJm9A9B1fMXgxBC2ArbC/dyk7FIWOfR4NWm\n3k9/b3sSvh4ujIuq/3OFEMJW2F64J26CggzoWf8ZqSk5RWw6fJa7ereV1R+FEHbN9sK9KBsCukKX\nm+v91A92nAFgWr/25q5KCCGsSp3CXSk1Ril1VCmVqJSaX8Pjv1dKHVJKxSulvlVKNV169pwOj/wM\njvXb47S4rJyVO88wOrw1QT5uTVScEEJYh1rDXSnlCLwJjAXCgalKqfArDtsLxGqto4BVwEvmLvSK\nour9lLX708gpKmPGALlqF0LYv7pcufcBErXWJ7XWpcBK4NbqB2itN2utiypv/gxY1a4XxvDHJLq0\n8qR/Bz9LlyOEEE2uLuEeBCRXu51Sed/V3Aesb0xR5hZ35gIHUvNk+KMQ4obhZM7GlFLTgVhgyFUe\nnwPMAWjX7vqt6bLspySauzpxe8/6768qhBC2qC5X7qlA22q3gyvvu4xSaiTwFDBBa11SU0Na63e0\n1rFa69iAgICG1FtvmfnFfJWQzuRebfFoZtbfZUIIYbXqEu67gM5KqVCllAtwF7Cm+gFKqZ7A2xjB\nnmn+Mhvuwx3JlJVr7ukvb6QKIW4ctYa71toEzAU2AoeBj7XWB5VSzymlJlQe9jLgCXyilNqnlFpz\nleauq1JTBR/sOM3QsABC/T0sXY4QQlw3deqn0Fp/BXx1xX1/rfb5SDPXZRYbD2aQmV/Ci/1DLF2K\nEEJcV7Y3Q7Uelv2URHs/d4Z0uT79+0IIYS3sNtwPpuWyKymHe/q1x8FBhj8KIW4sdhvuy7afxs3Z\nkcm92tZ+sBBC2Bm7DPecwlI+35fKbT2D8Hav3xo0QghhD+wy3D/enUyJqYKZso6MEOIGZXfhXl6h\nWf7zafqG+tK1tZelyxFCCIuwu3D/7kgmKTkXmSWbXwshbmB2F+7Lfkqijbcro8JbWboUIYSwGLsK\n98TMArYez2Za33Y4OdrVSxNCiHqxqwRc/lMSLo4O3NXn+q04KYQQ1shuwj2/uIxVe1IYF9UGf89m\nli5HCCEsym7C/dO4VApLy5khb6QKIYR9hPulbfSi2/rQo62PpcsRQgiLs4tw35aYzcmsQmbKmu1C\nCAHYSbgv3X4aPw8XbolqY+lShBDCKth8uCefL+LbI2eZ2qcdzZwcLV2OEEJYBZsP9/d/Po2DUkzr\nJ8MfhRDiEpsO94ul5azclczN3VvRxtvN0uUIIYTVsOlwX7s/jdyLZcyQbfSEEOIyNhvuWmve255E\nWKvm9A31tXQ5QghhVWw23PeczuFQeh4zB4SglGyjJ4QQ1dlsuL+3PQkvVydu6xlo6VKEEMLq2GS4\nn80rZsOBDO6MbYu7i5OlyxFCCKtjk+G+YscZyrVmej+ZkSqEEDWxuXAvNVWwYucZhnYJIMTfw9Ll\nCCGEVbK5cF9/IJ2s/BJmyuqPQghxVTYX7h4uTowKb8XgzgGWLkUIIayWzb0bOTK8FSNlf1QhhLgm\nm7tyF0IIUTsJdyGEsEMS7kIIYYck3IUQwg5JuAshhB2ScBdCCDsk4S6EEHZIwl0IIeyQ0lpb5sRK\nZQGnG/h0fyDbjOU0NVuq15ZqBduq15ZqBduq15ZqhcbV215rXesUfYuFe2MopXZrrWMtXUdd2VK9\ntlQr2Fa9tlQr2Fa9tlQrXJ96pVtGCCHskIS7EELYIVsN93csXUA92VK9tlQr2Fa9tlQr2Fa9tlQr\nXId6bbLPXQghxLXZ6pW7EEKIa7C5cFdKjVFKHVVKJSql5lu6nqtRSrVVSm1WSh1SSh1USj1u6Zrq\nQinlqJTaq5T60tK1XItSykcptUopdUQpdVgp1d/SNV2LUup3ld8HB5RSHyqlXC1dU3VKqcVKqUyl\n1IFq9/kqpb5RSh2v/LeFJWu85Cq1vlz5vRCvlPpMKeVjyRovqanWao/9QSmllVL+TXFumwp3pZQj\n8CYwFggHpiqlwi1b1VWZgD9orcOBfsCjVlxrdY8Dhy1dRB38E9igte4KRGPFNSulgoB5QKzWOgJw\nBO6ybFW/8h4w5or75gPfaq07A99W3rYG7/HrWr8BIrTWUcAx4M/Xu6ireI9f14pSqi0wGjjTVCe2\nqXAH+gCJWuuTWutSYCVwq4VrqpHWOl1rHVf5eT5G+ARZtqprU0oFA7cAiyxdy7UopbyBwcC7AFrr\nUq31BctWVSsnwE0p5QS4A2kWrucyWustwPkr7r4VWFr5+VLgtuta1FXUVKvW+muttany5s9A8HUv\nrAZX+boC/B/wJNBkb3raWrgHAcnVbqdg5YEJoJQKAXoCOyxbSa0WYnzDVVi6kFqEAlnAksoupEVK\nKQ9LF3U1WutU4BWMq7R0IFdr/bVlq6qTVlrr9MrPMwBb2d/yXmC9pYu4GqXUrUCq1np/U57H1sLd\n5iilPIHVwG+11nmWrudqlFLjgEyt9R5L11IHTkAM8JbWuidQiPV0GfxKZV/1rRi/lAIBD6XUdMtW\nVT/aGFZn9UPrlFJPYXSJfmDpWmqilHIH/gL8tanPZWvhngq0rXY7uPI+q6SUcsYI9g+01p9aup5a\nDAQmKKWSMLq7hiul3rdsSVeVAqRorS/9JbQKI+yt1UjglNY6S2tdBnwKDLBwTXVxVinVBqDy30wL\n13NNSqlZwDhgmrbeMd4dMX7J76/8WQsG4pRSrc19IlsL911AZ6VUqFLKBeNNqTUWrqlGSimF0Sd8\nWGv9mqXrqY3W+s9a62CtdQjG1/U7rbVVXl1qrTOAZKVUWOVdI4BDFiypNmeAfkop98rvixFY8RvA\n1awBZlZ+PhP4woK1XJNSagxGl+IErXWRpeu5Gq11gta6pdY6pPJnLQWIqfyeNiubCvfKN0zmAhsx\nfjg+1loftGxVVzUQuAfjCnhf5cdvLF2UHXkM+EApFQ/0AP5u4XquqvIvjFVAHJCA8XNnVTMqlVIf\nAj8BYUqpFKXUfcALwCil1HGMvz5esGSNl1yl1n8BzYFvKn/W/mPRIitdpdbrc27r/etFCCFEQ9nU\nlbsQQoi6kXAXQgg7JOEuhBB2SMJdCCHskIS7EELYIQl3IYSwQxLuQghhhyTchRDCDv0/2jYP+70l\n9W0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "bdae24d0-8146-4997-bf46-4fe445959392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  227.270867\n",
              "  1       2   train  202.480373\n",
              "  2       3   train  178.094968\n",
              "  3       4   train  166.912071\n",
              "  4       5   train  159.397001\n",
              "  5       6   train  152.911004\n",
              "  6       7   train  147.603137\n",
              "  7       8   train  143.066251\n",
              "  8       9   train  139.013632\n",
              "  9      10   train  135.034796\n",
              "  10     11   train  131.651717\n",
              "  11     12   train  128.271497\n",
              "  12     13   train  125.757074\n",
              "  13     14   train  122.630540\n",
              "  14     15   train  120.007502\n",
              "  15      1   valid  216.257251\n",
              "  16      2   valid  179.409558\n",
              "  17      3   valid  164.660706\n",
              "  18      4   valid  155.281171\n",
              "  19      5   valid  152.392656\n",
              "  20      6   valid  145.726868\n",
              "  21      7   valid  143.556403\n",
              "  22      8   valid  137.573079\n",
              "  23      9   valid  137.970926\n",
              "  24     10   valid  134.769469\n",
              "  25     11   valid  128.958974\n",
              "  26     12   valid  128.632952\n",
              "  27     13   valid  124.774177\n",
              "  28     14   valid  123.417387\n",
              "  29     15   valid  124.314561,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-a78de514e5b62c61cb7e268b224d209c\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-a78de514e5b62c61cb7e268b224d209c\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 227.27086734771729}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 202.48037297725676}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 178.09496841430663}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 166.91207075119019}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 159.3970008611679}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 152.91100444793702}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 147.6031368970871}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 143.06625125408172}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 139.01363210678102}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 135.03479626178742}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 131.65171716213226}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 128.27149658203126}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 125.75707449913025}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 122.63053971529007}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 120.00750191211701}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 216.25725054740906}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 179.40955758094788}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 164.660706281662}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 155.2811712026596}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 152.39265632629395}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 145.72686755657196}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 143.55640256404877}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 137.57307887077332}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 137.97092580795288}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 134.76946926116943}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 128.9589742422104}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 128.63295221328735}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 124.77417743206024}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 123.41738700866699}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 124.31456100940704}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}