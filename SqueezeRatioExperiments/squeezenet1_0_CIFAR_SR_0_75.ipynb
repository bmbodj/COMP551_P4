{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_0_CIFAR_SR_0.75.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0 for the use of the squeeze ratio experiment t with squeeze ratio =0.75"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "7102abae-74cd-4cef-ccd7-a7745dfdd501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.55 s, sys: 433 ms, total: 1.98 s\n",
            "Wall time: 1.98 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "## esperimenting squeezeratio 0.125\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 48, 64, 64),\n",
        "                Fire(128, 48, 64, 64),\n",
        "                Fire(128, 96, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 96, 128, 128),\n",
        "                Fire(256, 144, 192, 192),\n",
        "                Fire(384, 144, 192, 192),\n",
        "                Fire(384, 192, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 192, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "0f7ef440-e569-4055-9370-b5ddb711f8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sowAzFMy8q-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        },
        "outputId": "e120bab2-de33-4bd8-9ba2-53e2eb5721a5"
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 10.771939 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "2685736\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 96, 1, 1), (48,), (64, 48, 1, 1), (64,), (64, 48, 3, 3), (64,)), parameters=35504\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 128, 1, 1), (48,), (64, 48, 1, 1), (64,), (64, 48, 3, 3), (64,)), parameters=37040\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((96, 128, 1, 1), (96,), (128, 96, 1, 1), (128,), (128, 96, 3, 3), (128,)), parameters=135520\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((96, 256, 1, 1), (96,), (128, 96, 1, 1), (128,), (128, 96, 3, 3), (128,)), parameters=147808\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((144, 256, 1, 1), (144,), (192, 144, 1, 1), (192,), (192, 144, 3, 3), (192,)), parameters=313872\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((144, 384, 1, 1), (144,), (192, 144, 1, 1), (192,), (192, 144, 3, 3), (192,)), parameters=332304\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((192, 384, 1, 1), (192,), (256, 192, 1, 1), (256,), (256, 192, 3, 3), (256,)), parameters=565952\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((192, 512, 1, 1), (192,), (256, 192, 1, 1), (256,), (256, 192, 3, 3), (256,)), parameters=590528\n",
            "  ), weights=((96, 3, 7, 7), (96,), (48, 96, 1, 1), (48,), (64, 48, 1, 1), (64,), (64, 48, 3, 3), (64,), (48, 128, 1, 1), (48,), (64, 48, 1, 1), (64,), (64, 48, 3, 3), (64,), (96, 128, 1, 1), (96,), (128, 96, 1, 1), (128,), (128, 96, 3, 3), (128,), (96, 256, 1, 1), (96,), (128, 96, 1, 1), (128,), (128, 96, 3, 3), (128,), (144, 256, 1, 1), (144,), (192, 144, 1, 1), (192,), (192, 144, 3, 3), (192,), (144, 384, 1, 1), (144,), (192, 144, 1, 1), (192,), (192, 144, 3, 3), (192,), (192, 384, 1, 1), (192,), (256, 192, 1, 1), (256,), (256, 192, 3, 3), (256,), (192, 512, 1, 1), (192,), (256, 192, 1, 1), (256,), (256, 192, 3, 3), (256,)), parameters=2172736\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "0d61ab83-ce20-465c-b775-c6f22ec2648d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efmf2BYD9DRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        },
        "outputId": "a20830e8-d53e-4b55-c701-3f7cf888c160"
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "2177866\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 96, 1, 1), (48,), (64, 48, 1, 1), (64,), (64, 48, 3, 3), (64,)), parameters=35504\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 128, 1, 1), (48,), (64, 48, 1, 1), (64,), (64, 48, 3, 3), (64,)), parameters=37040\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((96, 128, 1, 1), (96,), (128, 96, 1, 1), (128,), (128, 96, 3, 3), (128,)), parameters=135520\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((96, 256, 1, 1), (96,), (128, 96, 1, 1), (128,), (128, 96, 3, 3), (128,)), parameters=147808\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((144, 256, 1, 1), (144,), (192, 144, 1, 1), (192,), (192, 144, 3, 3), (192,)), parameters=313872\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((144, 384, 1, 1), (144,), (192, 144, 1, 1), (192,), (192, 144, 3, 3), (192,)), parameters=332304\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((192, 384, 1, 1), (192,), (256, 192, 1, 1), (256,), (256, 192, 3, 3), (256,)), parameters=565952\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((192, 512, 1, 1), (192,), (256, 192, 1, 1), (256,), (256, 192, 3, 3), (256,)), parameters=590528\n",
            "  ), weights=((96, 3, 7, 7), (96,), (48, 96, 1, 1), (48,), (64, 48, 1, 1), (64,), (64, 48, 3, 3), (64,), (48, 128, 1, 1), (48,), (64, 48, 1, 1), (64,), (64, 48, 3, 3), (64,), (96, 128, 1, 1), (96,), (128, 96, 1, 1), (128,), (128, 96, 3, 3), (128,), (96, 256, 1, 1), (96,), (128, 96, 1, 1), (128,), (128, 96, 3, 3), (128,), (144, 256, 1, 1), (144,), (192, 144, 1, 1), (192,), (192, 144, 3, 3), (192,), (144, 384, 1, 1), (144,), (192, 144, 1, 1), (192,), (192, 144, 3, 3), (192,), (192, 384, 1, 1), (192,), (256, 192, 1, 1), (256,), (256, 192, 3, 3), (256,), (192, 512, 1, 1), (192,), (256, 192, 1, 1), (256,), (256, 192, 3, 3), (256,)), parameters=2172736\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "757370ed-c2d4-4041-f182-9751ebdc3f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print (model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(144, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "#define criteria and optimizer\n",
        "# Note that other losses or optimizers can also be tried\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.004, amsgrad=True)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "81b1bc8b-5817-4a41-f5e2-46e2a278376b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 228.5646  Top1 Accuracy: 0.1327  Top5 Accuracy: 0.5488\n",
            "Epoch: 1 Validation Loss : 217.3825  Top 1 Validation Accuracy 0.2251 Top5 Validation Accuracy: 0.6851\n",
            "Training time for Epoch 1: 48.0339s\n",
            "Validation time for Epoch 1: 6.0996s\n",
            "2\n",
            "Epoch: 2 Train Loss : 197.3523  Top1 Accuracy: 0.2719  Top5 Accuracy: 0.7919\n",
            "Epoch: 2 Validation Loss : 171.4841  Top 1 Validation Accuracy 0.3722 Top5 Validation Accuracy: 0.8818\n",
            "Training time for Epoch 2: 48.1384s\n",
            "Validation time for Epoch 2: 6.2189s\n",
            "3\n",
            "Epoch: 3 Train Loss : 171.7021  Top1 Accuracy: 0.3657  Top5 Accuracy: 0.8796\n",
            "Epoch: 3 Validation Loss : 157.9341  Top 1 Validation Accuracy 0.4130 Top5 Validation Accuracy: 0.9085\n",
            "Training time for Epoch 3: 48.1314s\n",
            "Validation time for Epoch 3: 6.1799s\n",
            "4\n",
            "Epoch: 4 Train Loss : 160.5543  Top1 Accuracy: 0.4090  Top5 Accuracy: 0.9013\n",
            "Epoch: 4 Validation Loss : 152.8914  Top 1 Validation Accuracy 0.4392 Top5 Validation Accuracy: 0.9128\n",
            "Training time for Epoch 4: 48.2039s\n",
            "Validation time for Epoch 4: 6.1857s\n",
            "5\n",
            "Epoch: 5 Train Loss : 153.2699  Top1 Accuracy: 0.4352  Top5 Accuracy: 0.9144\n",
            "Epoch: 5 Validation Loss : 144.7779  Top 1 Validation Accuracy 0.4705 Top5 Validation Accuracy: 0.9269\n",
            "Training time for Epoch 5: 48.3197s\n",
            "Validation time for Epoch 5: 6.2562s\n",
            "6\n",
            "Epoch: 6 Train Loss : 147.2260  Top1 Accuracy: 0.4618  Top5 Accuracy: 0.9208\n",
            "Epoch: 6 Validation Loss : 140.6971  Top 1 Validation Accuracy 0.4843 Top5 Validation Accuracy: 0.9290\n",
            "Training time for Epoch 6: 48.3938s\n",
            "Validation time for Epoch 6: 6.2778s\n",
            "7\n",
            "Epoch: 7 Train Loss : 141.6542  Top1 Accuracy: 0.4889  Top5 Accuracy: 0.9288\n",
            "Epoch: 7 Validation Loss : 138.9203  Top 1 Validation Accuracy 0.4950 Top5 Validation Accuracy: 0.9328\n",
            "Training time for Epoch 7: 48.0823s\n",
            "Validation time for Epoch 7: 6.1694s\n",
            "8\n",
            "Epoch: 8 Train Loss : 136.4601  Top1 Accuracy: 0.5105  Top5 Accuracy: 0.9346\n",
            "Epoch: 8 Validation Loss : 134.1670  Top 1 Validation Accuracy 0.5168 Top5 Validation Accuracy: 0.9373\n",
            "Training time for Epoch 8: 48.4710s\n",
            "Validation time for Epoch 8: 6.2925s\n",
            "9\n",
            "Epoch: 9 Train Loss : 132.6855  Top1 Accuracy: 0.5252  Top5 Accuracy: 0.9393\n",
            "Epoch: 9 Validation Loss : 128.2504  Top 1 Validation Accuracy 0.5371 Top5 Validation Accuracy: 0.9437\n",
            "Training time for Epoch 9: 48.8059s\n",
            "Validation time for Epoch 9: 6.4134s\n",
            "10\n",
            "Epoch: 10 Train Loss : 129.1366  Top1 Accuracy: 0.5408  Top5 Accuracy: 0.9432\n",
            "Epoch: 10 Validation Loss : 128.1287  Top 1 Validation Accuracy 0.5378 Top5 Validation Accuracy: 0.9459\n",
            "Training time for Epoch 10: 48.7524s\n",
            "Validation time for Epoch 10: 6.3515s\n",
            "11\n",
            "Epoch: 11 Train Loss : 125.1826  Top1 Accuracy: 0.5538  Top5 Accuracy: 0.9479\n",
            "Epoch: 11 Validation Loss : 125.5458  Top 1 Validation Accuracy 0.5521 Top5 Validation Accuracy: 0.9452\n",
            "Training time for Epoch 11: 48.1948s\n",
            "Validation time for Epoch 11: 6.1690s\n",
            "12\n",
            "Epoch: 12 Train Loss : 122.6850  Top1 Accuracy: 0.5636  Top5 Accuracy: 0.9487\n",
            "Epoch: 12 Validation Loss : 126.3167  Top 1 Validation Accuracy 0.5462 Top5 Validation Accuracy: 0.9451\n",
            "Training time for Epoch 12: 48.1558s\n",
            "Validation time for Epoch 12: 6.1128s\n",
            "13\n",
            "Epoch: 13 Train Loss : 119.1950  Top1 Accuracy: 0.5746  Top5 Accuracy: 0.9524\n",
            "Epoch: 13 Validation Loss : 121.0837  Top 1 Validation Accuracy 0.5653 Top5 Validation Accuracy: 0.9495\n",
            "Training time for Epoch 13: 48.1766s\n",
            "Validation time for Epoch 13: 6.1215s\n",
            "14\n",
            "Epoch: 14 Train Loss : 116.8278  Top1 Accuracy: 0.5840  Top5 Accuracy: 0.9535\n",
            "Epoch: 14 Validation Loss : 121.9257  Top 1 Validation Accuracy 0.5681 Top5 Validation Accuracy: 0.9504\n",
            "Training time for Epoch 14: 48.1211s\n",
            "Validation time for Epoch 14: 6.1452s\n",
            "15\n",
            "Epoch: 15 Train Loss : 113.0027  Top1 Accuracy: 0.6007  Top5 Accuracy: 0.9578\n",
            "Epoch: 15 Validation Loss : 117.5574  Top 1 Validation Accuracy 0.5823 Top5 Validation Accuracy: 0.9503\n",
            "Training time for Epoch 15: 48.0937s\n",
            "Validation time for Epoch 15: 6.1160s\n",
            "Total time for training and validation: 817.1889s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "6fbe4f5b-af44-423f-b85e-6c5efffbb02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa0a8ad40b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "c45ab5cb-f4be-4450-e9ee-3b653a7d8f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa0a8c09b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "2f577c8c-f17e-449d-944f-0a15b8a8705d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  228.564557\n",
              "  1       2   train  197.352280\n",
              "  2       3   train  171.702145\n",
              "  3       4   train  160.554301\n",
              "  4       5   train  153.269935\n",
              "  5       6   train  147.225975\n",
              "  6       7   train  141.654183\n",
              "  7       8   train  136.460105\n",
              "  8       9   train  132.685504\n",
              "  9      10   train  129.136557\n",
              "  10     11   train  125.182616\n",
              "  11     12   train  122.685000\n",
              "  12     13   train  119.194992\n",
              "  13     14   train  116.827789\n",
              "  14     15   train  113.002658\n",
              "  15      1   valid  217.382478\n",
              "  16      2   valid  171.484117\n",
              "  17      3   valid  157.934106\n",
              "  18      4   valid  152.891398\n",
              "  19      5   valid  144.777946\n",
              "  20      6   valid  140.697079\n",
              "  21      7   valid  138.920325\n",
              "  22      8   valid  134.166973\n",
              "  23      9   valid  128.250440\n",
              "  24     10   valid  128.128702\n",
              "  25     11   valid  125.545832\n",
              "  26     12   valid  126.316733\n",
              "  27     13   valid  121.083662\n",
              "  28     14   valid  121.925696\n",
              "  29     15   valid  117.557430,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-23919ff1beeeb688db39faa1be9ca234\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-23919ff1beeeb688db39faa1be9ca234\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 228.56455726623534}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 197.35227987766265}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 171.70214524269105}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 160.55430057048798}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 153.2699345588684}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 147.22597539424896}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 141.65418329238892}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 136.4601050376892}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 132.6855037689209}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 129.13655695915222}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 125.18261560201645}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 122.68500032424927}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 119.19499183893204}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 116.82778862714767}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 113.00265837907791}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 217.38247799873352}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 171.4841170310974}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 157.93410575389862}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 152.89139759540558}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 144.77794635295868}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 140.69707918167114}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 138.92032527923584}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 134.1669726371765}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 128.25044000148773}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 128.1287021636963}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 125.54583185911179}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 126.31673330068588}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 121.08366197347641}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 121.92569571733475}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 117.55742996931076}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}