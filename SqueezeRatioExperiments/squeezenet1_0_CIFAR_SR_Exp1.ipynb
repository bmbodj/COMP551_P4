{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_0_CIFAR_SR_Exp1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0 for the use of the squeeze ratio experiment"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "dd80ff1d-f1ea-4476-bf52-ea7305755a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.59 s, sys: 394 ms, total: 1.99 s\n",
            "Wall time: 1.99 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "## esperimenting squeezeratio 0.125\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "              self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "53442895-c9bd-45b6-cee1-9464c6eb1f9e"
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "cd1a690f-9e12-44c6-dd39-14aa5313b9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        },
        "outputId": "d962e834-b36d-4249-cb45-b6e1ded0cc49"
      },
      "cell_type": "code",
      "source": [
        "print (model)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "#define criteria and optimizer\n",
        "# Note that other losses or optimizers can also be tried\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.004, amsgrad=True)\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "5a63af8e-03fd-4324-c3de-556befdf2929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 16 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 229.9030  Top1 Accuracy: 0.1074  Top5 Accuracy: 0.5118\n",
            "Epoch: 1 Validation Loss : 228.2755  Top 1 Validation Accuracy 0.1199 Top5 Validation Accuracy: 0.5512\n",
            "Training time for Epoch 1: 37.1725s\n",
            "Validation time for Epoch 1: 6.2085s\n",
            "2\n",
            "Epoch: 2 Train Loss : 218.9993  Top1 Accuracy: 0.1654  Top5 Accuracy: 0.6325\n",
            "Epoch: 2 Validation Loss : 198.0094  Top 1 Validation Accuracy 0.2633 Top5 Validation Accuracy: 0.7972\n",
            "Training time for Epoch 2: 37.2134s\n",
            "Validation time for Epoch 2: 6.2128s\n",
            "3\n",
            "Epoch: 3 Train Loss : 190.3426  Top1 Accuracy: 0.2730  Top5 Accuracy: 0.8282\n",
            "Epoch: 3 Validation Loss : 178.4293  Top 1 Validation Accuracy 0.3360 Top5 Validation Accuracy: 0.8593\n",
            "Training time for Epoch 3: 37.0164s\n",
            "Validation time for Epoch 3: 6.1477s\n",
            "4\n",
            "Epoch: 4 Train Loss : 176.5048  Top1 Accuracy: 0.3357  Top5 Accuracy: 0.8708\n",
            "Epoch: 4 Validation Loss : 166.1801  Top 1 Validation Accuracy 0.3796 Top5 Validation Accuracy: 0.8902\n",
            "Training time for Epoch 4: 36.8770s\n",
            "Validation time for Epoch 4: 6.2069s\n",
            "5\n",
            "Epoch: 5 Train Loss : 168.4110  Top1 Accuracy: 0.3688  Top5 Accuracy: 0.8877\n",
            "Epoch: 5 Validation Loss : 160.3130  Top 1 Validation Accuracy 0.3955 Top5 Validation Accuracy: 0.9034\n",
            "Training time for Epoch 5: 36.7211s\n",
            "Validation time for Epoch 5: 6.1344s\n",
            "6\n",
            "Epoch: 6 Train Loss : 162.1378  Top1 Accuracy: 0.3946  Top5 Accuracy: 0.8986\n",
            "Epoch: 6 Validation Loss : 158.9077  Top 1 Validation Accuracy 0.4144 Top5 Validation Accuracy: 0.9002\n",
            "Training time for Epoch 6: 36.6193s\n",
            "Validation time for Epoch 6: 6.1223s\n",
            "7\n",
            "Epoch: 7 Train Loss : 157.0979  Top1 Accuracy: 0.4153  Top5 Accuracy: 0.9074\n",
            "Epoch: 7 Validation Loss : 151.0390  Top 1 Validation Accuracy 0.4357 Top5 Validation Accuracy: 0.9172\n",
            "Training time for Epoch 7: 36.8501s\n",
            "Validation time for Epoch 7: 6.1467s\n",
            "8\n",
            "Epoch: 8 Train Loss : 152.9433  Top1 Accuracy: 0.4377  Top5 Accuracy: 0.9151\n",
            "Epoch: 8 Validation Loss : 150.5928  Top 1 Validation Accuracy 0.4383 Top5 Validation Accuracy: 0.9185\n",
            "Training time for Epoch 8: 36.7325s\n",
            "Validation time for Epoch 8: 6.1768s\n",
            "9\n",
            "Epoch: 9 Train Loss : 149.2338  Top1 Accuracy: 0.4533  Top5 Accuracy: 0.9195\n",
            "Epoch: 9 Validation Loss : 146.3390  Top 1 Validation Accuracy 0.4570 Top5 Validation Accuracy: 0.9244\n",
            "Training time for Epoch 9: 36.7682s\n",
            "Validation time for Epoch 9: 6.1248s\n",
            "10\n",
            "Epoch: 10 Train Loss : 145.5586  Top1 Accuracy: 0.4672  Top5 Accuracy: 0.9242\n",
            "Epoch: 10 Validation Loss : 147.0950  Top 1 Validation Accuracy 0.4716 Top5 Validation Accuracy: 0.9148\n",
            "Training time for Epoch 10: 36.6999s\n",
            "Validation time for Epoch 10: 6.1101s\n",
            "11\n",
            "Epoch: 11 Train Loss : 142.9768  Top1 Accuracy: 0.4782  Top5 Accuracy: 0.9282\n",
            "Epoch: 11 Validation Loss : 141.1583  Top 1 Validation Accuracy 0.4788 Top5 Validation Accuracy: 0.9268\n",
            "Training time for Epoch 11: 36.6581s\n",
            "Validation time for Epoch 11: 6.1581s\n",
            "12\n",
            "Epoch: 12 Train Loss : 139.9879  Top1 Accuracy: 0.4925  Top5 Accuracy: 0.9292\n",
            "Epoch: 12 Validation Loss : 142.6541  Top 1 Validation Accuracy 0.4795 Top5 Validation Accuracy: 0.9228\n",
            "Training time for Epoch 12: 36.9582s\n",
            "Validation time for Epoch 12: 6.1877s\n",
            "13\n",
            "Epoch: 13 Train Loss : 137.2648  Top1 Accuracy: 0.5033  Top5 Accuracy: 0.9334\n",
            "Epoch: 13 Validation Loss : 136.2797  Top 1 Validation Accuracy 0.5019 Top5 Validation Accuracy: 0.9334\n",
            "Training time for Epoch 13: 36.8996s\n",
            "Validation time for Epoch 13: 6.1894s\n",
            "14\n",
            "Epoch: 14 Train Loss : 135.4088  Top1 Accuracy: 0.5116  Top5 Accuracy: 0.9350\n",
            "Epoch: 14 Validation Loss : 135.6979  Top 1 Validation Accuracy 0.5080 Top5 Validation Accuracy: 0.9324\n",
            "Training time for Epoch 14: 37.0281s\n",
            "Validation time for Epoch 14: 6.1789s\n",
            "15\n",
            "Epoch: 15 Train Loss : 132.8803  Top1 Accuracy: 0.5220  Top5 Accuracy: 0.9375\n",
            "Epoch: 15 Validation Loss : 133.1044  Top 1 Validation Accuracy 0.5205 Top5 Validation Accuracy: 0.9375\n",
            "Training time for Epoch 15: 36.9156s\n",
            "Validation time for Epoch 15: 6.1884s\n",
            "16\n",
            "Epoch: 16 Train Loss : 130.4403  Top1 Accuracy: 0.5281  Top5 Accuracy: 0.9414\n",
            "Epoch: 16 Validation Loss : 130.6174  Top 1 Validation Accuracy 0.5259 Top5 Validation Accuracy: 0.9398\n",
            "Training time for Epoch 16: 36.8070s\n",
            "Validation time for Epoch 16: 6.1605s\n",
            "Total time for training and validation: 688.5961s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "aec970c5-dcfb-45a3-c704-4ee80eaf6e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8a1768dcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "5cc7112d-ee32-4bfc-cfe6-97efa781b648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8a16bd8fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "5e949247-e1b0-4492-d074-81c7c50741e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  229.903043\n",
              "  1       2   train  218.999331\n",
              "  2       3   train  190.342623\n",
              "  3       4   train  176.504801\n",
              "  4       5   train  168.411031\n",
              "  5       6   train  162.137838\n",
              "  6       7   train  157.097897\n",
              "  7       8   train  152.943251\n",
              "  8       9   train  149.233802\n",
              "  9      10   train  145.558595\n",
              "  10     11   train  142.976834\n",
              "  11     12   train  139.987865\n",
              "  12     13   train  137.264776\n",
              "  13     14   train  135.408801\n",
              "  14     15   train  132.880271\n",
              "  15     16   train  130.440290\n",
              "  16      1   valid  228.275541\n",
              "  17      2   valid  198.009409\n",
              "  18      3   valid  178.429322\n",
              "  19      4   valid  166.180050\n",
              "  20      5   valid  160.312963\n",
              "  21      6   valid  158.907697\n",
              "  22      7   valid  151.038985\n",
              "  23      8   valid  150.592832\n",
              "  24      9   valid  146.339014\n",
              "  25     10   valid  147.094977\n",
              "  26     11   valid  141.158270\n",
              "  27     12   valid  142.654108\n",
              "  28     13   valid  136.279669\n",
              "  29     14   valid  135.697893\n",
              "  30     15   valid  133.104398\n",
              "  31     16   valid  130.617370,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector004: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-c2bb1e8757d4b05ccf4673d59c9ca1e3\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector004\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-c2bb1e8757d4b05ccf4673d59c9ca1e3\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 229.9030427455902}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 218.99933090209962}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 190.34262347221375}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 176.50480093955994}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 168.4110308408737}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 162.13783791065217}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 157.09789695739747}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 152.9432511329651}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 149.23380155563353}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 145.55859470367432}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 142.97683436870574}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 139.9878652572632}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 137.26477615833284}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 135.40880093574523}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 132.88027110099793}, {\"epoch\": 16, \"Dataset\": \"train\", \"loss\": 130.44028975963593}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 228.275541305542}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 198.00940883159637}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 178.42932188510895}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 166.1800501346588}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 160.31296277046204}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 158.907696723938}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 151.03898513317108}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 150.59283196926117}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 146.3390142917633}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 147.0949765443802}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 141.15826988220215}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 142.65410840511322}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 136.27966856956482}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 135.6978931427002}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 133.1043976545334}, {\"epoch\": 16, \"Dataset\": \"valid\", \"loss\": 130.6173701286316}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    }
  ]
}