{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_1_CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_1"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "4355017d-b9f7-4e98-c67c-0465412264aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.57 s, sys: 436 ms, total: 2.01 s\n",
            "Wall time: 2.01 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "# experimenting squeezeratio 0.5\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "              self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "bf075e46-27dd-46bd-ac28-8cae85949675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPymGSZuqg-e",
        "colab_type": "code",
        "outputId": "14aff2a3-4816-4181-ebf2-b293a93d8c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 5.022867 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1248424\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "27ee9e9e-99c9-415b-8d64-f29d9b1754ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "1529b450-6143-4304-c7a0-f19e6e89c52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "740554\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "f55e1542-404c-4874-b56a-1227c10ea335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 147.8052  Top1 Accuracy: 0.4637  Top5 Accuracy: 0.9209\n",
            "Epoch: 1 Validation Loss : 146.8858  Top 1 Validation Accuracy 0.4671 Top5 Validation Accuracy: 0.9164\n",
            "Training time for Epoch 1: 36.8383s\n",
            "Validation time for Epoch 1: 6.2165s\n",
            "2\n",
            "Epoch: 2 Train Loss : 144.6810  Top1 Accuracy: 0.4738  Top5 Accuracy: 0.9257\n",
            "Epoch: 2 Validation Loss : 143.7621  Top 1 Validation Accuracy 0.4758 Top5 Validation Accuracy: 0.9220\n",
            "Training time for Epoch 2: 37.6107s\n",
            "Validation time for Epoch 2: 6.1466s\n",
            "3\n",
            "Epoch: 3 Train Loss : 141.6550  Top1 Accuracy: 0.4869  Top5 Accuracy: 0.9282\n",
            "Epoch: 3 Validation Loss : 139.9518  Top 1 Validation Accuracy 0.4845 Top5 Validation Accuracy: 0.9279\n",
            "Training time for Epoch 3: 37.5658s\n",
            "Validation time for Epoch 3: 6.1984s\n",
            "4\n",
            "Epoch: 4 Train Loss : 139.2776  Top1 Accuracy: 0.4952  Top5 Accuracy: 0.9311\n",
            "Epoch: 4 Validation Loss : 136.8702  Top 1 Validation Accuracy 0.5077 Top5 Validation Accuracy: 0.9307\n",
            "Training time for Epoch 4: 37.5327s\n",
            "Validation time for Epoch 4: 6.2313s\n",
            "5\n",
            "Epoch: 5 Train Loss : 136.2089  Top1 Accuracy: 0.5084  Top5 Accuracy: 0.9322\n",
            "Epoch: 5 Validation Loss : 134.8655  Top 1 Validation Accuracy 0.5066 Top5 Validation Accuracy: 0.9371\n",
            "Training time for Epoch 5: 37.9764s\n",
            "Validation time for Epoch 5: 6.2669s\n",
            "6\n",
            "Epoch: 6 Train Loss : 134.3250  Top1 Accuracy: 0.5167  Top5 Accuracy: 0.9370\n",
            "Epoch: 6 Validation Loss : 141.4441  Top 1 Validation Accuracy 0.4844 Top5 Validation Accuracy: 0.9276\n",
            "Training time for Epoch 6: 37.8539s\n",
            "Validation time for Epoch 6: 6.2148s\n",
            "7\n",
            "Epoch: 7 Train Loss : 131.8003  Top1 Accuracy: 0.5231  Top5 Accuracy: 0.9395\n",
            "Epoch: 7 Validation Loss : 132.5569  Top 1 Validation Accuracy 0.5149 Top5 Validation Accuracy: 0.9367\n",
            "Training time for Epoch 7: 37.9016s\n",
            "Validation time for Epoch 7: 6.2217s\n",
            "8\n",
            "Epoch: 8 Train Loss : 129.3876  Top1 Accuracy: 0.5374  Top5 Accuracy: 0.9411\n",
            "Epoch: 8 Validation Loss : 136.3266  Top 1 Validation Accuracy 0.5057 Top5 Validation Accuracy: 0.9296\n",
            "Training time for Epoch 8: 37.6216s\n",
            "Validation time for Epoch 8: 6.2955s\n",
            "9\n",
            "Epoch: 9 Train Loss : 127.1647  Top1 Accuracy: 0.5432  Top5 Accuracy: 0.9426\n",
            "Epoch: 9 Validation Loss : 128.8046  Top 1 Validation Accuracy 0.5383 Top5 Validation Accuracy: 0.9403\n",
            "Training time for Epoch 9: 37.9053s\n",
            "Validation time for Epoch 9: 6.2400s\n",
            "10\n",
            "Epoch: 10 Train Loss : 124.9192  Top1 Accuracy: 0.5514  Top5 Accuracy: 0.9463\n",
            "Epoch: 10 Validation Loss : 127.8114  Top 1 Validation Accuracy 0.5394 Top5 Validation Accuracy: 0.9414\n",
            "Training time for Epoch 10: 37.9167s\n",
            "Validation time for Epoch 10: 6.3458s\n",
            "11\n",
            "Epoch: 11 Train Loss : 122.7987  Top1 Accuracy: 0.5629  Top5 Accuracy: 0.9474\n",
            "Epoch: 11 Validation Loss : 127.3103  Top 1 Validation Accuracy 0.5408 Top5 Validation Accuracy: 0.9402\n",
            "Training time for Epoch 11: 37.6853s\n",
            "Validation time for Epoch 11: 6.2354s\n",
            "12\n",
            "Epoch: 12 Train Loss : 121.4010  Top1 Accuracy: 0.5664  Top5 Accuracy: 0.9489\n",
            "Epoch: 12 Validation Loss : 127.0998  Top 1 Validation Accuracy 0.5393 Top5 Validation Accuracy: 0.9424\n",
            "Training time for Epoch 12: 37.8625s\n",
            "Validation time for Epoch 12: 6.2635s\n",
            "13\n",
            "Epoch: 13 Train Loss : 119.3571  Top1 Accuracy: 0.5727  Top5 Accuracy: 0.9506\n",
            "Epoch: 13 Validation Loss : 123.1520  Top 1 Validation Accuracy 0.5594 Top5 Validation Accuracy: 0.9474\n",
            "Training time for Epoch 13: 37.2310s\n",
            "Validation time for Epoch 13: 6.2537s\n",
            "14\n",
            "Epoch: 14 Train Loss : 117.9188  Top1 Accuracy: 0.5799  Top5 Accuracy: 0.9530\n",
            "Epoch: 14 Validation Loss : 124.4403  Top 1 Validation Accuracy 0.5551 Top5 Validation Accuracy: 0.9448\n",
            "Training time for Epoch 14: 37.9654s\n",
            "Validation time for Epoch 14: 6.2129s\n",
            "15\n",
            "Epoch: 15 Train Loss : 116.4544  Top1 Accuracy: 0.5866  Top5 Accuracy: 0.9521\n",
            "Epoch: 15 Validation Loss : 125.1298  Top 1 Validation Accuracy 0.5580 Top5 Validation Accuracy: 0.9429\n",
            "Training time for Epoch 15: 38.0858s\n",
            "Validation time for Epoch 15: 6.2626s\n",
            "Total time for training and validation: 659.1635s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "b7b05171-8203-409e-da96-dbeaa08343dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6e5b9e0898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "75c68297-cada-4244-bb9a-6cf76ba714c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6e5ba0e898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqhAJfSGEqEIk9IUQogr5f6kliSMBzzdaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "8ca69840-1170-4086-9c3f-1c5a5b5a6d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  230.325739\n",
              "  1       2   train  226.031561\n",
              "  2       3   train  218.619994\n",
              "  3       4   train  199.479480\n",
              "  4       5   train  191.358823\n",
              "  5       6   train  185.667815\n",
              "  6       7   train  171.809245\n",
              "  7       8   train  160.807105\n",
              "  8       9   train  155.913977\n",
              "  9      10   train  151.744114\n",
              "  10      1   valid  228.645117\n",
              "  11      2   valid  222.521504\n",
              "  12      3   valid  207.204268\n",
              "  13      4   valid  190.684129\n",
              "  14      5   valid  186.861237\n",
              "  15      6   valid  174.531156\n",
              "  16      7   valid  159.477173\n",
              "  17      8   valid  155.340457\n",
              "  18      9   valid  163.075201\n",
              "  19     10   valid  150.157833,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector002: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-1dde3a2620fb0269a33f43d8dbb0fb92\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector002\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-1dde3a2620fb0269a33f43d8dbb0fb92\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 230.32573852539062}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 226.03156085014342}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 218.61999387741088}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 199.47947957515717}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 191.35882298946382}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 185.66781520843506}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 171.8092448234558}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 160.80710487365724}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 155.9139767408371}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 151.74411401748657}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 228.64511704444885}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 222.52150416374207}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 207.2042680978775}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 190.68412899971008}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 186.86123669147491}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 174.53115570545197}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 159.47717332839966}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 155.34045660495758}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 163.07520067691803}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 150.1578333377838}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}