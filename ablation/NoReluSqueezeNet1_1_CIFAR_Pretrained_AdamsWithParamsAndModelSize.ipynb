{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SqueezeNet1_1_CIFAR_Pretrained_AdamsWithParamsAndModelSize.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "r6HdN6hUrLs7"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4 - Removing Relu after Squeeze"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eJo-aFMiufRA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount for colab\n",
        "#from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "a24c5a30-aa29-4a7c-effd-7e1cfd59ee32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([\n",
        "                       transforms.RandomHorizontalFlip(),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.491399689874, 0.482158419622, 0.446530924224), (0.247032237587, 0.243485133253, 0.261587846975))\n",
        "                   ]))\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.Compose([\n",
        "                       transforms.RandomHorizontalFlip(),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.491399689874, 0.482158419622, 0.446530924224), (0.247032237587, 0.243485133253, 0.261587846975))\n",
        "                   ]))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size =100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SJzvv6Dr1a42",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "    'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        #https://github.com/DeepScale/SqueezeNet/issues/47 \n",
        "        # self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze(x)\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "\n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UZ-CJNOJPRgI",
        "outputId": "8dc1d800-651b-4f4a-d3fb-fab6a825d0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1329
        }
      },
      "cell_type": "code",
      "source": [
        "#*********************************************************************\n",
        "# model part\n",
        "#import torchvision.models as models\n",
        "# use pretrained model:\n",
        "model = squeezenet1_1(pretrained = True)\n",
        "\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))  \n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to /root/.torch/models/squeezenet1_1-f364aa15.pth\n",
            "4966400it [00:00, 40509340.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model size = 4.96998 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1235496\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2)), weights=((64, 3, 3, 3), (64,)), parameters=1792\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 64, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11408\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (6): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((64, 3, 3, 3), (64,), (16, 64, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=722496\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AdaptiveAvgPool2d(output_size=(1, 1)), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I0-4JV8qWEcc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import nn to modify features\n",
        "#import OrderedDicted to corectly align the network layers\n",
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "#create classifier which fit our num of outputs\n",
        "\n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "#replace the model's classifier with this new classifier \n",
        "model.classifier = classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YlergFUNWG_7",
        "outputId": "356b581f-1293-40ca-8d1a-9c34c7501543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1278
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))  \n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "727626\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2)), weights=((64, 3, 3, 3), (64,)), parameters=1792\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 64, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11408\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (6): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((64, 3, 3, 3), (64,), (16, 64, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=722496\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "#define criteria and optimizer\n",
        "# Note that other losses or optimizers can also be tried\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr = 0.0003, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, amsgrad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "e286013e-9413-462e-b5e1-dacc436ffb72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1643
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = False\n",
        "# define number of epochs\n",
        "epochs = 16\n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 266.0507  Top1 Accuracy: 0.1012  Top5 Accuracy: 0.4992\n",
            "Epoch: 1 Validation Loss : 230.2586  Top 1 Validation Accuracy 0.1000 Top5 Validation Accuracy: 0.5000\n",
            "Training time for Epoch 1: 41.9663s\n",
            "Validation time for Epoch 1: 6.6625s\n",
            "2\n",
            "Epoch: 2 Train Loss : 229.7603  Top1 Accuracy: 0.1099  Top5 Accuracy: 0.5116\n",
            "Epoch: 2 Validation Loss : 230.2586  Top 1 Validation Accuracy 0.1000 Top5 Validation Accuracy: 0.5000\n",
            "Training time for Epoch 2: 42.2106s\n",
            "Validation time for Epoch 2: 6.6192s\n",
            "3\n",
            "Epoch: 3 Train Loss : 217.1553  Top1 Accuracy: 0.1833  Top5 Accuracy: 0.5908\n",
            "Epoch: 3 Validation Loss : 201.5739  Top 1 Validation Accuracy 0.2843 Top5 Validation Accuracy: 0.6714\n",
            "Training time for Epoch 3: 42.2758s\n",
            "Validation time for Epoch 3: 6.6153s\n",
            "4\n",
            "Epoch: 4 Train Loss : 179.7162  Top1 Accuracy: 0.3863  Top5 Accuracy: 0.8011\n",
            "Epoch: 4 Validation Loss : 138.9203  Top 1 Validation Accuracy 0.5241 Top5 Validation Accuracy: 0.9188\n",
            "Training time for Epoch 4: 42.2518s\n",
            "Validation time for Epoch 4: 6.6412s\n",
            "5\n",
            "Epoch: 5 Train Loss : 134.0931  Top1 Accuracy: 0.5552  Top5 Accuracy: 0.9173\n",
            "Epoch: 5 Validation Loss : 111.8499  Top 1 Validation Accuracy 0.6109 Top5 Validation Accuracy: 0.9525\n",
            "Training time for Epoch 5: 42.2929s\n",
            "Validation time for Epoch 5: 6.7274s\n",
            "6\n",
            "Epoch: 6 Train Loss : 105.6792  Top1 Accuracy: 0.6503  Top5 Accuracy: 0.9546\n",
            "Epoch: 6 Validation Loss : 92.2260  Top 1 Validation Accuracy 0.6832 Top5 Validation Accuracy: 0.9647\n",
            "Training time for Epoch 6: 42.0058s\n",
            "Validation time for Epoch 6: 6.5861s\n",
            "7\n",
            "Epoch: 7 Train Loss : 93.4916  Top1 Accuracy: 0.6930  Top5 Accuracy: 0.9637\n",
            "Epoch: 7 Validation Loss : 93.7562  Top 1 Validation Accuracy 0.6854 Top5 Validation Accuracy: 0.9661\n",
            "Training time for Epoch 7: 41.5987s\n",
            "Validation time for Epoch 7: 6.6270s\n",
            "8\n",
            "Epoch: 8 Train Loss : 85.6857  Top1 Accuracy: 0.7186  Top5 Accuracy: 0.9703\n",
            "Epoch: 8 Validation Loss : 85.9694  Top 1 Validation Accuracy 0.7119 Top5 Validation Accuracy: 0.9733\n",
            "Training time for Epoch 8: 41.7032s\n",
            "Validation time for Epoch 8: 6.4419s\n",
            "9\n",
            "Epoch: 9 Train Loss : 78.6644  Top1 Accuracy: 0.7403  Top5 Accuracy: 0.9756\n",
            "Epoch: 9 Validation Loss : 84.5686  Top 1 Validation Accuracy 0.7232 Top5 Validation Accuracy: 0.9748\n",
            "Training time for Epoch 9: 41.4553s\n",
            "Validation time for Epoch 9: 6.5841s\n",
            "10\n",
            "Epoch: 10 Train Loss : 73.8244  Top1 Accuracy: 0.7541  Top5 Accuracy: 0.9774\n",
            "Epoch: 10 Validation Loss : 75.9441  Top 1 Validation Accuracy 0.7480 Top5 Validation Accuracy: 0.9774\n",
            "Training time for Epoch 10: 41.1188s\n",
            "Validation time for Epoch 10: 6.5809s\n",
            "11\n",
            "Epoch: 11 Train Loss : 69.8458  Top1 Accuracy: 0.7673  Top5 Accuracy: 0.9797\n",
            "Epoch: 11 Validation Loss : 73.2893  Top 1 Validation Accuracy 0.7515 Top5 Validation Accuracy: 0.9813\n",
            "Training time for Epoch 11: 41.5656s\n",
            "Validation time for Epoch 11: 6.4755s\n",
            "12\n",
            "Epoch: 12 Train Loss : 66.5793  Top1 Accuracy: 0.7801  Top5 Accuracy: 0.9819\n",
            "Epoch: 12 Validation Loss : 73.1354  Top 1 Validation Accuracy 0.7561 Top5 Validation Accuracy: 0.9807\n",
            "Training time for Epoch 12: 41.5112s\n",
            "Validation time for Epoch 12: 6.4486s\n",
            "13\n",
            "Epoch: 13 Train Loss : 63.1244  Top1 Accuracy: 0.7902  Top5 Accuracy: 0.9834\n",
            "Epoch: 13 Validation Loss : 75.4374  Top 1 Validation Accuracy 0.7495 Top5 Validation Accuracy: 0.9809\n",
            "Training time for Epoch 13: 41.1610s\n",
            "Validation time for Epoch 13: 6.3839s\n",
            "14\n",
            "Epoch: 14 Train Loss : 60.4065  Top1 Accuracy: 0.7994  Top5 Accuracy: 0.9849\n",
            "Epoch: 14 Validation Loss : 74.1159  Top 1 Validation Accuracy 0.7609 Top5 Validation Accuracy: 0.9807\n",
            "Training time for Epoch 14: 41.3136s\n",
            "Validation time for Epoch 14: 6.3284s\n",
            "15\n",
            "Epoch: 15 Train Loss : 57.2022  Top1 Accuracy: 0.8093  Top5 Accuracy: 0.9870\n",
            "Epoch: 15 Validation Loss : 71.6234  Top 1 Validation Accuracy 0.7602 Top5 Validation Accuracy: 0.9798\n",
            "Training time for Epoch 15: 40.8362s\n",
            "Validation time for Epoch 15: 6.4345s\n",
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-662e3808d955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#train:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_acc_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#epoch_train_acc = train(model,trainloader, criteria, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-75214156257e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, gpu)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds_5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mcurrent_correct_5\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(output,preds,preds_5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#check if the training is correct:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "eabd7ad6-c291-4cb5-ef27-033c5fb41d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc898153cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "9fdacdb6-0528-434c-8d26-be612fd389b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc898b2f748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhLsQQrggCXchhHBBEu5CCOGC/j/rYY32+7VbcQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "71b5d854-5ccc-4431-8cea-e6e9d9e16b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  197.569495\n",
              "  1       2   train  119.188716\n",
              "  2       3   train   96.014599\n",
              "  3       4   train   84.773152\n",
              "  4       5   train   78.407903\n",
              "  5       6   train   71.682172\n",
              "  6       7   train   67.330663\n",
              "  7       8   train   64.084642\n",
              "  8       9   train   60.550854\n",
              "  9      10   train   58.619733\n",
              "  10      1   valid  131.233782\n",
              "  11      2   valid   99.674501\n",
              "  12      3   valid   91.123526\n",
              "  13      4   valid   86.266094\n",
              "  14      5   valid   81.742518\n",
              "  15      6   valid   75.064264\n",
              "  16      7   valid   71.652176\n",
              "  17      8   valid   68.258196\n",
              "  18      9   valid   70.047015\n",
              "  19     10   valid   68.370592,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-a9bed629d317188fc293fb94822fa533\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-a9bed629d317188fc293fb94822fa533\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 197.56949450969697}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 119.18871630430222}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 96.01459863185883}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 84.77315207719803}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 78.40790340304375}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 71.68217229247094}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 67.33066272735596}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 64.08464167118072}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 60.55085391402245}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 58.61973294019699}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 131.23378241062164}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 99.67450112104416}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 91.12352603673935}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 86.2660943865776}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 81.74251782894135}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 75.06426393985748}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 71.65217626094818}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 68.25819626450539}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 70.04701483249664}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 68.37059152126312}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}