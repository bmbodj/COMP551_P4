{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SqueezeNet1_0_CIFAR_Pretrained_AdamsWithParamsAndModelSize.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "r6HdN6hUrLs7"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eJo-aFMiufRA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount for colab\n",
        "#from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "fc092a65-319c-4804-b116-98b7feee5ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([\n",
        "                       transforms.RandomHorizontalFlip(),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.491399689874, 0.482158419622, 0.446530924224), (0.247032237587, 0.243485133253, 0.261587846975))\n",
        "                   ]))\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.Compose([\n",
        "                       transforms.RandomHorizontalFlip(),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.491399689874, 0.482158419622, 0.446530924224), (0.247032237587, 0.243485133253, 0.261587846975))\n",
        "                   ]))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size =100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SJzvv6Dr1a42",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "    'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "\n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UZ-CJNOJPRgI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1465
        },
        "outputId": "0dd5ffd1-9c6f-4c14-c543-0ca52f570670"
      },
      "cell_type": "code",
      "source": [
        "#*********************************************************************\n",
        "# model part\n",
        "#import torchvision.models as models\n",
        "# use pretrained model:\n",
        "model = squeezenet1_0(pretrained = True)\n",
        "\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))  \n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 5.022845 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1248424\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I0-4JV8qWEcc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import nn to modify features\n",
        "#import OrderedDicted to corectly align the network layers\n",
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "#create classifier which fit our num of outputs\n",
        "\n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "#replace the model's classifier with this new classifier \n",
        "model.classifier = classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YlergFUNWG_7",
        "outputId": "97a2c843-c2ab-4c20-900a-0ad245dece0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))  \n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "740554\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "#define criteria and optimizer\n",
        "# Note that other losses or optimizers can also be tried\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr = 0.0003, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, amsgrad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "3598abba-39a0-425a-ccc7-ec06b44321fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = False\n",
        "# define number of epochs\n",
        "epochs = 10\n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 197.5695  Top1 Accuracy: 0.2619  Top5 Accuracy: 0.7337\n",
            "Epoch: 1 Validation Loss : 131.2338  Top 1 Validation Accuracy 0.5209 Top5 Validation Accuracy: 0.9361\n",
            "Training time for Epoch 1: 38.6532s\n",
            "Validation time for Epoch 1: 6.3470s\n",
            "2\n",
            "Epoch: 2 Train Loss : 119.1887  Top1 Accuracy: 0.5934  Top5 Accuracy: 0.9465\n",
            "Epoch: 2 Validation Loss : 99.6745  Top 1 Validation Accuracy 0.6643 Top5 Validation Accuracy: 0.9546\n",
            "Training time for Epoch 2: 39.6894s\n",
            "Validation time for Epoch 2: 6.3945s\n",
            "3\n",
            "Epoch: 3 Train Loss : 96.0146  Top1 Accuracy: 0.6847  Top5 Accuracy: 0.9622\n",
            "Epoch: 3 Validation Loss : 91.1235  Top 1 Validation Accuracy 0.6954 Top5 Validation Accuracy: 0.9641\n",
            "Training time for Epoch 3: 39.6048s\n",
            "Validation time for Epoch 3: 6.3914s\n",
            "4\n",
            "Epoch: 4 Train Loss : 84.7732  Top1 Accuracy: 0.7219  Top5 Accuracy: 0.9700\n",
            "Epoch: 4 Validation Loss : 86.2661  Top 1 Validation Accuracy 0.7124 Top5 Validation Accuracy: 0.9684\n",
            "Training time for Epoch 4: 39.6399s\n",
            "Validation time for Epoch 4: 6.3343s\n",
            "5\n",
            "Epoch: 5 Train Loss : 78.4079  Top1 Accuracy: 0.7411  Top5 Accuracy: 0.9736\n",
            "Epoch: 5 Validation Loss : 81.7425  Top 1 Validation Accuracy 0.7280 Top5 Validation Accuracy: 0.9699\n",
            "Training time for Epoch 5: 39.2867s\n",
            "Validation time for Epoch 5: 6.3059s\n",
            "6\n",
            "Epoch: 6 Train Loss : 71.6822  Top1 Accuracy: 0.7638  Top5 Accuracy: 0.9782\n",
            "Epoch: 6 Validation Loss : 75.0643  Top 1 Validation Accuracy 0.7481 Top5 Validation Accuracy: 0.9767\n",
            "Training time for Epoch 6: 39.6518s\n",
            "Validation time for Epoch 6: 6.3907s\n",
            "7\n",
            "Epoch: 7 Train Loss : 67.3307  Top1 Accuracy: 0.7779  Top5 Accuracy: 0.9812\n",
            "Epoch: 7 Validation Loss : 71.6522  Top 1 Validation Accuracy 0.7581 Top5 Validation Accuracy: 0.9771\n",
            "Training time for Epoch 7: 39.3191s\n",
            "Validation time for Epoch 7: 6.3658s\n",
            "8\n",
            "Epoch: 8 Train Loss : 64.0846  Top1 Accuracy: 0.7884  Top5 Accuracy: 0.9829\n",
            "Epoch: 8 Validation Loss : 68.2582  Top 1 Validation Accuracy 0.7759 Top5 Validation Accuracy: 0.9808\n",
            "Training time for Epoch 8: 41.4577s\n",
            "Validation time for Epoch 8: 6.4803s\n",
            "9\n",
            "Epoch: 9 Train Loss : 60.5509  Top1 Accuracy: 0.7999  Top5 Accuracy: 0.9838\n",
            "Epoch: 9 Validation Loss : 70.0470  Top 1 Validation Accuracy 0.7718 Top5 Validation Accuracy: 0.9800\n",
            "Training time for Epoch 9: 39.9060s\n",
            "Validation time for Epoch 9: 6.5198s\n",
            "10\n",
            "Epoch: 10 Train Loss : 58.6197  Top1 Accuracy: 0.8053  Top5 Accuracy: 0.9850\n",
            "Epoch: 10 Validation Loss : 68.3706  Top 1 Validation Accuracy 0.7754 Top5 Validation Accuracy: 0.9809\n",
            "Training time for Epoch 10: 40.2345s\n",
            "Validation time for Epoch 10: 6.4332s\n",
            "Total time for training and validation: 461.4102s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "690bdf93-0d7e-4e52-f2f7-10460fa88d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f75a6f678d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "297e4710-97ce-4581-8c11-5804adc530c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f75ed540438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "71b5d854-5ccc-4431-8cea-e6e9d9e16b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  197.569495\n",
              "  1       2   train  119.188716\n",
              "  2       3   train   96.014599\n",
              "  3       4   train   84.773152\n",
              "  4       5   train   78.407903\n",
              "  5       6   train   71.682172\n",
              "  6       7   train   67.330663\n",
              "  7       8   train   64.084642\n",
              "  8       9   train   60.550854\n",
              "  9      10   train   58.619733\n",
              "  10      1   valid  131.233782\n",
              "  11      2   valid   99.674501\n",
              "  12      3   valid   91.123526\n",
              "  13      4   valid   86.266094\n",
              "  14      5   valid   81.742518\n",
              "  15      6   valid   75.064264\n",
              "  16      7   valid   71.652176\n",
              "  17      8   valid   68.258196\n",
              "  18      9   valid   70.047015\n",
              "  19     10   valid   68.370592,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-a9bed629d317188fc293fb94822fa533\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-a9bed629d317188fc293fb94822fa533\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 197.56949450969697}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 119.18871630430222}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 96.01459863185883}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 84.77315207719803}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 78.40790340304375}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 71.68217229247094}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 67.33066272735596}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 64.08464167118072}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 60.55085391402245}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 58.61973294019699}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 131.23378241062164}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 99.67450112104416}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 91.12352603673935}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 86.2660943865776}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 81.74251782894135}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 75.06426393985748}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 71.65217626094818}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 68.25819626450539}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 70.04701483249664}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 68.37059152126312}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}