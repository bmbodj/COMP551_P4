{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SqueezeNet1_0_CIFAR_Pretrained_XavierWithParamsAndModelSize.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "r6HdN6hUrLs7"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eJo-aFMiufRA",
        "outputId": "98c5be2c-d1cc-45b1-a324-30eaac83ec40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount for colab\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "c3dd4c33-cf45-455f-a60e-8cc35d3bca39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([\n",
        "                       transforms.RandomHorizontalFlip(),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.491399689874, 0.482158419622, 0.446530924224), (0.247032237587, 0.243485133253, 0.261587846975))\n",
        "                   ]))\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.Compose([\n",
        "                       transforms.RandomHorizontalFlip(),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.491399689874, 0.482158419622, 0.446530924224), (0.247032237587, 0.243485133253, 0.261587846975))\n",
        "                   ]))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size =100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SJzvv6Dr1a42",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "    'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "\n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                   init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UZ-CJNOJPRgI",
        "outputId": "95f172a0-66b6-4878-d166-f63e9ee16526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1448
        }
      },
      "cell_type": "code",
      "source": [
        "#*********************************************************************\n",
        "# model part\n",
        "#import torchvision.models as models\n",
        "# use pretrained model:\n",
        "model = squeezenet1_0(pretrained = True)\n",
        "\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))  \n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 5.022873 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1248424\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I0-4JV8qWEcc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import nn to modify features\n",
        "#import OrderedDicted to corectly align the network layers\n",
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "#create classifier which fit our num of outputs\n",
        "\n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "#replace the model's classifier with this new classifier \n",
        "model.classifier = classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YlergFUNWG_7",
        "outputId": "864d1013-8f9b-449f-ff16-3fd231c5436c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))  \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "740554\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "#define criteria and optimizer\n",
        "# Note that other losses or optimizers can also be tried\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0003, momentum=0.9)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001, amsgrad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "45482236-ed92-4933-8c73-9a29dbb47872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = False\n",
        "# define number of epochs\n",
        "epochs = 16\n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 235.2349  Top1 Accuracy: 0.1080  Top5 Accuracy: 0.5056\n",
            "Epoch: 1 Validation Loss : 224.1046  Top 1 Validation Accuracy 0.1553 Top5 Validation Accuracy: 0.5280\n",
            "Training time for Epoch 1: 39.2195s\n",
            "Validation time for Epoch 1: 6.5612s\n",
            "2\n",
            "Epoch: 2 Train Loss : 201.6539  Top1 Accuracy: 0.2916  Top5 Accuracy: 0.6614\n",
            "Epoch: 2 Validation Loss : 158.4443  Top 1 Validation Accuracy 0.4718 Top5 Validation Accuracy: 0.8490\n",
            "Training time for Epoch 2: 39.3795s\n",
            "Validation time for Epoch 2: 6.5020s\n",
            "3\n",
            "Epoch: 3 Train Loss : 153.6701  Top1 Accuracy: 0.4684  Top5 Accuracy: 0.8813\n",
            "Epoch: 3 Validation Loss : 124.6880  Top 1 Validation Accuracy 0.5589 Top5 Validation Accuracy: 0.9482\n",
            "Training time for Epoch 3: 39.8600s\n",
            "Validation time for Epoch 3: 6.5873s\n",
            "4\n",
            "Epoch: 4 Train Loss : 131.1850  Top1 Accuracy: 0.5377  Top5 Accuracy: 0.9427\n",
            "Epoch: 4 Validation Loss : 113.6763  Top 1 Validation Accuracy 0.5975 Top5 Validation Accuracy: 0.9556\n",
            "Training time for Epoch 4: 40.0984s\n",
            "Validation time for Epoch 4: 6.5503s\n",
            "5\n",
            "Epoch: 5 Train Loss : 120.7005  Top1 Accuracy: 0.5752  Top5 Accuracy: 0.9527\n",
            "Epoch: 5 Validation Loss : 105.1006  Top 1 Validation Accuracy 0.6339 Top5 Validation Accuracy: 0.9648\n",
            "Training time for Epoch 5: 40.8502s\n",
            "Validation time for Epoch 5: 6.5328s\n",
            "6\n",
            "Epoch: 6 Train Loss : 112.7175  Top1 Accuracy: 0.6086  Top5 Accuracy: 0.9593\n",
            "Epoch: 6 Validation Loss : 101.4552  Top 1 Validation Accuracy 0.6391 Top5 Validation Accuracy: 0.9671\n",
            "Training time for Epoch 6: 42.1430s\n",
            "Validation time for Epoch 6: 6.5968s\n",
            "7\n",
            "Epoch: 7 Train Loss : 107.1094  Top1 Accuracy: 0.6318  Top5 Accuracy: 0.9629\n",
            "Epoch: 7 Validation Loss : 95.3416  Top 1 Validation Accuracy 0.6732 Top5 Validation Accuracy: 0.9686\n",
            "Training time for Epoch 7: 40.4285s\n",
            "Validation time for Epoch 7: 6.5594s\n",
            "8\n",
            "Epoch: 8 Train Loss : 102.1596  Top1 Accuracy: 0.6531  Top5 Accuracy: 0.9651\n",
            "Epoch: 8 Validation Loss : 93.5089  Top 1 Validation Accuracy 0.6805 Top5 Validation Accuracy: 0.9690\n",
            "Training time for Epoch 8: 41.1084s\n",
            "Validation time for Epoch 8: 6.5790s\n",
            "9\n",
            "Epoch: 9 Train Loss : 97.8740  Top1 Accuracy: 0.6693  Top5 Accuracy: 0.9682\n",
            "Epoch: 9 Validation Loss : 88.6421  Top 1 Validation Accuracy 0.6967 Top5 Validation Accuracy: 0.9719\n",
            "Training time for Epoch 9: 41.6590s\n",
            "Validation time for Epoch 9: 6.5819s\n",
            "10\n",
            "Epoch: 10 Train Loss : 94.2883  Top1 Accuracy: 0.6831  Top5 Accuracy: 0.9701\n",
            "Epoch: 10 Validation Loss : 86.7137  Top 1 Validation Accuracy 0.7011 Top5 Validation Accuracy: 0.9753\n",
            "Training time for Epoch 10: 39.8572s\n",
            "Validation time for Epoch 10: 6.5094s\n",
            "11\n",
            "Epoch: 11 Train Loss : 91.6320  Top1 Accuracy: 0.6911  Top5 Accuracy: 0.9720\n",
            "Epoch: 11 Validation Loss : 86.4054  Top 1 Validation Accuracy 0.7017 Top5 Validation Accuracy: 0.9734\n",
            "Training time for Epoch 11: 41.3359s\n",
            "Validation time for Epoch 11: 6.5293s\n",
            "12\n",
            "Epoch: 12 Train Loss : 88.6803  Top1 Accuracy: 0.7028  Top5 Accuracy: 0.9731\n",
            "Epoch: 12 Validation Loss : 84.9753  Top 1 Validation Accuracy 0.7090 Top5 Validation Accuracy: 0.9745\n",
            "Training time for Epoch 12: 39.8670s\n",
            "Validation time for Epoch 12: 6.5755s\n",
            "13\n",
            "Epoch: 13 Train Loss : 86.0826  Top1 Accuracy: 0.7131  Top5 Accuracy: 0.9744\n",
            "Epoch: 13 Validation Loss : 80.0967  Top 1 Validation Accuracy 0.7258 Top5 Validation Accuracy: 0.9785\n",
            "Training time for Epoch 13: 41.0414s\n",
            "Validation time for Epoch 13: 6.6097s\n",
            "14\n",
            "Epoch: 14 Train Loss : 83.7216  Top1 Accuracy: 0.7204  Top5 Accuracy: 0.9755\n",
            "Epoch: 14 Validation Loss : 79.1213  Top 1 Validation Accuracy 0.7276 Top5 Validation Accuracy: 0.9794\n",
            "Training time for Epoch 14: 41.3930s\n",
            "Validation time for Epoch 14: 6.5465s\n",
            "15\n",
            "Epoch: 15 Train Loss : 81.5890  Top1 Accuracy: 0.7290  Top5 Accuracy: 0.9770\n",
            "Epoch: 15 Validation Loss : 78.7175  Top 1 Validation Accuracy 0.7253 Top5 Validation Accuracy: 0.9790\n",
            "Training time for Epoch 15: 39.9109s\n",
            "Validation time for Epoch 15: 6.5335s\n",
            "16\n",
            "Epoch: 16 Train Loss : 79.4306  Top1 Accuracy: 0.7349  Top5 Accuracy: 0.9786\n",
            "Epoch: 16 Validation Loss : 77.2351  Top 1 Validation Accuracy 0.7308 Top5 Validation Accuracy: 0.9809\n",
            "Training time for Epoch 16: 42.7816s\n",
            "Validation time for Epoch 16: 6.7249s\n",
            "Total time for training and validation: 756.0193s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "c1c32a05-7081-4c43-9e28-08bb55a4f4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5b3ae2e0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "98b910ef-e632-4505-b5fc-bcacedd43b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5b3aee3828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "40f3469d-a6bd-4e04-bc91-ed9b1383525b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  235.234882\n",
              "  1       2   train  201.653860\n",
              "  2       3   train  153.670094\n",
              "  3       4   train  131.185045\n",
              "  4       5   train  120.700480\n",
              "  5       6   train  112.717463\n",
              "  6       7   train  107.109438\n",
              "  7       8   train  102.159599\n",
              "  8       9   train   97.874032\n",
              "  9      10   train   94.288279\n",
              "  10     11   train   91.632038\n",
              "  11     12   train   88.680294\n",
              "  12     13   train   86.082635\n",
              "  13     14   train   83.721605\n",
              "  14     15   train   81.589002\n",
              "  15     16   train   79.430631\n",
              "  16      1   valid  224.104623\n",
              "  17      2   valid  158.444342\n",
              "  18      3   valid  124.687965\n",
              "  19      4   valid  113.676292\n",
              "  20      5   valid  105.100567\n",
              "  21      6   valid  101.455195\n",
              "  22      7   valid   95.341639\n",
              "  23      8   valid   93.508917\n",
              "  24      9   valid   88.642137\n",
              "  25     10   valid   86.713726\n",
              "  26     11   valid   86.405390\n",
              "  27     12   valid   84.975277\n",
              "  28     13   valid   80.096658\n",
              "  29     14   valid   79.121279\n",
              "  30     15   valid   78.717479\n",
              "  31     16   valid   77.235068,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-72f542acbcf2bf19171a500adeaa0f1e\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-72f542acbcf2bf19171a500adeaa0f1e\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 235.23488168716432}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 201.65386035442353}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 153.67009406089784}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 131.185044670105}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 120.70047966241836}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 112.71746324300766}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 107.10943837165833}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 102.15959862470626}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 97.87403192520142}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 94.28827897310256}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 91.6320380449295}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 88.68029426336288}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 86.08263466358184}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 83.7216048002243}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 81.58900247812271}, {\"epoch\": 16, \"Dataset\": \"train\", \"loss\": 79.4306311249733}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 224.10462307929993}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 158.44434249401093}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 124.68796503543854}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 113.67629200220108}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 105.10056680440903}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 101.45519518852234}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 95.34163933992386}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 93.50891715288162}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 88.64213663339615}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 86.71372598409653}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 86.4053904414177}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 84.97527688741684}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 80.09665793180466}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 79.12127932906151}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 78.71747925877571}, {\"epoch\": 16, \"Dataset\": \"valid\", \"loss\": 77.23506817221642}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}