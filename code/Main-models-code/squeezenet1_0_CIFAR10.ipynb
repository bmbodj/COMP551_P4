{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_0_CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_0"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "adc6a96e-4d6a-4b9b-e360-ab993c81d5b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:04, 40765518.73it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "CPU times: user 3.66 s, sys: 1.32 s, total: 4.99 s\n",
            "Wall time: 7.75 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "# experimenting squeezeratio 0.5\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "              self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "508a4a05-c76b-48c4-f023-24e7326d0935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_0(pretrained=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPymGSZuqg-e",
        "colab_type": "code",
        "outputId": "82f40329-745b-4d76-dfc8-d12ee721b609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 5.022681 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1248424\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "09c73717-8723-4122-89a6-d1fbeab4766c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "32a9eff9-ea75-4864-9bb4-77b7cda0e5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "740554\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)), weights=((96, 3, 7, 7), (96,)), parameters=14208\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11920\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((96, 3, 7, 7), (96,), (16, 96, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=735424\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "a11f0289-598e-4c59-c313-d7cb1b85a073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 229.6778  Top1 Accuracy: 0.1200  Top5 Accuracy: 0.5104\n",
            "Epoch: 1 Validation Loss : 227.0628  Top 1 Validation Accuracy 0.1435 Top5 Validation Accuracy: 0.5206\n",
            "Training time for Epoch 1: 37.7560s\n",
            "Validation time for Epoch 1: 6.2685s\n",
            "2\n",
            "Epoch: 2 Train Loss : 220.2266  Top1 Accuracy: 0.2004  Top5 Accuracy: 0.6038\n",
            "Epoch: 2 Validation Loss : 199.3458  Top 1 Validation Accuracy 0.2915 Top5 Validation Accuracy: 0.7747\n",
            "Training time for Epoch 2: 38.1496s\n",
            "Validation time for Epoch 2: 6.3521s\n",
            "3\n",
            "Epoch: 3 Train Loss : 190.0024  Top1 Accuracy: 0.2978  Top5 Accuracy: 0.8219\n",
            "Epoch: 3 Validation Loss : 170.9898  Top 1 Validation Accuracy 0.3617 Top5 Validation Accuracy: 0.8850\n",
            "Training time for Epoch 3: 38.3752s\n",
            "Validation time for Epoch 3: 6.4005s\n",
            "4\n",
            "Epoch: 4 Train Loss : 173.7934  Top1 Accuracy: 0.3514  Top5 Accuracy: 0.8743\n",
            "Epoch: 4 Validation Loss : 164.6575  Top 1 Validation Accuracy 0.3885 Top5 Validation Accuracy: 0.8941\n",
            "Training time for Epoch 4: 38.3297s\n",
            "Validation time for Epoch 4: 6.4657s\n",
            "5\n",
            "Epoch: 5 Train Loss : 165.5444  Top1 Accuracy: 0.3864  Top5 Accuracy: 0.8926\n",
            "Epoch: 5 Validation Loss : 157.1194  Top 1 Validation Accuracy 0.4130 Top5 Validation Accuracy: 0.9081\n",
            "Training time for Epoch 5: 37.9441s\n",
            "Validation time for Epoch 5: 6.3485s\n",
            "6\n",
            "Epoch: 6 Train Loss : 159.0184  Top1 Accuracy: 0.4111  Top5 Accuracy: 0.9034\n",
            "Epoch: 6 Validation Loss : 151.8559  Top 1 Validation Accuracy 0.4281 Top5 Validation Accuracy: 0.9157\n",
            "Training time for Epoch 6: 38.0504s\n",
            "Validation time for Epoch 6: 6.4878s\n",
            "7\n",
            "Epoch: 7 Train Loss : 153.0700  Top1 Accuracy: 0.4363  Top5 Accuracy: 0.9127\n",
            "Epoch: 7 Validation Loss : 148.3175  Top 1 Validation Accuracy 0.4474 Top5 Validation Accuracy: 0.9171\n",
            "Training time for Epoch 7: 38.5698s\n",
            "Validation time for Epoch 7: 6.4001s\n",
            "8\n",
            "Epoch: 8 Train Loss : 148.6609  Top1 Accuracy: 0.4573  Top5 Accuracy: 0.9188\n",
            "Epoch: 8 Validation Loss : 145.0192  Top 1 Validation Accuracy 0.4679 Top5 Validation Accuracy: 0.9248\n",
            "Training time for Epoch 8: 38.6330s\n",
            "Validation time for Epoch 8: 6.4491s\n",
            "9\n",
            "Epoch: 9 Train Loss : 144.1659  Top1 Accuracy: 0.4747  Top5 Accuracy: 0.9252\n",
            "Epoch: 9 Validation Loss : 139.1608  Top 1 Validation Accuracy 0.4904 Top5 Validation Accuracy: 0.9327\n",
            "Training time for Epoch 9: 38.3266s\n",
            "Validation time for Epoch 9: 6.4133s\n",
            "10\n",
            "Epoch: 10 Train Loss : 140.8756  Top1 Accuracy: 0.4866  Top5 Accuracy: 0.9295\n",
            "Epoch: 10 Validation Loss : 137.7244  Top 1 Validation Accuracy 0.4949 Top5 Validation Accuracy: 0.9332\n",
            "Training time for Epoch 10: 38.4579s\n",
            "Validation time for Epoch 10: 6.4410s\n",
            "11\n",
            "Epoch: 11 Train Loss : 137.5827  Top1 Accuracy: 0.5016  Top5 Accuracy: 0.9317\n",
            "Epoch: 11 Validation Loss : 138.9503  Top 1 Validation Accuracy 0.4955 Top5 Validation Accuracy: 0.9274\n",
            "Training time for Epoch 11: 38.7030s\n",
            "Validation time for Epoch 11: 6.3531s\n",
            "12\n",
            "Epoch: 12 Train Loss : 134.8947  Top1 Accuracy: 0.5128  Top5 Accuracy: 0.9357\n",
            "Epoch: 12 Validation Loss : 133.4153  Top 1 Validation Accuracy 0.5104 Top5 Validation Accuracy: 0.9366\n",
            "Training time for Epoch 12: 38.1580s\n",
            "Validation time for Epoch 12: 6.2801s\n",
            "13\n",
            "Epoch: 13 Train Loss : 131.9979  Top1 Accuracy: 0.5248  Top5 Accuracy: 0.9381\n",
            "Epoch: 13 Validation Loss : 134.3281  Top 1 Validation Accuracy 0.5142 Top5 Validation Accuracy: 0.9353\n",
            "Training time for Epoch 13: 38.0484s\n",
            "Validation time for Epoch 13: 6.3205s\n",
            "14\n",
            "Epoch: 14 Train Loss : 129.4177  Top1 Accuracy: 0.5320  Top5 Accuracy: 0.9416\n",
            "Epoch: 14 Validation Loss : 128.8850  Top 1 Validation Accuracy 0.5333 Top5 Validation Accuracy: 0.9413\n",
            "Training time for Epoch 14: 37.7066s\n",
            "Validation time for Epoch 14: 6.3155s\n",
            "15\n",
            "Epoch: 15 Train Loss : 127.4215  Top1 Accuracy: 0.5437  Top5 Accuracy: 0.9431\n",
            "Epoch: 15 Validation Loss : 128.7515  Top 1 Validation Accuracy 0.5319 Top5 Validation Accuracy: 0.9412\n",
            "Training time for Epoch 15: 38.1357s\n",
            "Validation time for Epoch 15: 6.3816s\n",
            "Total time for training and validation: 669.0242s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "5cccb613-fefc-4526-f029-78b3c1e22d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f28cbb2dd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "ff1c50c7-a879-4afc-822e-050603390ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f28ccc64630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "693bfe1c-cb88-4510-a444-a4b46f276e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  229.677798\n",
              "  1       2   train  220.226572\n",
              "  2       3   train  190.002417\n",
              "  3       4   train  173.793404\n",
              "  4       5   train  165.544365\n",
              "  5       6   train  159.018377\n",
              "  6       7   train  153.069967\n",
              "  7       8   train  148.660926\n",
              "  8       9   train  144.165908\n",
              "  9      10   train  140.875581\n",
              "  10     11   train  137.582683\n",
              "  11     12   train  134.894691\n",
              "  12     13   train  131.997898\n",
              "  13     14   train  129.417702\n",
              "  14     15   train  127.421469\n",
              "  15      1   valid  227.062832\n",
              "  16      2   valid  199.345757\n",
              "  17      3   valid  170.989840\n",
              "  18      4   valid  164.657537\n",
              "  19      5   valid  157.119415\n",
              "  20      6   valid  151.855934\n",
              "  21      7   valid  148.317501\n",
              "  22      8   valid  145.019197\n",
              "  23      9   valid  139.160792\n",
              "  24     10   valid  137.724373\n",
              "  25     11   valid  138.950314\n",
              "  26     12   valid  133.415348\n",
              "  27     13   valid  134.328148\n",
              "  28     14   valid  128.885034\n",
              "  29     15   valid  128.751459,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-8faae867d29c06f8762b49e2888b8e8d\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-8faae867d29c06f8762b49e2888b8e8d\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 229.6777977466583}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 220.22657177448272}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 190.0024171590805}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 173.793404173851}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 165.54436523914336}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 159.01837730407715}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 153.069966506958}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 148.66092562675476}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 144.1659080028534}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 140.87558085918425}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 137.58268327713012}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 134.8946908712387}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 131.99789755344392}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 129.41770244836806}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 127.42146904468537}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 227.0628318786621}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 199.34575724601746}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 170.98984003067017}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 164.65753710269928}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 157.11941504478455}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 151.85593366622925}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 148.3175013065338}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 145.01919662952423}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 139.1607917547226}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 137.7243731021881}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 138.9503140449524}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 133.4153482913971}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 134.32814764976501}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 128.8850338459015}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 128.7514592409134}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}