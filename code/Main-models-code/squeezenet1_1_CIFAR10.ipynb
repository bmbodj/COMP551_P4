{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "squeezenet1_1_CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r6HdN6hUrLs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP551: Project 4"
      ]
    },
    {
      "metadata": {
        "id": "sGtlRPN47x5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Group 77:\n",
        "#####Authors :  Boury Mbodj, Humayun Khan & Ying Sun \n",
        "#####Date : April 15 th 2019\n",
        "#####Subject: The given file contains the implementation of the squeezenet1_1"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "an4jb3M2o0iZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pYAd2_qtvypy",
        "outputId": "a8cdad90-3194-4fcf-ccda-3f25f07eec34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "transform = transforms.Compose([transforms.Resize(32,32),\n",
        "                               transforms.ToTensor(),\n",
        "                               #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "training_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True,num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(validation_dataset, batch_size = 100, shuffle=False,num_workers=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CPU times: user 1.58 s, sys: 410 ms, total: 1.99 s\n",
            "Wall time: 1.99 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "17cQ8K4PO83O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "   'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "# experimenting squeezeratio 0.5\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "# Imported class in order to perfrom directly squeezeratio experiments \n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "              self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_0(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet model architecture from the `\"SqueezeNet: AlexNet-level\n",
        "    accuracy with 50x fewer parameters and <0.5MB model size\"\n",
        "    <https://arxiv.org/abs/1602.07360>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.0, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_0']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4VDzUt3Pe0m",
        "colab_type": "code",
        "outputId": "a6ae14bc-8024-4a96-acb3-42a965aa1791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "model= squeezenet1_1(pretrained=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPymGSZuqg-e",
        "colab_type": "code",
        "outputId": "da3aefe0-ca7f-4bb8-f005-39b07204cedc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "# Add code to get model size and number of parameters\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "p = pickle.dumps(model)\n",
        "\n",
        "size = sys.getsizeof(p)  #gets the size in bytes\n",
        "size = size/1000000\n",
        "print(\"Model size =\", size, \"MBs\")\n",
        "\n",
        "\n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "  \n",
        "print(\"Total number of parameters before reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "from torch.nn.modules.module import _addindent\n",
        "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
        "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
        "    tmpstr = model.__class__.__name__ + ' (\\n'\n",
        "    for key, module in model._modules.items():\n",
        "        # if it contains layers let call it recursively to get params and weights\n",
        "        if type(module) in [\n",
        "            torch.nn.modules.container.Container,\n",
        "            torch.nn.modules.container.Sequential\n",
        "        ]:\n",
        "            modstr = torch_summarize(module)\n",
        "        else:\n",
        "            modstr = module.__repr__()\n",
        "        modstr = _addindent(modstr, 2)\n",
        "\n",
        "        params = sum([np.prod(p.size()) for p in module.parameters()])\n",
        "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
        "\n",
        "        tmpstr += '  (' + key + '): ' + modstr \n",
        "        if show_weights:\n",
        "            tmpstr += ', weights={}'.format(weights)\n",
        "        if show_parameters:\n",
        "            tmpstr +=  ', parameters={}'.format(params)\n",
        "        tmpstr += '\\n'   \n",
        "\n",
        "    tmpstr = tmpstr + ')'\n",
        "    return tmpstr\n",
        "  \n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 4.970969 MBs\n",
            "Total number of parameters before reducing class size: \n",
            "1235496\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2)), weights=((64, 3, 3, 3), (64,)), parameters=1792\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 64, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11408\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (6): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((64, 3, 3, 3), (64,), (16, 64, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=722496\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((1000, 512, 1, 1), (1000,)), parameters=513000\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R6kVjm2SMUzt",
        "colab_type": "code",
        "outputId": "c6e251aa-56ef-42e1-c910-6345e522c7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1360
        }
      },
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (6): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FVgvU4GlQOrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adapt the classifier to our actual computatioons \n",
        "classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Conv2d(512, 10, kernel_size=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.AvgPool2d(1)\n",
        ")\n",
        "model.classifier= classifier\n",
        "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C12Nx3zIRAoJ",
        "colab_type": "code",
        "outputId": "bb6a5430-d3a4-4f2d-bf3d-3a4901a564d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1414
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Total number of parameters after reducing class size: \")\n",
        "print(get_n_params(model))\n",
        "\n",
        "print(torch_summarize(model))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of parameters after reducing class size: \n",
            "727626\n",
            "SqueezeNet (\n",
            "  (features): Sequential (\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2)), weights=((64, 3, 3, 3), (64,)), parameters=1792\n",
            "    (1): ReLU(inplace), weights=(), parameters=0\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 64, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=11408\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,)), parameters=12432\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (6): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=45344\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,)), parameters=49440\n",
            "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True), weights=(), parameters=0\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=104880\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,)), parameters=111024\n",
            "    (11): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=188992\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    ), weights=((64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=197184\n",
            "  ), weights=((64, 3, 3, 3), (64,), (16, 64, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (16, 128, 1, 1), (16,), (64, 16, 1, 1), (64,), (64, 16, 3, 3), (64,), (32, 128, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (32, 256, 1, 1), (32,), (128, 32, 1, 1), (128,), (128, 32, 3, 3), (128,), (48, 256, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (48, 384, 1, 1), (48,), (192, 48, 1, 1), (192,), (192, 48, 3, 3), (192,), (64, 384, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,), (64, 512, 1, 1), (64,), (256, 64, 1, 1), (256,), (256, 64, 3, 3), (256,)), parameters=722496\n",
            "  (classifier): Sequential (\n",
            "    (0): Dropout(p=0.5), weights=(), parameters=0\n",
            "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1)), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            "    (2): ReLU(inplace), weights=(), parameters=0\n",
            "    (3): AvgPool2d(kernel_size=1, stride=1, padding=0), weights=(), parameters=0\n",
            "  ), weights=((10, 512, 1, 1), (10,)), parameters=5130\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNJMkhfKPSAI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import optimizer:\n",
        "from torch import optim\n",
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.0004, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gSumLrfaPZZ6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#define training function\n",
        "def train (model, loader, criterion, gpu):\n",
        "    model.train()\n",
        "    current_loss = 0\n",
        "    current_correct = 0\n",
        "    current_correct_5=0\n",
        "    for train, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            train, y_train = train.to('cuda'), y_train.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(train)\n",
        "        _, preds = torch.max(output,1)#The most likelihood\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)#Top-5 prediction\n",
        "        loss = criterion(output, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()*train.size(0)\n",
        "        current_correct += torch.sum(preds == y_train.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                current_correct_5+=torch.sum(y_train.data[i]==j)\n",
        "        #print(output,preds,preds_5)\n",
        "        #check if the training is correct: \n",
        "        #print(preds,y_train,current_correct,current_loss)\n",
        "    epoch_loss = current_loss / len(loader)\n",
        "    # devide 4 because we read 4 data everytime\n",
        "    epoch_acc = current_correct.double() / len(loader)/100 # Top 1 accuracy\n",
        "    epoch_acc_5 = current_correct_5.double()/len(loader)/100 #Top 5 accuracy\n",
        "        \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KVd48zETPc3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define validation function\n",
        "def validation (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    valid_correct_5 = 0 #Top 5 accuracy\n",
        "    #I added this\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for valid, y_valid in iter(loader):\n",
        "        if gpu:\n",
        "            valid, y_valid = valid.to('cuda'), y_valid.to('cuda')\n",
        "        output = model.forward(valid)\n",
        "        _, preds = torch.max(output,1)\n",
        "        _, preds_5=torch.topk(output, 5, largest=True, sorted=True)\n",
        "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
        "        valid_correct += torch.sum(preds == y_valid.data)\n",
        "        for i in range(100):\n",
        "            for j in preds_5[i]:\n",
        "                valid_correct_5+=torch.sum(y_valid.data[i]==j)\n",
        "    epoch_loss = valid_loss / len(loader)\n",
        "    epoch_acc = valid_correct.double() / len(loader)/100\n",
        "    epoch_acc_5 = valid_correct_5.double() / len(loader)/100\n",
        "    \n",
        "    return epoch_loss, epoch_acc,epoch_acc_5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeVn5a0vPhJW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define test function\n",
        "def test (model, loader, criterion, gpu):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "    i=0\n",
        "    pred=torch.zeros(len(loader))\n",
        "    for test, y_train in iter(loader):\n",
        "        if gpu:\n",
        "            test = test.to('cuda')\n",
        "        output = model.forward(test)\n",
        "        _, preds = torch.max(output,1)\n",
        "        pred[i]=preds\n",
        "        i=i+1    \n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgXlX7GTPmqb",
        "outputId": "03e5d4bb-fa1d-4b88-ee32-cdc4c82ba785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1309
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "#send model to gpu. If not send it to GPU, delete next line.\n",
        "model.to('cuda')\n",
        "train_losses =[]\n",
        "train_acc =[]\n",
        "train_acc_5 =[]\n",
        "valid_losses=[]\n",
        "valid_acc =[]\n",
        "valid_acc_5 =[]\n",
        "#Initialize training params  \n",
        "#freeze gradient parameters in pretrained model\n",
        "for param in model.parameters():\n",
        "    param.require_grad = True\n",
        "# define number of epochs\n",
        "epochs = 15 \n",
        "epoch = 0\n",
        "import time\n",
        "start=time.time()\n",
        "for e in range(epochs):\n",
        "    start_train = time.time()\n",
        "    epoch +=1\n",
        "    print(epoch)\n",
        "#train:    \n",
        "    with torch.set_grad_enabled(True):\n",
        "        epoch_train_loss, epoch_train_acc, epoch_train_acc_5 = train(model,trainloader, criteria, 1)\n",
        "        #epoch_train_acc = train(model,trainloader, criteria, 1)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_acc.append(epoch_train_acc)\n",
        "        train_acc_5.append(epoch_train_acc_5)\n",
        "    print(\"Epoch: {} Train Loss : {:.4f}  Top1 Accuracy: {:.4f}  Top5 Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc,epoch_train_acc_5))\n",
        "    end_train=time.time()\n",
        "#Valid, Activate next code when validation result is needed:\n",
        "    with torch.no_grad():\n",
        "        epoch_val_loss, epoch_val_acc,epoch_val_acc_5 = validation(model, validloader, criteria, 1)\n",
        "        valid_losses.append(epoch_val_loss)\n",
        "        valid_acc.append(epoch_val_acc)\n",
        "        valid_acc_5.append(epoch_val_acc_5)\n",
        "    print(\"Epoch: {} Validation Loss : {:.4f}  Top 1 Validation Accuracy {:.4f} Top5 Validation Accuracy: {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc,epoch_val_acc_5))\n",
        "    end_valid = time.time()\n",
        "    print(\"Training time for Epoch {}: {:.4f}s\".format(epoch,end_train-start_train))\n",
        "    print(\"Validation time for Epoch {}: {:.4f}s\".format(epoch,end_valid-end_train))\n",
        "end=time.time()\n",
        "print(\"Total time for training and validation: {:.4f}s\".format(end-start))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch: 1 Train Loss : 230.0939  Top1 Accuracy: 0.1093  Top5 Accuracy: 0.5124\n",
            "Epoch: 1 Validation Loss : 229.6055  Top 1 Validation Accuracy 0.1158 Top5 Validation Accuracy: 0.5444\n",
            "Training time for Epoch 1: 38.5314s\n",
            "Validation time for Epoch 1: 6.1782s\n",
            "2\n",
            "Epoch: 2 Train Loss : 227.8799  Top1 Accuracy: 0.1446  Top5 Accuracy: 0.5608\n",
            "Epoch: 2 Validation Loss : 222.3921  Top 1 Validation Accuracy 0.2018 Top5 Validation Accuracy: 0.6409\n",
            "Training time for Epoch 2: 37.9797s\n",
            "Validation time for Epoch 2: 6.3480s\n",
            "3\n",
            "Epoch: 3 Train Loss : 214.6416  Top1 Accuracy: 0.2178  Top5 Accuracy: 0.6899\n",
            "Epoch: 3 Validation Loss : 198.8523  Top 1 Validation Accuracy 0.2623 Top5 Validation Accuracy: 0.7891\n",
            "Training time for Epoch 3: 38.7370s\n",
            "Validation time for Epoch 3: 6.2162s\n",
            "4\n",
            "Epoch: 4 Train Loss : 196.7121  Top1 Accuracy: 0.2671  Top5 Accuracy: 0.7988\n",
            "Epoch: 4 Validation Loss : 187.1849  Top 1 Validation Accuracy 0.3062 Top5 Validation Accuracy: 0.8467\n",
            "Training time for Epoch 4: 37.7557s\n",
            "Validation time for Epoch 4: 6.2598s\n",
            "5\n",
            "Epoch: 5 Train Loss : 184.5672  Top1 Accuracy: 0.3107  Top5 Accuracy: 0.8428\n",
            "Epoch: 5 Validation Loss : 174.8736  Top 1 Validation Accuracy 0.3529 Top5 Validation Accuracy: 0.8774\n",
            "Training time for Epoch 5: 38.4842s\n",
            "Validation time for Epoch 5: 6.2036s\n",
            "6\n",
            "Epoch: 6 Train Loss : 175.0221  Top1 Accuracy: 0.3490  Top5 Accuracy: 0.8723\n",
            "Epoch: 6 Validation Loss : 166.8255  Top 1 Validation Accuracy 0.3868 Top5 Validation Accuracy: 0.8902\n",
            "Training time for Epoch 6: 37.7013s\n",
            "Validation time for Epoch 6: 6.3478s\n",
            "7\n",
            "Epoch: 7 Train Loss : 167.5371  Top1 Accuracy: 0.3769  Top5 Accuracy: 0.8887\n",
            "Epoch: 7 Validation Loss : 163.6069  Top 1 Validation Accuracy 0.3926 Top5 Validation Accuracy: 0.8925\n",
            "Training time for Epoch 7: 38.7141s\n",
            "Validation time for Epoch 7: 6.1135s\n",
            "8\n",
            "Epoch: 8 Train Loss : 162.5333  Top1 Accuracy: 0.3969  Top5 Accuracy: 0.8992\n",
            "Epoch: 8 Validation Loss : 158.4964  Top 1 Validation Accuracy 0.4093 Top5 Validation Accuracy: 0.9044\n",
            "Training time for Epoch 8: 38.4004s\n",
            "Validation time for Epoch 8: 6.2954s\n",
            "9\n",
            "Epoch: 9 Train Loss : 159.1472  Top1 Accuracy: 0.4103  Top5 Accuracy: 0.9037\n",
            "Epoch: 9 Validation Loss : 153.8208  Top 1 Validation Accuracy 0.4293 Top5 Validation Accuracy: 0.9135\n",
            "Training time for Epoch 9: 38.4924s\n",
            "Validation time for Epoch 9: 6.3806s\n",
            "10\n",
            "Epoch: 10 Train Loss : 154.8458  Top1 Accuracy: 0.4288  Top5 Accuracy: 0.9128\n",
            "Epoch: 10 Validation Loss : 152.9045  Top 1 Validation Accuracy 0.4301 Top5 Validation Accuracy: 0.9156\n",
            "Training time for Epoch 10: 37.9175s\n",
            "Validation time for Epoch 10: 6.2367s\n",
            "11\n",
            "Epoch: 11 Train Loss : 151.7224  Top1 Accuracy: 0.4405  Top5 Accuracy: 0.9150\n",
            "Epoch: 11 Validation Loss : 146.2686  Top 1 Validation Accuracy 0.4550 Top5 Validation Accuracy: 0.9233\n",
            "Training time for Epoch 11: 37.9519s\n",
            "Validation time for Epoch 11: 6.2860s\n",
            "12\n",
            "Epoch: 12 Train Loss : 147.8077  Top1 Accuracy: 0.4583  Top5 Accuracy: 0.9207\n",
            "Epoch: 12 Validation Loss : 146.5367  Top 1 Validation Accuracy 0.4670 Top5 Validation Accuracy: 0.9179\n",
            "Training time for Epoch 12: 38.1734s\n",
            "Validation time for Epoch 12: 6.2786s\n",
            "13\n",
            "Epoch: 13 Train Loss : 145.5875  Top1 Accuracy: 0.4682  Top5 Accuracy: 0.9224\n",
            "Epoch: 13 Validation Loss : 146.4425  Top 1 Validation Accuracy 0.4592 Top5 Validation Accuracy: 0.9218\n",
            "Training time for Epoch 13: 37.3529s\n",
            "Validation time for Epoch 13: 6.2023s\n",
            "14\n",
            "Epoch: 14 Train Loss : 143.0672  Top1 Accuracy: 0.4794  Top5 Accuracy: 0.9271\n",
            "Epoch: 14 Validation Loss : 139.8668  Top 1 Validation Accuracy 0.4855 Top5 Validation Accuracy: 0.9302\n",
            "Training time for Epoch 14: 37.4094s\n",
            "Validation time for Epoch 14: 6.0554s\n",
            "15\n",
            "Epoch: 15 Train Loss : 140.3343  Top1 Accuracy: 0.4917  Top5 Accuracy: 0.9288\n",
            "Epoch: 15 Validation Loss : 141.6381  Top 1 Validation Accuracy 0.4832 Top5 Validation Accuracy: 0.9277\n",
            "Training time for Epoch 15: 37.2207s\n",
            "Validation time for Epoch 15: 6.1168s\n",
            "Total time for training and validation: 664.3455s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m55HUEJOOAzb",
        "outputId": "1b07b511-27ea-4e15-9546-8117e752c38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f07d0e2ad68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ieym9VY0TI-_",
        "outputId": "4501a8fc-3595-4737-e329-7193e7940a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training accuracy')\n",
        "plt.plot(valid_acc, label='Validation accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f07d0ee1fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nETEgKfoREQOSoh8RMSA/AVEA1vZ64hj6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "icl6jrEU0x9C",
        "outputId": "e009896f-5f7c-4132-e0ac-77c9e93f75d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# for variety, lets use altair to do the plot\n",
        "import altair as alt\n",
        "\n",
        "# create a pandas dataframe for the loss\n",
        "df = pd.DataFrame({\n",
        "    'epoch': range(1, len(train_losses) + 1),\n",
        "    'train': train_losses,\n",
        "    'valid': valid_losses\n",
        "})\n",
        "\n",
        "# unpivot to have cols [epoch, dataset, loss]\n",
        "df = df.melt(id_vars=['epoch'],\n",
        "             value_vars=['train', 'valid'],\n",
        "             value_name='loss',\n",
        "             var_name='Dataset')\n",
        "\n",
        "# line plot with altair\n",
        "alt.Chart(df).mark_line(point=True)\\\n",
        "    .encode(x='epoch', y='loss', color='Dataset')\\\n",
        "    .interactive()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chart({\n",
              "  data:     epoch Dataset        loss\n",
              "  0       1   train  230.093939\n",
              "  1       2   train  227.879870\n",
              "  2       3   train  214.641593\n",
              "  3       4   train  196.712059\n",
              "  4       5   train  184.567219\n",
              "  5       6   train  175.022077\n",
              "  6       7   train  167.537129\n",
              "  7       8   train  162.533342\n",
              "  8       9   train  159.147211\n",
              "  9      10   train  154.845794\n",
              "  10     11   train  151.722445\n",
              "  11     12   train  147.807735\n",
              "  12     13   train  145.587504\n",
              "  13     14   train  143.067193\n",
              "  14     15   train  140.334292\n",
              "  15      1   valid  229.605453\n",
              "  16      2   valid  222.392111\n",
              "  17      3   valid  198.852258\n",
              "  18      4   valid  187.184940\n",
              "  19      5   valid  174.873605\n",
              "  20      6   valid  166.825472\n",
              "  21      7   valid  163.606930\n",
              "  22      8   valid  158.496354\n",
              "  23      9   valid  153.820782\n",
              "  24     10   valid  152.904532\n",
              "  25     11   valid  146.268620\n",
              "  26     12   valid  146.536687\n",
              "  27     13   valid  146.442543\n",
              "  28     14   valid  139.866849\n",
              "  29     15   valid  141.638051,\n",
              "  encoding: EncodingWithFacet({\n",
              "    color: Color({\n",
              "      shorthand: 'Dataset'\n",
              "    }),\n",
              "    x: X({\n",
              "      shorthand: 'epoch'\n",
              "    }),\n",
              "    y: Y({\n",
              "      shorthand: 'loss'\n",
              "    })\n",
              "  }),\n",
              "  mark: MarkDef({\n",
              "    point: True,\n",
              "    type: 'line'\n",
              "  }),\n",
              "  selection: SelectionMapping({\n",
              "    selector001: SelectionDef({\n",
              "      bind: 'scales',\n",
              "      encodings: ['x', 'y'],\n",
              "      type: 'interval'\n",
              "    })\n",
              "  })\n",
              "})"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "  <style>\n",
              "    .vega-actions a {\n",
              "        margin-right: 12px;\n",
              "        color: #757575;\n",
              "        font-weight: normal;\n",
              "        font-size: 13px;\n",
              "    }\n",
              "    .error {\n",
              "        color: red;\n",
              "    }\n",
              "  </style>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega@4\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-lite@2.6.0\"></script>\n",
              "  <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm//vega-embed@3\"></script>\n",
              "</head>\n",
              "<body>\n",
              "  <div id=\"altair-viz\"></div>\n",
              "  <script>\n",
              "      var spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}}, \"data\": {\"name\": \"data-3adcf7d3a202b6b716e26d66ba3c433c\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Dataset\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"epoch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"loss\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.6.0.json\", \"datasets\": {\"data-3adcf7d3a202b6b716e26d66ba3c433c\": [{\"epoch\": 1, \"Dataset\": \"train\", \"loss\": 230.09393911361695}, {\"epoch\": 2, \"Dataset\": \"train\", \"loss\": 227.87986969947815}, {\"epoch\": 3, \"Dataset\": \"train\", \"loss\": 214.64159336090088}, {\"epoch\": 4, \"Dataset\": \"train\", \"loss\": 196.71205875873565}, {\"epoch\": 5, \"Dataset\": \"train\", \"loss\": 184.5672188282013}, {\"epoch\": 6, \"Dataset\": \"train\", \"loss\": 175.02207729816436}, {\"epoch\": 7, \"Dataset\": \"train\", \"loss\": 167.53712856769562}, {\"epoch\": 8, \"Dataset\": \"train\", \"loss\": 162.53334233760833}, {\"epoch\": 9, \"Dataset\": \"train\", \"loss\": 159.1472110748291}, {\"epoch\": 10, \"Dataset\": \"train\", \"loss\": 154.84579417705535}, {\"epoch\": 11, \"Dataset\": \"train\", \"loss\": 151.72244505882264}, {\"epoch\": 12, \"Dataset\": \"train\", \"loss\": 147.80773475170136}, {\"epoch\": 13, \"Dataset\": \"train\", \"loss\": 145.58750441074372}, {\"epoch\": 14, \"Dataset\": \"train\", \"loss\": 143.06719257831574}, {\"epoch\": 15, \"Dataset\": \"train\", \"loss\": 140.3342919588089}, {\"epoch\": 1, \"Dataset\": \"valid\", \"loss\": 229.60545325279236}, {\"epoch\": 2, \"Dataset\": \"valid\", \"loss\": 222.39211058616638}, {\"epoch\": 3, \"Dataset\": \"valid\", \"loss\": 198.85225772857666}, {\"epoch\": 4, \"Dataset\": \"valid\", \"loss\": 187.1849400997162}, {\"epoch\": 5, \"Dataset\": \"valid\", \"loss\": 174.87360453605652}, {\"epoch\": 6, \"Dataset\": \"valid\", \"loss\": 166.8254715204239}, {\"epoch\": 7, \"Dataset\": \"valid\", \"loss\": 163.6069302558899}, {\"epoch\": 8, \"Dataset\": \"valid\", \"loss\": 158.49635446071625}, {\"epoch\": 9, \"Dataset\": \"valid\", \"loss\": 153.82078158855438}, {\"epoch\": 10, \"Dataset\": \"valid\", \"loss\": 152.90453159809113}, {\"epoch\": 11, \"Dataset\": \"valid\", \"loss\": 146.26862001419067}, {\"epoch\": 12, \"Dataset\": \"valid\", \"loss\": 146.53668749332428}, {\"epoch\": 13, \"Dataset\": \"valid\", \"loss\": 146.44254338741302}, {\"epoch\": 14, \"Dataset\": \"valid\", \"loss\": 139.86684918403625}, {\"epoch\": 15, \"Dataset\": \"valid\", \"loss\": 141.6380511522293}]}};\n",
              "      var embedOpt = {\"mode\": \"vega-lite\"};\n",
              "\n",
              "      function showError(el, error){\n",
              "          el.innerHTML = ('<div class=\"error\" style=\"color:red;\">'\n",
              "                          + '<p>JavaScript Error: ' + error.message + '</p>'\n",
              "                          + \"<p>This usually means there's a typo in your chart specification. \"\n",
              "                          + \"See the javascript console for the full traceback.</p>\"\n",
              "                          + '</div>');\n",
              "          throw error;\n",
              "      }\n",
              "      const el = document.getElementById('altair-viz');\n",
              "      vegaEmbed(\"#altair-viz\", spec, embedOpt)\n",
              "        .catch(error => showError(el, error));\n",
              "\n",
              "  </script>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}